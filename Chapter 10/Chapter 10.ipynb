{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 10 - Introduction to Artificial Neural Networks with Keras\n",
    "- Inspiration in nature\n",
    "- Biological neurons -> Artificial neurons\n",
    "\n",
    "## Contents\n",
    "- Getting to the Multi-Layer Perceptron (MLP)\n",
    "- Building a MLP using Keras\n",
    "\n",
    "### From biological neurons to artificial neurons\n",
    "\n",
    "- Neural networks are old\n",
    "    - \"A logical calculus of ideas immanent in nervous activity\" - McCulloch and Pitts (1943)\n",
    "- Interest in it came and went over the decades\n",
    "- It might be the case that now it is here to stay\n",
    "    - Quantity of data available\n",
    "    - Computing power increase\n",
    "    - Better training algorithms\n",
    "    - Local optima is not that bad in practice\n",
    "    - Funding has resulted in progress lately\n",
    "    \n",
    "#### Biological neurons\n",
    "\n",
    "- A single neuron\n",
    "\n",
    "<img src=\"Imagens/bioneuron.png\">\n",
    "\n",
    "- Layers of neurons\n",
    "\n",
    "<img src=\"Imagens/biolayer.png\">\n",
    "\n",
    "#### Logical computation with neurons\n",
    "\n",
    "- Warren McCulloch and Walter Pitts Neuron, 1943.\n",
    "\n",
    "<img src=\"Imagens/artneuron.png\">\n",
    "\n",
    "- Perceptron, Frank Rosenblatt, 1957.\n",
    "\n",
    "<img src=\"Imagens/perceptron.png\">\n",
    "\n",
    "<img src=\"Imagens/perceptron2.png\">\n",
    "\n",
    "<img src=\"Imagens/perceptron3.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.linear_model import Perceptron\n",
    "\n",
    "iris = load_iris()\n",
    "X = iris.data[:, (2, 3)] # petal length, petal width\n",
    "y = (iris.target == 0).astype(np.int) # Iris Setosa?\n",
    "per_clf = Perceptron()\n",
    "per_clf.fit(X, y)\n",
    "y_pred = per_clf.predict([[2, 0.5]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "a = -per_clf.coef_[0][0] / per_clf.coef_[0][1]\n",
    "b = -per_clf.intercept_ / per_clf.coef_[0][1]\n",
    "\n",
    "axes = [0, 5, 0, 2]\n",
    "\n",
    "x0, x1 = np.meshgrid(\n",
    "        np.linspace(axes[0], axes[1], 500).reshape(-1, 1),\n",
    "        np.linspace(axes[2], axes[3], 200).reshape(-1, 1),\n",
    "    )\n",
    "X_new = np.c_[x0.ravel(), x1.ravel()]\n",
    "y_predict = per_clf.predict(X_new)\n",
    "zz = y_predict.reshape(x0.shape)\n",
    "\n",
    "plt.figure(figsize=(10, 4))\n",
    "plt.plot(X[y==0, 0], X[y==0, 1], \"bs\", label=\"Not Iris-Setosa\")\n",
    "plt.plot(X[y==1, 0], X[y==1, 1], \"yo\", label=\"Iris-Setosa\")\n",
    "\n",
    "plt.plot([axes[0], axes[1]], [a * axes[0] + b, a * axes[1] + b], \"k-\", linewidth=3)\n",
    "from matplotlib.colors import ListedColormap\n",
    "custom_cmap = ListedColormap(['#9898ff', '#fafab0'])\n",
    "\n",
    "plt.contourf(x0, x1, zz, cmap=custom_cmap)\n",
    "plt.xlabel(\"Petal length\", fontsize=14)\n",
    "plt.ylabel(\"Petal width\", fontsize=14)\n",
    "plt.legend(loc=\"lower right\", fontsize=14)\n",
    "plt.axis(axes)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Marvin Minsky and Seymour Papert, 1969.\n",
    "    - Highlighted perceptron weaknesses\n",
    "    - Can't learn XOR\n",
    "    - This weakness can be removed by stacking multiple perceptrons.\n",
    "    \n",
    "<img src=\"Imagens/xor.png\">\n",
    "\n",
    "#### Multi-layer perceptron and back propagation\n",
    "\n",
    "- 3b1b - Neural network playlist\n",
    "\n",
    "[![](http://img.youtube.com/vi/aircAruvnKk/0.jpg)](http://www.youtube.com/watch?v=aircAruvnKk \"3b1b - Neural network playlist\")\n",
    "\n",
    "- Welch Labs - Neural network playlist\n",
    "\n",
    "[![](http://img.youtube.com/vi/bxe2T-V8XRs/0.jpg)](http://www.youtube.com/watch?v=bxe2T-V8XRs \"Welch Labs - Neural network playlist\")\n",
    "\n",
    "### Multi-layer perceptron schema\n",
    "\n",
    "<img src=\"Imagens/mlp.png\">\n",
    "\n",
    "- Many layers stacked on top of each other (Deep)\n",
    "- Decades trying to find a way to train them, very little success\n",
    "- Backpropagation training algorithm, David Rumelhart, Geoffrey Hinton and Ronald Williams, 1986.\n",
    "    - Gradient descent with efficient technique to automatically compute gradients\n",
    "\n",
    "- Backpropagation algorithm\n",
    "    - Handles one mini-batch at a time\n",
    "    - A pass through all instance is called an epoch\n",
    "    - foward pass (intermediate results are cached)\n",
    "    - measure output error\n",
    "    - computes the contributio of each connection to the error through chain rule\n",
    "    - updates the weights\n",
    "- Activation functions\n",
    "    - Sigmoid (Rumelhart paper's choice)\n",
    "    - Hyperbolic tangent\n",
    "    - Rectified linear unit\n",
    "    - Softplus\n",
    "    - ...\n",
    "    \n",
    "<img src=\"Imagens/activ.png\">\n",
    "\n",
    "#### Regression MLPs\n",
    "- Output activation: ReLu/Softplus (positive outputs), logistic/tanh (bounded outputs)\n",
    "- Loss: MSE or MAE/Huber (if there are outliers)\n",
    "\n",
    "#### Classification MLPs\n",
    "- Output activation: Logistic (binary), Softmax(multiclass)\n",
    "- Loss: MSE or MAE/Huber (if there are outliers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementing MLP's with Keras\n",
    "- Sequential API\n",
    "    - Classification\n",
    "    - Regression\n",
    "- Functional API\n",
    "\n",
    "### Sequential API\n",
    "\n",
    "#### Building an Image Classifier using the sequential API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loading data with keras.datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "fashion_mnist = keras.datasets.fashion_mnist\n",
    "(X_train_full, y_train_full), (X_test, y_test) = fashion_mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 60000 28X28 grayscale images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_full.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating a validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_valid, X_train = X_train_full[:5000] / 255., X_train_full[5000:] / 255.\n",
    "y_valid, y_train = y_train_full[:5000], y_train_full[5000:]\n",
    "X_test = X_test / 255."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- What an example looks like?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAOcAAADnCAYAAADl9EEgAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/Il7ecAAAACXBIWXMAAAsTAAALEwEAmpwYAAAKN0lEQVR4nO3d20rWWx/F8WllWeYuUwtCSsIMCkqKiCDIrqOjovPooDvoIjrpCjrrHhZC1EHuyHaWFaXltkxts87eo/UfI3xe1zMe1vdzOpg+mxz9wR9zzqbfv38XAHl21PsNAPhnlBMIRTmBUJQTCEU5gVC7TM6fcvF/4yYDTU1N/9I7ifOPH5wnJxCKcgKhKCcQinICoSgnEIpyAqEoJxDKzTmxDcbGxiqzBw8eyLWjo6My//nzp8wPHTok85MnT1ZmV65ckWsvXLgg8//wHHNLeHICoSgnEIpyAqEoJxCKcgKhKCcQinICoZhzbsHExITMr1+/LvNHjx5VZj9+/JBrd+3S/2Q7duj/b13+/fv3La8dHByU+e3bt2V+48YNmf/X8OQEQlFOIBTlBEJRTiAU5QRCUU4gVJM5rrBhj8b89etXZeZGAk5fX5/M5+fnZd7R0VGZueMjm5ubZe5GMTt37pS523KmLCwsyPzIkSMyf/v27ZZfu1Z1PraTozGBRkI5gVCUEwhFOYFQlBMIRTmBUJQTCNWwW8bUHLOU2maZi4uLMndzzpaWFpnv27evMhsaGpJr3XY1N49z713NOd+8eSPXdnZ2yrytrU3mjx8/rsyGh4flWmc7f1+2S947AlBKoZxALMoJhKKcQCjKCYSinEAoygmEit3PuZ1zqYsXL8p8ZmZG5u69uVnj0tJSZaau4CullOXlZZm/ePFC5m4Ge+LEicrMzSndfkx17GYppWxsbFRm7t97bm5O5o7bx+r2wdaI/ZxAI6GcQCjKCYSinEAoygmEopxAKMoJhIrdz1nrOaF37typzJ4/fy7X9vf3y9ydDetmiWre52aFp06dkrmaoZbi91yq9/b69Wu51hkYGJC5Os/35cuXcu3Nmzdlfu/ePZlv8xxzS3hyAqEoJxCKcgKhKCcQinICoSgnECp2y1itLl++XJmtr6/LtW6Ms7a2JvM9e/bIfO/evZXZysqKXLt//36Zt7a2ytxtKVOvf+zYMbn28OHDMnff29evX7f0vkrx3/lff/0l8zpjyxjQSCgnEIpyAqEoJxCKcgKhKCcQinICoWK3jDnuKMMvX75UZmrOWEop7e3tMldX+JWij3h0uZvXuRltrcd2njt3rjJzM1Z3daLb9tXd3V2Z7dqlf1Xn5+dl7q4vdNsE64EnJxCKcgKhKCcQinICoSgnEIpyAqEoJxCqYeec7po+tf/Pzes2Nzdl7mZublapZrTu2E33s3t7e2XuZrBqT+WnT5/k2t27d8u8q6tL5up7cfNdd72gm4My5wTwxygnEIpyAqEoJxCKcgKhKCcQinICoRp2zun2Birfvn2TuZr1leLnpG4WqWaZ7mxXtxd1dXVV5u6zqxmum2O6a/Tce1teXq7M3Hm8bn/v+Pi4zIeHh2VeDzw5gVCUEwhFOYFQlBMIRTmBUJQTCEU5gVANO+d0c6sdO6r/31lYWJBr3717J/PTp0/L3M371CzT7bd059K2tbXJ3O0XVe/NzRLdfNftufz48WNldvDgQbnWfefufs5r167JvB54cgKhKCcQinICoSgnEIpyAqEoJxCqYUcps7OzMlcjB/dn99+/f8vcjQzcljN19KZ7b24U4o6QVCOmUkppbm6WueLemxulqO/NjYjctYxTU1MyT8STEwhFOYFQlBMIRTmBUJQTCEU5gVCUEwjVsHPOyclJmatZZVNTU02v7WaRbmuVmiW6WWCt3JYzNYN1Vx+6z+3WqyNH3WzZHds5NjYm80Q8OYFQlBMIRTmBUJQTCEU5gVCUEwhFOYFQDTvnfPr0qczVLFLN8v6Eu0bP7ZmsZQbrZoVuL2otM143I3V5S0uLzNWxoO5nO3NzczJ/9uyZzAcHB2t6/a3gyQmEopxAKMoJhKKcQCjKCYSinEAoygmEatg554cPH2R+4MCBysztmezs7JS5m7m5vYVqnudmgW5G686tddSc1O3XdK/tZqzq7Fn3ud2ZuY67UpI5J4D/oZxAKMoJhKKcQCjKCYSinEAoygmEatg5p9szqeZibh7nzkh1s0h3rq2a97n9mG6e5+7XdLNG9fPdXtJaPrd7bXfnqZstOx0dHTWt3w48OYFQlBMIRTmBUJQTCEU5gVCUEwjVsKMU92d59af1xcVFubanp0fmbqSwuroq871791Zma2trcq373K2trTJ3R0TW8tpqy1cppSwsLMj8+PHjldnU1JRc60ZrXV1dMndHY46MjMh8O/DkBEJRTiAU5QRCUU4gFOUEQlFOIBTlBELFzjndNXtue9L+/fsrs8+fP8u1Bw8elLnjZm7btbYUf+yn25Kmtpy5ozHdVjuXnz9/vjJ79eqVXOu2fLnZ9PT0tMzrgScnEIpyAqEoJxCKcgKhKCcQinICoSgnECp2zumOQnS5OmbR7Xns7e2V+fv372Wurh8spZSlpSWZK25PZa3r1ffmZrDuyNDZ2VmZqxlse3u7XDszMyNzd22ju1KyHnhyAqEoJxCKcgKhKCcQinICoSgnEIpyAqFi55zubFl19mspeu+hm3kNDAzIfHl5WeZuHqhy994ct2fSUd+bO5fWzTnb2tpkrv5N3Wu7ubebk6r9v/XCkxMIRTmBUJQTCEU5gVCUEwhFOYFQsaMUd1WdGxmo7UduFOKOl1THR5ZSyubmpsxrobZ0leKPDHXfmzqS1I2I3HGmtVyd6I7ldNzozX1v9cCTEwhFOYFQlBMIRTmBUJQTCEU5gVCUEwgVO+d0M7Pdu3fLXB0B6bYHdXd3y3xiYkLmtcxg3RV97nM77mhMNcOtdcZay/x3aGhI5g8fPpR5T0+PzN1nqweenEAoygmEopxAKMoJhKKcQCjKCYSinECo2DnnysqKzN0xjGqed/To0S2vLaWUz58/y9wdran2i7q9pG6G+uXLF5nPz8/LXB0h6eaYtcyeS9HX8F27dk2udXNOtwfX/T7VA09OIBTlBEJRTiAU5QRCUU4gFOUEQlFOIFTsnNNd6dbR0SFzde7tyMiIXHvo0CGZu6vs3DV+6+vrlZmbxzlufWdnp8zVflK3H9Pl7ho/NQe9evWqXOu4c2/d71s98OQEQlFOIBTlBEJRTiAU5QRCUU4gFOUEQsXOOd28zt31qOZ1Z8+elWtHR0dl/uTJE5m7M1bX1tYqM7fn0c1Ya51F1nI/58bGxpZ/din6fs6+vj651p1L62bPzDkB/DHKCYSinEAoygmEopxAKMoJhIodpbg/+bsjJJXp6WmZ379/X+b9/f0yX1hYkLn6s737XO7IUDeKccd2qpGDGnWU4rejufHYpUuXZK64MY4aX5VSyuTk5JZfe7vw5ARCUU4gFOUEQlFOIBTlBEJRTiAU5QRCxc45z5w5I/Ph4WGZj4+PV2Zuu5mbx929e1fm+PfdunVL5m67m9tGWA88OYFQlBMIRTmBUJQTCEU5gVCUEwhFOYFQTeoISQD1w5MTCEU5gVCUEwhFOYFQlBMIRTmBUH8DscHqopQEqFAAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(X_train[0], cmap=\"binary\")\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4, 0, 7, ..., 3, 0, 5], dtype=uint8)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = [\"T-shirt/top\", \"Trouser\", \"Pullover\", \"Dress\", \"Coat\",\n",
    "               \"Sandal\", \"Shirt\", \"Sneaker\", \"Bag\", \"Ankle boot\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Coat'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_names[y_train[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1296x345.6 with 60 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "n_rows = 4\n",
    "n_cols = 15\n",
    "plt.figure(figsize=(n_cols * 1.2, n_rows * 1.2))\n",
    "for row in range(n_rows):\n",
    "    for col in range(n_cols):\n",
    "        index = n_cols * row + col\n",
    "        plt.subplot(n_rows, n_cols, index + 1)\n",
    "        plt.imshow(X_train[index], cmap=\"binary\", interpolation=\"nearest\")\n",
    "        plt.axis('off')\n",
    "        plt.title(class_names[y_train[index]], fontsize=12)\n",
    "plt.subplots_adjust(wspace=0.2, hspace=0.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating the model with the sequential API #1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential()\n",
    "model.add(keras.layers.Flatten(input_shape=[28, 28]))\n",
    "model.add(keras.layers.Dense(300, activation=\"relu\"))\n",
    "model.add(keras.layers.Dense(100, activation=\"relu\"))\n",
    "model.add(keras.layers.Dense(10, activation=\"softmax\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten (Flatten)            (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 300)               235500    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 100)               30100     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                1010      \n",
      "=================================================================\n",
      "Total params: 266,610\n",
      "Trainable params: 266,610\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating the model with the sequential API #2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape=[28, 28]),\n",
    "    keras.layers.Dense(300, activation=\"relu\"),\n",
    "    keras.layers.Dense(100, activation=\"relu\"),\n",
    "    keras.layers.Dense(10, activation=\"softmax\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_1 (Flatten)          (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 300)               235500    \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 100)               30100     \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 10)                1010      \n",
      "=================================================================\n",
      "Total params: 266,610\n",
      "Trainable params: 266,610\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### List the layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tensorflow.python.keras.layers.core.Flatten at 0x1aaad870048>,\n",
       " <tensorflow.python.keras.layers.core.Dense at 0x1aaad870248>,\n",
       " <tensorflow.python.keras.layers.core.Dense at 0x1aaad870488>,\n",
       " <tensorflow.python.keras.layers.core.Dense at 0x1aaad870748>]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden1 = model.layers[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights, biases = hidden1.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-6.4410530e-02,  4.4310823e-02, -5.0729871e-02, ...,\n",
       "        -1.4930379e-02, -2.1941494e-02, -1.3807483e-02],\n",
       "       [-2.1084171e-02,  6.9389790e-03, -6.8886958e-02, ...,\n",
       "        -5.2052140e-02, -5.1032159e-02,  3.6087312e-02],\n",
       "       [-5.5392340e-02, -6.7793064e-02, -5.4584645e-02, ...,\n",
       "        -6.9570169e-02, -6.9586635e-03,  1.9336529e-02],\n",
       "       ...,\n",
       "       [ 3.8992167e-02,  9.1865659e-06,  7.1894646e-02, ...,\n",
       "        -6.8635754e-02,  5.4154873e-02,  5.4808423e-02],\n",
       "       [-3.9843600e-02, -3.0470353e-02,  3.7246227e-02, ...,\n",
       "         1.3626590e-02, -1.5415225e-02, -2.1660440e-02],\n",
       "       [-6.4390607e-02, -1.4924079e-02, -1.4129069e-02, ...,\n",
       "         2.2175938e-02,  1.4035873e-02, -6.5941818e-02]], dtype=float32)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "biases"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compiling the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "              optimizer=\"sgd\",\n",
    "              metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fitting the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "1719/1719 [==============================] - 11s 7ms/step - loss: 0.7235 - accuracy: 0.7644 - val_loss: 0.5335 - val_accuracy: 0.8180\n",
      "Epoch 2/30\n",
      "1719/1719 [==============================] - 9s 5ms/step - loss: 0.4942 - accuracy: 0.8273 - val_loss: 0.4863 - val_accuracy: 0.8264\n",
      "Epoch 3/30\n",
      "1719/1719 [==============================] - 11s 6ms/step - loss: 0.4486 - accuracy: 0.8438 - val_loss: 0.4227 - val_accuracy: 0.8518\n",
      "Epoch 4/30\n",
      "1719/1719 [==============================] - 9s 5ms/step - loss: 0.4228 - accuracy: 0.8520 - val_loss: 0.4272 - val_accuracy: 0.8510\n",
      "Epoch 5/30\n",
      "1719/1719 [==============================] - 9s 5ms/step - loss: 0.4035 - accuracy: 0.8587 - val_loss: 0.3945 - val_accuracy: 0.8638\n",
      "Epoch 6/30\n",
      "1719/1719 [==============================] - 9s 5ms/step - loss: 0.3869 - accuracy: 0.8645 - val_loss: 0.4028 - val_accuracy: 0.8562\n",
      "Epoch 7/30\n",
      "1719/1719 [==============================] - 9s 5ms/step - loss: 0.3731 - accuracy: 0.8685 - val_loss: 0.3611 - val_accuracy: 0.8726\n",
      "Epoch 8/30\n",
      "1719/1719 [==============================] - 9s 5ms/step - loss: 0.3619 - accuracy: 0.8713 - val_loss: 0.3654 - val_accuracy: 0.8732\n",
      "Epoch 9/30\n",
      "1719/1719 [==============================] - 9s 5ms/step - loss: 0.3519 - accuracy: 0.8744 - val_loss: 0.3712 - val_accuracy: 0.8652\n",
      "Epoch 10/30\n",
      "1719/1719 [==============================] - 11s 6ms/step - loss: 0.3412 - accuracy: 0.8792 - val_loss: 0.3451 - val_accuracy: 0.8790\n",
      "Epoch 11/30\n",
      "1719/1719 [==============================] - 9s 5ms/step - loss: 0.3319 - accuracy: 0.8821 - val_loss: 0.3557 - val_accuracy: 0.8748\n",
      "Epoch 12/30\n",
      "1719/1719 [==============================] - 9s 5ms/step - loss: 0.3255 - accuracy: 0.8835 - val_loss: 0.3549 - val_accuracy: 0.8758\n",
      "Epoch 13/30\n",
      "1719/1719 [==============================] - 11s 6ms/step - loss: 0.3169 - accuracy: 0.8866 - val_loss: 0.3512 - val_accuracy: 0.8722\n",
      "Epoch 14/30\n",
      "1719/1719 [==============================] - 11s 6ms/step - loss: 0.3104 - accuracy: 0.8878 - val_loss: 0.3417 - val_accuracy: 0.8754\n",
      "Epoch 15/30\n",
      "1719/1719 [==============================] - 9s 5ms/step - loss: 0.3037 - accuracy: 0.8906 - val_loss: 0.3359 - val_accuracy: 0.8798\n",
      "Epoch 16/30\n",
      "1719/1719 [==============================] - 10s 6ms/step - loss: 0.2979 - accuracy: 0.8927 - val_loss: 0.3185 - val_accuracy: 0.8846\n",
      "Epoch 17/30\n",
      "1719/1719 [==============================] - 11s 7ms/step - loss: 0.2919 - accuracy: 0.8950 - val_loss: 0.3200 - val_accuracy: 0.8872\n",
      "Epoch 18/30\n",
      "1719/1719 [==============================] - 9s 5ms/step - loss: 0.2855 - accuracy: 0.8970 - val_loss: 0.3214 - val_accuracy: 0.8866\n",
      "Epoch 19/30\n",
      "1719/1719 [==============================] - 9s 5ms/step - loss: 0.2803 - accuracy: 0.8988 - val_loss: 0.3106 - val_accuracy: 0.8874\n",
      "Epoch 20/30\n",
      "1719/1719 [==============================] - 10s 6ms/step - loss: 0.2748 - accuracy: 0.9002 - val_loss: 0.3352 - val_accuracy: 0.8806\n",
      "Epoch 21/30\n",
      "1719/1719 [==============================] - 10s 6ms/step - loss: 0.2697 - accuracy: 0.9037 - val_loss: 0.3136 - val_accuracy: 0.8830\n",
      "Epoch 22/30\n",
      "1719/1719 [==============================] - 10s 6ms/step - loss: 0.2647 - accuracy: 0.9052 - val_loss: 0.3067 - val_accuracy: 0.8898\n",
      "Epoch 23/30\n",
      "1719/1719 [==============================] - 11s 6ms/step - loss: 0.2600 - accuracy: 0.9063 - val_loss: 0.3031 - val_accuracy: 0.8912\n",
      "Epoch 24/30\n",
      "1719/1719 [==============================] - 11s 6ms/step - loss: 0.2562 - accuracy: 0.9073 - val_loss: 0.3315 - val_accuracy: 0.8820\n",
      "Epoch 25/30\n",
      "1719/1719 [==============================] - 11s 6ms/step - loss: 0.2521 - accuracy: 0.9104 - val_loss: 0.3299 - val_accuracy: 0.8840\n",
      "Epoch 26/30\n",
      "1719/1719 [==============================] - 10s 6ms/step - loss: 0.2475 - accuracy: 0.9105 - val_loss: 0.3052 - val_accuracy: 0.8878\n",
      "Epoch 27/30\n",
      "1719/1719 [==============================] - 11s 6ms/step - loss: 0.2432 - accuracy: 0.9122 - val_loss: 0.3142 - val_accuracy: 0.8880\n",
      "Epoch 28/30\n",
      "1719/1719 [==============================] - 10s 6ms/step - loss: 0.2397 - accuracy: 0.9135 - val_loss: 0.2930 - val_accuracy: 0.8938\n",
      "Epoch 29/30\n",
      "1719/1719 [==============================] - 9s 5ms/step - loss: 0.2355 - accuracy: 0.9148 - val_loss: 0.3035 - val_accuracy: 0.8918\n",
      "Epoch 30/30\n",
      "1719/1719 [==============================] - 11s 6ms/step - loss: 0.2316 - accuracy: 0.9161 - val_loss: 0.3006 - val_accuracy: 0.8896\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, epochs=30, validation_data=(X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'verbose': 1, 'epochs': 30, 'steps': 1719}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history.params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29]\n"
     ]
    }
   ],
   "source": [
    "print(history.epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history.history.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "pd.DataFrame(history.history).plot(figsize=(8, 5))\n",
    "plt.grid(True)\n",
    "plt.gca().set_ylim(0, 1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 2s 6ms/step - loss: 0.3306 - accuracy: 0.8793\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.33063945174217224, 0.8792999982833862]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.01, 0.  , 0.99],\n",
       "       [0.  , 0.  , 1.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ],\n",
       "       [0.  , 1.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_new = X_test[:3]\n",
    "y_proba = model.predict(X_new)\n",
    "y_proba.round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-29-81ace37e545f>:1: Sequential.predict_classes (from tensorflow.python.keras.engine.sequential) is deprecated and will be removed after 2021-01-01.\n",
      "Instructions for updating:\n",
      "Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([9, 2, 1], dtype=int64)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = model.predict_classes(X_new)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Ankle boot', 'Pullover', 'Trouser'], dtype='<U11')"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(class_names)[y_pred]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([9, 2, 1], dtype=uint8)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_new = y_test[:3]\n",
    "y_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 518.4x172.8 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(7.2, 2.4))\n",
    "for index, image in enumerate(X_new):\n",
    "    plt.subplot(1, 3, index + 1)\n",
    "    plt.imshow(image, cmap=\"binary\", interpolation=\"nearest\")\n",
    "    plt.axis('off')\n",
    "    plt.title(class_names[y_test[index]], fontsize=12)\n",
    "plt.subplots_adjust(wspace=0.2, hspace=0.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Building an Regression modelusing the sequential API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "housing = fetch_california_housing()\n",
    "\n",
    "X_train_full, X_test, y_train_full, y_test = train_test_split(housing.data, housing.target, random_state=42)\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X_train_full, y_train_full, random_state=42)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_valid = scaler.transform(X_valid)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "362/363 [============================>.] - ETA: 0s - loss: 2.0335WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0000s vs `on_test_batch_end` time: 0.0040s). Check your callbacks.\n",
      "363/363 [==============================] - 2s 6ms/step - loss: 2.0316 - val_loss: 1.4573\n",
      "Epoch 2/20\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.8999 - val_loss: 0.7982\n",
      "Epoch 3/20\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.7768 - val_loss: 0.7328\n",
      "Epoch 4/20\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.7214 - val_loss: 0.7506\n",
      "Epoch 5/20\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.6790 - val_loss: 0.7030\n",
      "Epoch 6/20\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.6414 - val_loss: 0.6671\n",
      "Epoch 7/20\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.6092 - val_loss: 0.5919\n",
      "Epoch 8/20\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.5807 - val_loss: 0.5702\n",
      "Epoch 9/20\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.5564 - val_loss: 0.5726\n",
      "Epoch 10/20\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.5367 - val_loss: 0.5360\n",
      "Epoch 11/20\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.5199 - val_loss: 0.5213\n",
      "Epoch 12/20\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.5061 - val_loss: 0.4888\n",
      "Epoch 13/20\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.4945 - val_loss: 0.4779\n",
      "Epoch 14/20\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.4846 - val_loss: 0.4611\n",
      "Epoch 15/20\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.4761 - val_loss: 0.4458\n",
      "Epoch 16/20\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.4689 - val_loss: 0.4377\n",
      "Epoch 17/20\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.4626 - val_loss: 0.4302\n",
      "Epoch 18/20\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.4570 - val_loss: 0.4248\n",
      "Epoch 19/20\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.4521 - val_loss: 0.4232\n",
      "Epoch 20/20\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.4480 - val_loss: 0.4163\n",
      "162/162 [==============================] - 0s 3ms/step - loss: 0.4334\n"
     ]
    }
   ],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Dense(30, activation=\"relu\", input_shape=X_train.shape[1:]),\n",
    "    keras.layers.Dense(1)\n",
    "])\n",
    "model.compile(loss=\"mean_squared_error\", optimizer=keras.optimizers.SGD(lr=1e-3))\n",
    "history = model.fit(X_train, y_train, epochs=20, validation_data=(X_valid, y_valid))\n",
    "mse_test = model.evaluate(X_test, y_test)\n",
    "X_new = X_test[:3]\n",
    "y_pred = model.predict(X_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(pd.DataFrame(history.history))\n",
    "plt.grid(True)\n",
    "plt.gca().set_ylim(0, 1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.81849664],\n",
       "       [1.6877646 ],\n",
       "       [3.010167  ]], dtype=float32)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functional API\n",
    "\n",
    "#### Building complex models using the Functional API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"Imagens/widedeep.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ = keras.layers.Input(shape=X_train.shape[1:])\n",
    "hidden1 = keras.layers.Dense(30, activation=\"relu\")(input_)\n",
    "hidden2 = keras.layers.Dense(30, activation=\"relu\")(hidden1)\n",
    "concat = keras.layers.concatenate([input_, hidden2])\n",
    "output = keras.layers.Dense(1)(concat)\n",
    "model = keras.models.Model(inputs=[input_], outputs=[output])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 8)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_8 (Dense)                 (None, 30)           270         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_9 (Dense)                 (None, 30)           930         dense_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 38)           0           input_1[0][0]                    \n",
      "                                                                 dense_9[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_10 (Dense)                (None, 1)            39          concatenate[0][0]                \n",
      "==================================================================================================\n",
      "Total params: 1,239\n",
      "Trainable params: 1,239\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "363/363 [==============================] - 2s 6ms/step - loss: 1.5668 - val_loss: 0.8839\n",
      "Epoch 2/20\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.7364 - val_loss: 0.6948\n",
      "Epoch 3/20\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.6707 - val_loss: 0.6404\n",
      "Epoch 4/20\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.6277 - val_loss: 0.5911\n",
      "Epoch 5/20\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.5946 - val_loss: 0.5602\n",
      "Epoch 6/20\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.5679 - val_loss: 0.5888\n",
      "Epoch 7/20\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.5472 - val_loss: 0.5103\n",
      "Epoch 8/20\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.5291 - val_loss: 0.5139\n",
      "Epoch 9/20\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.5137 - val_loss: 0.5168\n",
      "Epoch 10/20\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.5010 - val_loss: 0.4724\n",
      "Epoch 11/20\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.4896 - val_loss: 0.5118\n",
      "Epoch 12/20\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.4809 - val_loss: 0.4522\n",
      "Epoch 13/20\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.4721 - val_loss: 0.4781\n",
      "Epoch 14/20\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.4651 - val_loss: 0.4421\n",
      "Epoch 15/20\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.4583 - val_loss: 0.4412\n",
      "Epoch 16/20\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.4528 - val_loss: 0.4223\n",
      "Epoch 17/20\n",
      "363/363 [==============================] - 2s 6ms/step - loss: 0.4474 - val_loss: 0.4439\n",
      "Epoch 18/20\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.4426 - val_loss: 0.4124\n",
      "Epoch 19/20\n",
      "363/363 [==============================] - 2s 6ms/step - loss: 0.4384 - val_loss: 0.4358\n",
      "Epoch 20/20\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.4341 - val_loss: 0.4105\n",
      "162/162 [==============================] - 0s 3ms/step - loss: 0.4405\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss=\"mean_squared_error\", optimizer=keras.optimizers.SGD(lr=1e-3))\n",
    "history = model.fit(X_train, y_train, epochs=20,\n",
    "                    validation_data=(X_valid, y_valid))\n",
    "mse_test = model.evaluate(X_test, y_test)\n",
    "y_pred = model.predict(X_new)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"Imagens/manyinput.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_A = keras.layers.Input(shape=[5], name=\"wide_input\")\n",
    "input_B = keras.layers.Input(shape=[6], name=\"deep_input\")\n",
    "hidden1 = keras.layers.Dense(30, activation=\"relu\")(input_B)\n",
    "hidden2 = keras.layers.Dense(30, activation=\"relu\")(hidden1)\n",
    "concat = keras.layers.concatenate([input_A, hidden2])\n",
    "output = keras.layers.Dense(1, name=\"output\")(concat)\n",
    "model = keras.models.Model(inputs=[input_A, input_B], outputs=[output])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "363/363 [==============================] - 2s 6ms/step - loss: 2.3570 - val_loss: 1.7819\n",
      "Epoch 2/20\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.7944 - val_loss: 0.6854\n",
      "Epoch 3/20\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.6996 - val_loss: 0.6288\n",
      "Epoch 4/20\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.6543 - val_loss: 0.5930\n",
      "Epoch 5/20\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.6187 - val_loss: 0.5891\n",
      "Epoch 6/20\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.5884 - val_loss: 0.5509\n",
      "Epoch 7/20\n",
      "363/363 [==============================] - 2s 6ms/step - loss: 0.5597 - val_loss: 0.5078\n",
      "Epoch 8/20\n",
      "363/363 [==============================] - 2s 6ms/step - loss: 0.5352 - val_loss: 0.5055\n",
      "Epoch 9/20\n",
      "363/363 [==============================] - 2s 6ms/step - loss: 0.5126 - val_loss: 0.4870\n",
      "Epoch 10/20\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.4957 - val_loss: 0.6019\n",
      "Epoch 11/20\n",
      "363/363 [==============================] - 2s 6ms/step - loss: 0.4799 - val_loss: 0.4431\n",
      "Epoch 12/20\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.4675 - val_loss: 0.4303\n",
      "Epoch 13/20\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.4566 - val_loss: 0.4235\n",
      "Epoch 14/20\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.4490 - val_loss: 0.4062\n",
      "Epoch 15/20\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.4416 - val_loss: 0.4034\n",
      "Epoch 16/20\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.4370 - val_loss: 0.4032\n",
      "Epoch 17/20\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.4321 - val_loss: 0.3926\n",
      "Epoch 18/20\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.4284 - val_loss: 0.4155\n",
      "Epoch 19/20\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.4252 - val_loss: 0.3881\n",
      "Epoch 20/20\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.4223 - val_loss: 0.3848\n",
      "162/162 [==============================] - 1s 3ms/step - loss: 0.4129\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss=\"mse\", optimizer=keras.optimizers.SGD(lr=1e-3))\n",
    "\n",
    "X_train_A, X_train_B = X_train[:, :5], X_train[:, 2:]\n",
    "X_valid_A, X_valid_B = X_valid[:, :5], X_valid[:, 2:]\n",
    "X_test_A, X_test_B = X_test[:, :5], X_test[:, 2:]\n",
    "X_new_A, X_new_B = X_test_A[:3], X_test_B[:3]\n",
    "\n",
    "history = model.fit((X_train_A, X_train_B), y_train, epochs=20,\n",
    "                    validation_data=((X_valid_A, X_valid_B), y_valid))\n",
    "mse_test = model.evaluate((X_test_A, X_test_B), y_test)\n",
    "y_pred = model.predict((X_new_A, X_new_B))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"Imagens/manyinmanyout.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_A = keras.layers.Input(shape=[5], name=\"wide_input\")\n",
    "input_B = keras.layers.Input(shape=[6], name=\"deep_input\")\n",
    "hidden1 = keras.layers.Dense(30, activation=\"relu\")(input_B)\n",
    "hidden2 = keras.layers.Dense(30, activation=\"relu\")(hidden1)\n",
    "concat = keras.layers.concatenate([input_A, hidden2])\n",
    "output = keras.layers.Dense(1, name=\"main_output\")(concat)\n",
    "aux_output = keras.layers.Dense(1, name=\"aux_output\")(hidden2)\n",
    "model = keras.models.Model(inputs=[input_A, input_B],\n",
    "                           outputs=[output, aux_output])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=[\"mse\", \"mse\"], loss_weights=[0.9, 0.1], optimizer=keras.optimizers.SGD(lr=1e-3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "363/363 [==============================] - 4s 10ms/step - loss: 2.1373 - main_output_loss: 1.9391 - aux_output_loss: 3.9211 - val_loss: 1.1017 - val_main_output_loss: 0.9004 - val_aux_output_loss: 2.9137\n",
      "Epoch 2/20\n",
      "363/363 [==============================] - 3s 9ms/step - loss: 0.9568 - main_output_loss: 0.7885 - aux_output_loss: 2.4718 - val_loss: 0.9150 - val_main_output_loss: 0.7255 - val_aux_output_loss: 2.6200\n",
      "Epoch 3/20\n",
      "363/363 [==============================] - 3s 9ms/step - loss: 0.8004 - main_output_loss: 0.6788 - aux_output_loss: 1.8947 - val_loss: 0.8389 - val_main_output_loss: 0.6339 - val_aux_output_loss: 2.6836\n",
      "Epoch 4/20\n",
      "363/363 [==============================] - 3s 10ms/step - loss: 0.7265 - main_output_loss: 0.6249 - aux_output_loss: 1.6410 - val_loss: 0.7918 - val_main_output_loss: 0.5876 - val_aux_output_loss: 2.6290\n",
      "Epoch 5/20\n",
      "363/363 [==============================] - 3s 9ms/step - loss: 0.6793 - main_output_loss: 0.5875 - aux_output_loss: 1.5061 - val_loss: 0.7439 - val_main_output_loss: 0.5550 - val_aux_output_loss: 2.4437\n",
      "Epoch 6/20\n",
      "363/363 [==============================] - 3s 10ms/step - loss: 0.6446 - main_output_loss: 0.5583 - aux_output_loss: 1.4206 - val_loss: 0.6956 - val_main_output_loss: 0.5247 - val_aux_output_loss: 2.2338\n",
      "Epoch 7/20\n",
      "363/363 [==============================] - 3s 10ms/step - loss: 0.6175 - main_output_loss: 0.5354 - aux_output_loss: 1.3563 - val_loss: 0.6549 - val_main_output_loss: 0.5012 - val_aux_output_loss: 2.0376\n",
      "Epoch 8/20\n",
      "363/363 [==============================] - 3s 9ms/step - loss: 0.5957 - main_output_loss: 0.5167 - aux_output_loss: 1.3069 - val_loss: 0.6212 - val_main_output_loss: 0.4842 - val_aux_output_loss: 1.8540\n",
      "Epoch 9/20\n",
      "363/363 [==============================] - 3s 9ms/step - loss: 0.5773 - main_output_loss: 0.5010 - aux_output_loss: 1.2642 - val_loss: 0.6022 - val_main_output_loss: 0.4767 - val_aux_output_loss: 1.7321\n",
      "Epoch 10/20\n",
      "363/363 [==============================] - 3s 9ms/step - loss: 0.5634 - main_output_loss: 0.4896 - aux_output_loss: 1.2281 - val_loss: 0.5748 - val_main_output_loss: 0.4618 - val_aux_output_loss: 1.5919\n",
      "Epoch 11/20\n",
      "363/363 [==============================] - 3s 9ms/step - loss: 0.5500 - main_output_loss: 0.4784 - aux_output_loss: 1.1947 - val_loss: 0.5573 - val_main_output_loss: 0.4534 - val_aux_output_loss: 1.4928\n",
      "Epoch 12/20\n",
      "363/363 [==============================] - 3s 9ms/step - loss: 0.5405 - main_output_loss: 0.4711 - aux_output_loss: 1.1654 - val_loss: 0.5521 - val_main_output_loss: 0.4557 - val_aux_output_loss: 1.4196\n",
      "Epoch 13/20\n",
      "363/363 [==============================] - 3s 10ms/step - loss: 0.5306 - main_output_loss: 0.4630 - aux_output_loss: 1.1388 - val_loss: 0.5469 - val_main_output_loss: 0.4572 - val_aux_output_loss: 1.3541\n",
      "Epoch 14/20\n",
      "363/363 [==============================] - 4s 10ms/step - loss: 0.5234 - main_output_loss: 0.4579 - aux_output_loss: 1.1132 - val_loss: 0.5353 - val_main_output_loss: 0.4523 - val_aux_output_loss: 1.2823\n",
      "Epoch 15/20\n",
      "363/363 [==============================] - 4s 10ms/step - loss: 0.5159 - main_output_loss: 0.4523 - aux_output_loss: 1.0887 - val_loss: 0.5174 - val_main_output_loss: 0.4397 - val_aux_output_loss: 1.2167\n",
      "Epoch 16/20\n",
      "363/363 [==============================] - 4s 10ms/step - loss: 0.5095 - main_output_loss: 0.4476 - aux_output_loss: 1.0666 - val_loss: 0.5247 - val_main_output_loss: 0.4514 - val_aux_output_loss: 1.1846\n",
      "Epoch 17/20\n",
      "363/363 [==============================] - 4s 10ms/step - loss: 0.5034 - main_output_loss: 0.4432 - aux_output_loss: 1.0457 - val_loss: 0.5000 - val_main_output_loss: 0.4309 - val_aux_output_loss: 1.1214\n",
      "Epoch 18/20\n",
      "363/363 [==============================] - 4s 10ms/step - loss: 0.4983 - main_output_loss: 0.4397 - aux_output_loss: 1.0262 - val_loss: 0.5023 - val_main_output_loss: 0.4368 - val_aux_output_loss: 1.0914\n",
      "Epoch 19/20\n",
      "363/363 [==============================] - 4s 10ms/step - loss: 0.4937 - main_output_loss: 0.4367 - aux_output_loss: 1.0065 - val_loss: 0.4922 - val_main_output_loss: 0.4301 - val_aux_output_loss: 1.0512\n",
      "Epoch 20/20\n",
      "363/363 [==============================] - 3s 9ms/step - loss: 0.4891 - main_output_loss: 0.4335 - aux_output_loss: 0.9893 - val_loss: 0.4788 - val_main_output_loss: 0.4194 - val_aux_output_loss: 1.0138\n"
     ]
    }
   ],
   "source": [
    "history = model.fit([X_train_A, X_train_B], [y_train, y_train], epochs=20,\n",
    "                    validation_data=([X_valid_A, X_valid_B], [y_valid, y_valid]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Subclassing API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WideAndDeepModel(keras.models.Model):\n",
    "    def __init__(self, units=30, activation=\"relu\", **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.hidden1 = keras.layers.Dense(units, activation=activation)\n",
    "        self.hidden2 = keras.layers.Dense(units, activation=activation)\n",
    "        self.main_output = keras.layers.Dense(1)\n",
    "        self.aux_output = keras.layers.Dense(1)\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        input_A, input_B = inputs\n",
    "        hidden1 = self.hidden1(input_B)\n",
    "        hidden2 = self.hidden2(hidden1)\n",
    "        concat = keras.layers.concatenate([input_A, hidden2])\n",
    "        main_output = self.main_output(concat)\n",
    "        aux_output = self.aux_output(hidden2)\n",
    "        return main_output, aux_output\n",
    "\n",
    "model = WideAndDeepModel(30, activation=\"relu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "363/363 [==============================] - 4s 10ms/step - loss: 2.1203 - output_1_loss: 1.7842 - output_2_loss: 5.1452 - val_loss: 6.2788 - val_output_1_loss: 6.0315 - val_output_2_loss: 8.5039\n",
      "Epoch 2/10\n",
      "363/363 [==============================] - 3s 9ms/step - loss: 1.0294 - output_1_loss: 0.7800 - output_2_loss: 3.2742 - val_loss: 1.4334 - val_output_1_loss: 0.8452 - val_output_2_loss: 6.7274\n",
      "Epoch 3/10\n",
      "363/363 [==============================] - 4s 10ms/step - loss: 0.8144 - output_1_loss: 0.6547 - output_2_loss: 2.2515 - val_loss: 1.2452 - val_output_1_loss: 0.6167 - val_output_2_loss: 6.9017\n",
      "Epoch 4/10\n",
      "363/363 [==============================] - 3s 9ms/step - loss: 0.7186 - output_1_loss: 0.6024 - output_2_loss: 1.7646 - val_loss: 1.1912 - val_output_1_loss: 0.5550 - val_output_2_loss: 6.9167\n",
      "Epoch 5/10\n",
      "363/363 [==============================] - 3s 9ms/step - loss: 0.6611 - output_1_loss: 0.5646 - output_2_loss: 1.5298 - val_loss: 1.1200 - val_output_1_loss: 0.5166 - val_output_2_loss: 6.5500\n",
      "Epoch 6/10\n",
      "363/363 [==============================] - 3s 8ms/step - loss: 0.6230 - output_1_loss: 0.5363 - output_2_loss: 1.4030 - val_loss: 1.0425 - val_output_1_loss: 0.4935 - val_output_2_loss: 5.9829\n",
      "Epoch 7/10\n",
      "363/363 [==============================] - 3s 9ms/step - loss: 0.5954 - output_1_loss: 0.5145 - output_2_loss: 1.3241 - val_loss: 0.9571 - val_output_1_loss: 0.4759 - val_output_2_loss: 5.2877\n",
      "Epoch 8/10\n",
      "363/363 [==============================] - 4s 10ms/step - loss: 0.5744 - output_1_loss: 0.4975 - output_2_loss: 1.2666 - val_loss: 0.8751 - val_output_1_loss: 0.4640 - val_output_2_loss: 4.5742\n",
      "Epoch 9/10\n",
      "363/363 [==============================] - 3s 9ms/step - loss: 0.5581 - output_1_loss: 0.4847 - output_2_loss: 1.2183 - val_loss: 0.8184 - val_output_1_loss: 0.4703 - val_output_2_loss: 3.9511\n",
      "Epoch 10/10\n",
      "363/363 [==============================] - 3s 9ms/step - loss: 0.5449 - output_1_loss: 0.4745 - output_2_loss: 1.1785 - val_loss: 0.7594 - val_output_1_loss: 0.4679 - val_output_2_loss: 3.3827\n",
      "162/162 [==============================] - 1s 5ms/step - loss: 0.5266 - output_1_loss: 0.4591 - output_2_loss: 1.1337\n",
      "WARNING:tensorflow:5 out of the last 6 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000001AA8C2010D8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss=\"mse\", loss_weights=[0.9, 0.1], optimizer=keras.optimizers.SGD(lr=1e-3))\n",
    "history = model.fit((X_train_A, X_train_B), (y_train, y_train), epochs=10,\n",
    "                    validation_data=((X_valid_A, X_valid_B), (y_valid, y_valid)))\n",
    "total_loss, main_loss, aux_loss = model.evaluate((X_test_A, X_test_B), (y_test, y_test))\n",
    "y_pred_main, y_pred_aux = model.predict((X_new_A, X_new_B))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving and Restoring Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Dense(30, activation=\"relu\", input_shape=[8]),\n",
    "    keras.layers.Dense(30, activation=\"relu\"),\n",
    "    keras.layers.Dense(1)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "363/363 [==============================] - 2s 6ms/step - loss: 1.9017 - val_loss: 1.0421\n",
      "Epoch 2/10\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.8238 - val_loss: 0.9994\n",
      "Epoch 3/10\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.7430 - val_loss: 0.8083\n",
      "Epoch 4/10\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.6815 - val_loss: 0.9570\n",
      "Epoch 5/10\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.6453 - val_loss: 0.6522\n",
      "Epoch 6/10\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.6045 - val_loss: 0.8748\n",
      "Epoch 7/10\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.5785 - val_loss: 0.7298\n",
      "Epoch 8/10\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.5485 - val_loss: 0.5219\n",
      "Epoch 9/10\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.5247 - val_loss: 0.4999\n",
      "Epoch 10/10\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.5028 - val_loss: 0.4758\n",
      "  1/162 [..............................] - ETA: 0s - loss: 0.5453WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0000s vs `on_test_batch_end` time: 0.0040s). Check your callbacks.\n",
      "162/162 [==============================] - 0s 3ms/step - loss: 0.4861\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss=\"mse\", optimizer=keras.optimizers.SGD(lr=1e-3))\n",
    "history = model.fit(X_train, y_train, epochs=10, validation_data=(X_valid, y_valid))\n",
    "mse_test = model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"my_keras_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.load_model(\"my_keras_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:6 out of the last 7 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000001AAA719DE58> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.75836647],\n",
       "       [1.3281429 ],\n",
       "       [2.9775898 ]], dtype=float32)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(X_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights(\"my_keras_weights.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x1aaa70d0488>"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_weights(\"my_keras_weights.ckpt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Dense(30, activation=\"relu\", input_shape=[8]),\n",
    "    keras.layers.Dense(30, activation=\"relu\"),\n",
    "    keras.layers.Dense(1)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "363/363 [==============================] - 2s 6ms/step - loss: 1.5228 - val_loss: 1.4280\n",
      "Epoch 2/10\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.6557 - val_loss: 0.6196\n",
      "Epoch 3/10\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.5782 - val_loss: 0.5239\n",
      "Epoch 4/10\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.5304 - val_loss: 0.4818\n",
      "Epoch 5/10\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.4965 - val_loss: 0.4571\n",
      "Epoch 6/10\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.4712 - val_loss: 0.4340\n",
      "Epoch 7/10\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.4528 - val_loss: 0.4489\n",
      "Epoch 8/10\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.4399 - val_loss: 0.4213\n",
      "Epoch 9/10\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.4302 - val_loss: 0.4481\n",
      "Epoch 10/10\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.4225 - val_loss: 0.4816\n",
      "162/162 [==============================] - 0s 3ms/step - loss: 0.4239\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss=\"mse\", optimizer=keras.optimizers.SGD(lr=1e-3))\n",
    "checkpoint_cb = keras.callbacks.ModelCheckpoint(\"my_keras_model.h5\", save_best_only=True)\n",
    "history = model.fit(X_train, y_train, epochs=10,\n",
    "                    validation_data=(X_valid, y_valid),\n",
    "                    callbacks=[checkpoint_cb])\n",
    "model = keras.models.load_model(\"my_keras_model.h5\") # rollback to best model\n",
    "mse_test = model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.4300 - val_loss: 0.4246\n",
      "Epoch 2/100\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.4229 - val_loss: 0.4051\n",
      "Epoch 3/100\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.4169 - val_loss: 0.4277\n",
      "Epoch 4/100\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.4119 - val_loss: 0.4067\n",
      "Epoch 5/100\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.4075 - val_loss: 0.3791\n",
      "Epoch 6/100\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.4039 - val_loss: 0.3955\n",
      "Epoch 7/100\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.4004 - val_loss: 0.3748\n",
      "Epoch 8/100\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.3974 - val_loss: 0.4173\n",
      "Epoch 9/100\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.3948 - val_loss: 0.3862\n",
      "Epoch 10/100\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.3922 - val_loss: 0.3784\n",
      "Epoch 11/100\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.3894 - val_loss: 0.3633\n",
      "Epoch 12/100\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.3875 - val_loss: 0.3734\n",
      "Epoch 13/100\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.3849 - val_loss: 0.4166\n",
      "Epoch 14/100\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.3834 - val_loss: 0.3703\n",
      "Epoch 15/100\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.3812 - val_loss: 0.3711\n",
      "Epoch 16/100\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.3792 - val_loss: 0.4466\n",
      "Epoch 17/100\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.3783 - val_loss: 0.3609\n",
      "Epoch 18/100\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.3759 - val_loss: 0.4118\n",
      "Epoch 19/100\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.3747 - val_loss: 0.3497\n",
      "Epoch 20/100\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.3726 - val_loss: 0.4295\n",
      "Epoch 21/100\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.3724 - val_loss: 0.3517\n",
      "Epoch 22/100\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.3701 - val_loss: 0.3659\n",
      "Epoch 23/100\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.3686 - val_loss: 0.3466\n",
      "Epoch 24/100\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.3676 - val_loss: 0.3664\n",
      "Epoch 25/100\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.3663 - val_loss: 0.3873\n",
      "Epoch 26/100\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.3657 - val_loss: 0.3439\n",
      "Epoch 27/100\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.3640 - val_loss: 0.3941\n",
      "Epoch 28/100\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.3634 - val_loss: 0.3577\n",
      "Epoch 29/100\n",
      "363/363 [==============================] - 2s 6ms/step - loss: 0.3620 - val_loss: 0.3664\n",
      "Epoch 30/100\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.3607 - val_loss: 0.3532\n",
      "Epoch 31/100\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.3598 - val_loss: 0.3928\n",
      "Epoch 32/100\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.3589 - val_loss: 0.3489\n",
      "Epoch 33/100\n",
      "363/363 [==============================] - 2s 6ms/step - loss: 0.3580 - val_loss: 0.3380\n",
      "Epoch 34/100\n",
      "363/363 [==============================] - 2s 6ms/step - loss: 0.3571 - val_loss: 0.3684\n",
      "Epoch 35/100\n",
      "363/363 [==============================] - 2s 6ms/step - loss: 0.3561 - val_loss: 0.3494\n",
      "Epoch 36/100\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.3553 - val_loss: 0.3392\n",
      "Epoch 37/100\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.3545 - val_loss: 0.4400\n",
      "Epoch 38/100\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.3539 - val_loss: 0.3370\n",
      "Epoch 39/100\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.3527 - val_loss: 0.4404\n",
      "Epoch 40/100\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.3524 - val_loss: 0.3604\n",
      "Epoch 41/100\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.3512 - val_loss: 0.3939\n",
      "Epoch 42/100\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.3507 - val_loss: 0.3780\n",
      "Epoch 43/100\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.3498 - val_loss: 0.3833\n",
      "Epoch 44/100\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.3493 - val_loss: 0.3332\n",
      "Epoch 45/100\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.3484 - val_loss: 0.3848\n",
      "Epoch 46/100\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.3480 - val_loss: 0.3351\n",
      "Epoch 47/100\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.3474 - val_loss: 0.3795\n",
      "Epoch 48/100\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.3469 - val_loss: 0.3395\n",
      "Epoch 49/100\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.3461 - val_loss: 0.3433\n",
      "Epoch 50/100\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.3459 - val_loss: 0.3887\n",
      "Epoch 51/100\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.3450 - val_loss: 0.3408\n",
      "Epoch 52/100\n",
      "363/363 [==============================] - 2s 6ms/step - loss: 0.3444 - val_loss: 0.3409\n",
      "Epoch 53/100\n",
      "363/363 [==============================] - 2s 6ms/step - loss: 0.3438 - val_loss: 0.3992\n",
      "Epoch 54/100\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.3433 - val_loss: 0.4318\n",
      "162/162 [==============================] - 0s 3ms/step - loss: 0.3483\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss=\"mse\", optimizer=keras.optimizers.SGD(lr=1e-3))\n",
    "early_stopping_cb = keras.callbacks.EarlyStopping(patience=10,\n",
    "                                                  restore_best_weights=True)\n",
    "history = model.fit(X_train, y_train, epochs=100,\n",
    "                    validation_data=(X_valid, y_valid),\n",
    "                    callbacks=[checkpoint_cb, early_stopping_cb])\n",
    "mse_test = model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PrintValTrainRatioCallback(keras.callbacks.Callback):\n",
    "    def on_epoch_end(self, epoch, logs):\n",
    "        print(\" - val/train ratio: {:.2f}\".format(logs[\"val_loss\"] / logs[\"loss\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "362/363 [============================>.] - ETA: 0s - loss: 0.3482 - val/train ratio: 1.05\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.3485 - val_loss: 0.3648\n",
      "Epoch 2/10\n",
      "363/363 [==============================] - ETA: 0s - loss: 0.3482 - val/train ratio: 0.95\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.3482 - val_loss: 0.3322\n",
      "Epoch 3/10\n",
      "360/363 [============================>.] - ETA: 0s - loss: 0.3484 - val/train ratio: 0.99\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.3475 - val_loss: 0.3451\n",
      "Epoch 4/10\n",
      "356/363 [============================>.] - ETA: 0s - loss: 0.3476 - val/train ratio: 1.15\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.3469 - val_loss: 0.3981\n",
      "Epoch 5/10\n",
      "355/363 [============================>.] - ETA: 0s - loss: 0.3471 - val/train ratio: 1.07\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.3464 - val_loss: 0.3711\n",
      "Epoch 6/10\n",
      "355/363 [============================>.] - ETA: 0s - loss: 0.3470 - val/train ratio: 1.23\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.3456 - val_loss: 0.4265\n",
      "Epoch 7/10\n",
      "360/363 [============================>.] - ETA: 0s - loss: 0.3453 - val/train ratio: 1.04\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.3450 - val_loss: 0.3572\n",
      "Epoch 8/10\n",
      "351/363 [============================>.] - ETA: 0s - loss: 0.3453 - val/train ratio: 1.10\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.3443 - val_loss: 0.3796\n",
      "Epoch 9/10\n",
      "356/363 [============================>.] - ETA: 0s - loss: 0.3421 - val/train ratio: 0.97\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.3441 - val_loss: 0.3334\n",
      "Epoch 10/10\n",
      "363/363 [==============================] - ETA: 0s - loss: 0.3433 - val/train ratio: 1.08\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.3433 - val_loss: 0.3711\n"
     ]
    }
   ],
   "source": [
    "val_train_ratio_cb = PrintValTrainRatioCallback()\n",
    "history = model.fit(X_train, y_train, epochs=10,\n",
    "                    validation_data=(X_valid, y_valid),\n",
    "                    callbacks=[val_train_ratio_cb])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using TensorBoard for Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "root_logdir = os.path.join(os.curdir, \"my_logs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'.\\\\my_logs\\\\run_2021_01_13-19_56_17'"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_run_logdir():\n",
    "    import time\n",
    "    run_id = time.strftime(\"run_%Y_%m_%d-%H_%M_%S\")\n",
    "    return os.path.join(root_logdir, run_id)\n",
    "\n",
    "run_logdir = get_run_logdir()\n",
    "run_logdir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Dense(30, activation=\"relu\", input_shape=[8]),\n",
    "    keras.layers.Dense(30, activation=\"relu\"),\n",
    "    keras.layers.Dense(1)\n",
    "])    \n",
    "model.compile(loss=\"mse\", optimizer=keras.optimizers.SGD(lr=1e-3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "  1/363 [..............................] - ETA: 0s - loss: 9.0131WARNING:tensorflow:From c:\\users\\artur\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\ops\\summary_ops_v2.py:1277: stop (from tensorflow.python.eager.profiler) is deprecated and will be removed after 2020-07-01.\n",
      "Instructions for updating:\n",
      "use `tf.profiler.experimental.stop` instead.\n",
      "  2/363 [..............................] - ETA: 1:24 - loss: 8.9112WARNING:tensorflow:Callbacks method `on_train_batch_begin` is slow compared to the batch time (batch time: 0.0120s vs `on_train_batch_begin` time: 0.0599s). Check your callbacks.\n",
      "WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0120s vs `on_train_batch_end` time: 0.3921s). Check your callbacks.\n",
      "363/363 [==============================] - 3s 8ms/step - loss: 2.8027 - val_loss: 1.1837\n",
      "Epoch 2/30\n",
      "363/363 [==============================] - 2s 6ms/step - loss: 0.7903 - val_loss: 0.6775\n",
      "Epoch 3/30\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.6706 - val_loss: 0.6520\n",
      "Epoch 4/30\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.6263 - val_loss: 0.6166\n",
      "Epoch 5/30\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.5931 - val_loss: 0.5517\n",
      "Epoch 6/30\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.5627 - val_loss: 0.5277\n",
      "Epoch 7/30\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.5365 - val_loss: 0.4887\n",
      "Epoch 8/30\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.5137 - val_loss: 0.4686\n",
      "Epoch 9/30\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.4933 - val_loss: 0.4778\n",
      "Epoch 10/30\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.4759 - val_loss: 0.4764\n",
      "Epoch 11/30\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.4619 - val_loss: 0.4285\n",
      "Epoch 12/30\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.4492 - val_loss: 0.4348\n",
      "Epoch 13/30\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.4387 - val_loss: 0.4094\n",
      "Epoch 14/30\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.4302 - val_loss: 0.4084\n",
      "Epoch 15/30\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.4227 - val_loss: 0.4004\n",
      "Epoch 16/30\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.4163 - val_loss: 0.3931\n",
      "Epoch 17/30\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.4111 - val_loss: 0.3875\n",
      "Epoch 18/30\n",
      "363/363 [==============================] - 2s 6ms/step - loss: 0.4063 - val_loss: 0.3856\n",
      "Epoch 19/30\n",
      "363/363 [==============================] - 2s 6ms/step - loss: 0.4023 - val_loss: 0.3802\n",
      "Epoch 20/30\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.3988 - val_loss: 0.3844\n",
      "Epoch 21/30\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.3952 - val_loss: 0.3985\n",
      "Epoch 22/30\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.3925 - val_loss: 0.3818\n",
      "Epoch 23/30\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.3896 - val_loss: 0.3792\n",
      "Epoch 24/30\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.3872 - val_loss: 0.3956\n",
      "Epoch 25/30\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.3850 - val_loss: 0.3811\n",
      "Epoch 26/30\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.3829 - val_loss: 0.3787\n",
      "Epoch 27/30\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.3810 - val_loss: 0.3951\n",
      "Epoch 28/30\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.3793 - val_loss: 0.4040\n",
      "Epoch 29/30\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.3776 - val_loss: 0.3851\n",
      "Epoch 30/30\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.3761 - val_loss: 0.3748\n"
     ]
    }
   ],
   "source": [
    "tensorboard_cb = keras.callbacks.TensorBoard(run_logdir)\n",
    "history = model.fit(X_train, y_train, epochs=30,\n",
    "                    validation_data=(X_valid, y_valid),\n",
    "                    callbacks=[checkpoint_cb, tensorboard_cb])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# tensorboard --logdir=./my_logs --port=6006\n",
    "\n",
    "### Fine-tuning Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(n_hidden=1, n_neurons=30, learning_rate=3e-3, input_shape=[8]):\n",
    "    model = keras.models.Sequential()\n",
    "    model.add(keras.layers.InputLayer(input_shape=input_shape))\n",
    "    for layer in range(n_hidden):\n",
    "        model.add(keras.layers.Dense(n_neurons, activation=\"relu\"))\n",
    "    model.add(keras.layers.Dense(1))\n",
    "    optimizer = keras.optimizers.SGD(lr=learning_rate)\n",
    "    model.compile(loss=\"mse\", optimizer=optimizer)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras_reg = keras.wrappers.scikit_learn.KerasRegressor(build_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "354/363 [============================>.] - ETA: 0s - loss: 1.6292WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0000s vs `on_test_batch_end` time: 0.0040s). Check your callbacks.\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 1.6070 - val_loss: 1.0081\n",
      "Epoch 2/100\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.5939 - val_loss: 0.5805\n",
      "Epoch 3/100\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.5266 - val_loss: 0.4765\n",
      "Epoch 4/100\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.4835 - val_loss: 0.4372\n",
      "Epoch 5/100\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.4582 - val_loss: 0.4217\n",
      "Epoch 6/100\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.4435 - val_loss: 0.4056\n",
      "Epoch 7/100\n",
      "363/363 [==============================] - 2s 4ms/step - loss: 0.4333 - val_loss: 0.3972\n",
      "Epoch 8/100\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.4261 - val_loss: 0.3935\n",
      "Epoch 9/100\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.4191 - val_loss: 0.3991\n",
      "Epoch 10/100\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.4151 - val_loss: 0.3904\n",
      "Epoch 11/100\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.4105 - val_loss: 0.3887\n",
      "Epoch 12/100\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.4067 - val_loss: 0.3899\n",
      "Epoch 13/100\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.4035 - val_loss: 0.3885\n",
      "Epoch 14/100\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.4005 - val_loss: 0.3835\n",
      "Epoch 15/100\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.3963 - val_loss: 0.3832\n",
      "Epoch 16/100\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.3946 - val_loss: 0.3788\n",
      "Epoch 17/100\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.3928 - val_loss: 0.3782\n",
      "Epoch 18/100\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.3903 - val_loss: 0.3825\n",
      "Epoch 19/100\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.3882 - val_loss: 0.3791\n",
      "Epoch 20/100\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.3861 - val_loss: 0.3785\n",
      "Epoch 21/100\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.3845 - val_loss: 0.3697\n",
      "Epoch 22/100\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.3829 - val_loss: 0.3743\n",
      "Epoch 23/100\n",
      "363/363 [==============================] - 2s 4ms/step - loss: 0.3810 - val_loss: 0.3888\n",
      "Epoch 24/100\n",
      "363/363 [==============================] - 2s 4ms/step - loss: 0.3800 - val_loss: 0.3757\n",
      "Epoch 25/100\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.3780 - val_loss: 0.3858\n",
      "Epoch 26/100\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.3768 - val_loss: 0.3734\n",
      "Epoch 27/100\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.3755 - val_loss: 0.3687\n",
      "Epoch 28/100\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.3744 - val_loss: 0.3692\n",
      "Epoch 29/100\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.3730 - val_loss: 0.3681\n",
      "Epoch 30/100\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.3718 - val_loss: 0.3781\n",
      "Epoch 31/100\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.3710 - val_loss: 0.3635\n",
      "Epoch 32/100\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.3696 - val_loss: 0.3815\n",
      "Epoch 33/100\n",
      "363/363 [==============================] - 2s 4ms/step - loss: 0.3688 - val_loss: 0.3846\n",
      "Epoch 34/100\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.3675 - val_loss: 0.3752\n",
      "Epoch 35/100\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.3668 - val_loss: 0.3861\n",
      "Epoch 36/100\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.3660 - val_loss: 0.3671\n",
      "Epoch 37/100\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.3651 - val_loss: 0.3592\n",
      "Epoch 38/100\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.3646 - val_loss: 0.3779\n",
      "Epoch 39/100\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.3636 - val_loss: 0.3649\n",
      "Epoch 40/100\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.3629 - val_loss: 0.3695\n",
      "Epoch 41/100\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.3621 - val_loss: 0.3856\n",
      "Epoch 42/100\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.3615 - val_loss: 0.3613\n",
      "Epoch 43/100\n",
      "363/363 [==============================] - 2s 4ms/step - loss: 0.3605 - val_loss: 0.3620\n",
      "Epoch 44/100\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.3594 - val_loss: 0.3723\n",
      "Epoch 45/100\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.3590 - val_loss: 0.3880\n",
      "Epoch 46/100\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.3586 - val_loss: 0.3592\n",
      "Epoch 47/100\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.3583 - val_loss: 0.3402\n",
      "Epoch 48/100\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.3576 - val_loss: 0.3971\n",
      "Epoch 49/100\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.3575 - val_loss: 0.3404\n",
      "Epoch 50/100\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.3561 - val_loss: 0.3935\n",
      "Epoch 51/100\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.3565 - val_loss: 0.3390\n",
      "Epoch 52/100\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.3556 - val_loss: 0.3408\n",
      "Epoch 53/100\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.3553 - val_loss: 0.3568\n",
      "Epoch 54/100\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.3551 - val_loss: 0.3478\n",
      "Epoch 55/100\n",
      "363/363 [==============================] - 2s 4ms/step - loss: 0.3542 - val_loss: 0.3391\n",
      "Epoch 56/100\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.3536 - val_loss: 0.3361\n",
      "Epoch 57/100\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.3531 - val_loss: 0.3378\n",
      "Epoch 58/100\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.3529 - val_loss: 0.3369\n",
      "Epoch 59/100\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.3521 - val_loss: 0.3345\n",
      "Epoch 60/100\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.3519 - val_loss: 0.4165\n",
      "Epoch 61/100\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.3523 - val_loss: 0.3378\n",
      "Epoch 62/100\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.3512 - val_loss: 0.3443\n",
      "Epoch 63/100\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.3507 - val_loss: 0.4401\n",
      "Epoch 64/100\n",
      "363/363 [==============================] - 2s 4ms/step - loss: 0.3508 - val_loss: 0.3325\n",
      "Epoch 65/100\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.3499 - val_loss: 0.3333\n",
      "Epoch 66/100\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.3497 - val_loss: 0.3457\n",
      "Epoch 67/100\n",
      "363/363 [==============================] - 2s 4ms/step - loss: 0.3489 - val_loss: 0.3340\n",
      "Epoch 68/100\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.3485 - val_loss: 0.3926\n",
      "Epoch 69/100\n",
      "363/363 [==============================] - 2s 4ms/step - loss: 0.3482 - val_loss: 0.3465\n",
      "Epoch 70/100\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.3477 - val_loss: 0.3345\n",
      "Epoch 71/100\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.3475 - val_loss: 0.3297\n",
      "Epoch 72/100\n",
      "363/363 [==============================] - 2s 4ms/step - loss: 0.3463 - val_loss: 0.3587\n",
      "Epoch 73/100\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.3465 - val_loss: 0.3361\n",
      "Epoch 74/100\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.3458 - val_loss: 0.3827\n",
      "Epoch 75/100\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.3457 - val_loss: 0.3330\n",
      "Epoch 76/100\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.3449 - val_loss: 0.3458\n",
      "Epoch 77/100\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.3446 - val_loss: 0.3278\n",
      "Epoch 78/100\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.3438 - val_loss: 0.3439\n",
      "Epoch 79/100\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.3436 - val_loss: 0.3320\n",
      "Epoch 80/100\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.3429 - val_loss: 0.3283\n",
      "Epoch 81/100\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.3425 - val_loss: 0.3394\n",
      "Epoch 82/100\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.3423 - val_loss: 0.3283\n",
      "Epoch 83/100\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.3415 - val_loss: 0.3955\n",
      "Epoch 84/100\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.3411 - val_loss: 0.3373\n",
      "Epoch 85/100\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.3407 - val_loss: 0.3380\n",
      "Epoch 86/100\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.3396 - val_loss: 0.4256\n",
      "Epoch 87/100\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.3401 - val_loss: 0.3248\n",
      "Epoch 88/100\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.3389 - val_loss: 0.3615\n",
      "Epoch 89/100\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.3391 - val_loss: 0.3965\n",
      "Epoch 90/100\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.3389 - val_loss: 0.3301\n",
      "Epoch 91/100\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.3375 - val_loss: 0.4439\n",
      "Epoch 92/100\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.3392 - val_loss: 0.3830\n",
      "Epoch 93/100\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.3381 - val_loss: 0.6449\n",
      "Epoch 94/100\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.3385 - val_loss: 0.3344\n",
      "Epoch 95/100\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.3358 - val_loss: 0.3828\n",
      "Epoch 96/100\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.3358 - val_loss: 0.3392\n",
      "Epoch 97/100\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.3348 - val_loss: 0.3751\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1aa8c01d648>"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keras_reg.fit(X_train, y_train, epochs=100,\n",
    "              validation_data=(X_valid, y_valid),\n",
    "              callbacks=[keras.callbacks.EarlyStopping(patience=10)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n",
      "[CV] learning_rate=0.003333910854886942, n_hidden=3, n_neurons=82 ....\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 2s 7ms/step - loss: 1.1639 - val_loss: 1.8441\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.5809 - val_loss: 1.0427\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.4811 - val_loss: 0.4584\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.4334 - val_loss: 0.4744\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.4071 - val_loss: 0.3795\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 0.3927 - val_loss: 0.4215\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 0.3809 - val_loss: 0.3651\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3721 - val_loss: 0.4846\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3665 - val_loss: 0.3650\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 0.3616 - val_loss: 0.3890\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.3565 - val_loss: 0.3512\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.3533 - val_loss: 0.3531\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3487 - val_loss: 0.3473\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3463 - val_loss: 0.4747\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3455 - val_loss: 0.3439\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3427 - val_loss: 0.3618\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3395 - val_loss: 0.3370\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3369 - val_loss: 0.3824\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3350 - val_loss: 0.3568\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3326 - val_loss: 0.3416\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3322 - val_loss: 0.3333\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 0.3297 - val_loss: 0.3352\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3284 - val_loss: 0.4978\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3281 - val_loss: 0.3236\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3230 - val_loss: 0.5556\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3259 - val_loss: 0.4511\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3237 - val_loss: 0.4809\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3214 - val_loss: 0.3196\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3192 - val_loss: 0.4001\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3180 - val_loss: 0.3274\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3171 - val_loss: 0.3471\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 0.3144 - val_loss: 0.3159\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 0.3131 - val_loss: 0.4028\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3129 - val_loss: 0.3131\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3106 - val_loss: 0.4265\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 0.3104 - val_loss: 0.3119\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3084 - val_loss: 0.4603\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3086 - val_loss: 0.5131\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3087 - val_loss: 0.7444\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3113 - val_loss: 0.3932\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3065 - val_loss: 0.4647\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3053 - val_loss: 0.3139\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3033 - val_loss: 0.5012\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3028 - val_loss: 0.3336\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3016 - val_loss: 0.4955\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3011 - val_loss: 0.2993\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.2983 - val_loss: 0.4209\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.2986 - val_loss: 0.3689\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.2983 - val_loss: 0.7434\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3004 - val_loss: 0.4189\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 0.2962 - val_loss: 0.6090\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.2958 - val_loss: 0.4320\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 0.2951 - val_loss: 0.6440\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.2946 - val_loss: 0.3542\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.2923 - val_loss: 0.5728\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.2936 - val_loss: 0.4074\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.2921 - val_loss: 0.5766\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.2925 - val_loss: 0.3561\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 0.2894 - val_loss: 0.4624\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.2887 - val_loss: 0.2958\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 0.2867 - val_loss: 0.3446\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.2866 - val_loss: 0.2916\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.2852 - val_loss: 0.3002\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 0.2847 - val_loss: 0.3382\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.2835 - val_loss: 0.3003\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.2833 - val_loss: 0.4432\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.2830 - val_loss: 0.2893\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 0.2809 - val_loss: 0.4144\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.2820 - val_loss: 0.2869\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.2805 - val_loss: 0.4443\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.2809 - val_loss: 0.2911\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.2794 - val_loss: 0.4272\n",
      "Epoch 73/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.2799 - val_loss: 0.4666\n",
      "Epoch 74/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.2814 - val_loss: 0.8172\n",
      "Epoch 75/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.2837 - val_loss: 0.3771\n",
      "Epoch 76/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 0.2787 - val_loss: 0.6660\n",
      "Epoch 77/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 0.2815 - val_loss: 0.5396\n",
      "Epoch 78/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 0.2817 - val_loss: 0.6977\n",
      "Epoch 79/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.2786 - val_loss: 0.3592\n",
      "Epoch 80/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.2756 - val_loss: 0.5007\n",
      "Epoch 81/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.2754 - val_loss: 0.3048\n",
      "Epoch 82/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.2755 - val_loss: 0.4552\n",
      "Epoch 83/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 0.2730 - val_loss: 0.2967\n",
      "Epoch 84/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 0.2723 - val_loss: 0.3352\n",
      "Epoch 85/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 0.2719 - val_loss: 0.3153\n",
      "Epoch 86/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.2707 - val_loss: 0.2853\n",
      "Epoch 87/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.2698 - val_loss: 0.3311\n",
      "Epoch 88/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.2699 - val_loss: 0.2990\n",
      "Epoch 89/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 0.2688 - val_loss: 0.3164\n",
      "Epoch 90/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.2685 - val_loss: 0.3349\n",
      "Epoch 91/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 0.2680 - val_loss: 0.2852\n",
      "Epoch 92/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.2672 - val_loss: 0.3208\n",
      "Epoch 93/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.2663 - val_loss: 0.2925\n",
      "Epoch 94/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.2671 - val_loss: 0.4963\n",
      "Epoch 95/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.2680 - val_loss: 0.2955\n",
      "Epoch 96/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.2648 - val_loss: 0.4419\n",
      "Epoch 97/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.2681 - val_loss: 0.3351\n",
      "Epoch 98/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.2669 - val_loss: 0.4911\n",
      "Epoch 99/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.2663 - val_loss: 0.3244\n",
      "Epoch 100/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.2642 - val_loss: 0.4257\n",
      "  1/121 [..............................] - ETA: 0s - loss: 0.4912WARNING:tensorflow:Callbacks method `on_test_batch_begin` is slow compared to the batch time (batch time: 0.0000s vs `on_test_batch_begin` time: 0.0040s). Check your callbacks.\n",
      "121/121 [==============================] - 0s 3ms/step - loss: 0.3127\n",
      "[CV]  learning_rate=0.003333910854886942, n_hidden=3, n_neurons=82, total= 2.5min\n",
      "[CV] learning_rate=0.003333910854886942, n_hidden=3, n_neurons=82 ....\n",
      "Epoch 1/100"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:  2.5min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "242/242 [==============================] - 2s 8ms/step - loss: 1.3243 - val_loss: 6.3925\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.6347 - val_loss: 0.6752\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 0.5398 - val_loss: 0.6240\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.4741 - val_loss: 0.9426\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 0.4330 - val_loss: 0.8384\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.4102 - val_loss: 0.6595\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.3963 - val_loss: 0.4823\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 0.3858 - val_loss: 0.3878\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3783 - val_loss: 0.3590\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.3717 - val_loss: 0.3713\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 0.3655 - val_loss: 0.5641\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 0.3615 - val_loss: 0.5420\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.3566 - val_loss: 0.6187\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.3524 - val_loss: 0.6063\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3485 - val_loss: 0.7247\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3453 - val_loss: 0.7892\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 0.3424 - val_loss: 0.8623\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.3393 - val_loss: 0.8311\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.3365 - val_loss: 0.6629\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.3338 - val_loss: 0.7468\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 0.3328 - val_loss: 0.7366\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 0.3307 - val_loss: 0.7477\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3289 - val_loss: 0.6726\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 0.3270 - val_loss: 0.6930\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 0.3248 - val_loss: 0.7634\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 0.3233 - val_loss: 0.6404\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 0.3210 - val_loss: 0.6337\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 0.3197 - val_loss: 0.7095\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3181 - val_loss: 0.7389\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3167 - val_loss: 0.7022\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3151 - val_loss: 0.6042\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3136 - val_loss: 0.6608\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3124 - val_loss: 0.5710\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 0.3114 - val_loss: 0.5142\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3090 - val_loss: 0.5136\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3067 - val_loss: 0.5017\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3062 - val_loss: 0.5483\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 0.3051 - val_loss: 0.5560\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 0.3039 - val_loss: 0.4823\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.3023 - val_loss: 0.3996\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 2s 8ms/step - loss: 0.3005 - val_loss: 0.5004\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.3002 - val_loss: 0.4252\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 0.2997 - val_loss: 0.3812\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.2980 - val_loss: 0.3624\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.2965 - val_loss: 0.4950\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 0.2954 - val_loss: 0.3825\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 0.2951 - val_loss: 0.4903\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.2938 - val_loss: 0.4239\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.2929 - val_loss: 0.3624\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.2914 - val_loss: 0.3611\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.2907 - val_loss: 0.3535\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.2898 - val_loss: 0.3849\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 0.2887 - val_loss: 0.3816\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 0.2874 - val_loss: 0.4404\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 0.2875 - val_loss: 0.4176\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 0.2869 - val_loss: 0.3953\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.2860 - val_loss: 0.3956\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 0.2847 - val_loss: 0.3310\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 0.2833 - val_loss: 0.5862\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 0.2833 - val_loss: 0.4866\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.2827 - val_loss: 0.3857\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 0.2810 - val_loss: 0.4593\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 0.2800 - val_loss: 0.4384\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 0.2801 - val_loss: 0.4278\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.2790 - val_loss: 0.4334\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 0.2783 - val_loss: 0.3527\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 0.2771 - val_loss: 0.4274\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 0.2765 - val_loss: 0.3956\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.2764 - val_loss: 0.4237\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.2750 - val_loss: 0.3932\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.2754 - val_loss: 0.4450\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.2742 - val_loss: 0.4332\n",
      "Epoch 73/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.2741 - val_loss: 0.3402\n",
      "Epoch 74/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.2733 - val_loss: 0.4270\n",
      "Epoch 75/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 0.2726 - val_loss: 0.4765\n",
      "Epoch 76/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.2721 - val_loss: 0.4333\n",
      "Epoch 77/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.2705 - val_loss: 0.4275\n",
      "Epoch 78/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.2704 - val_loss: 0.5263\n",
      "Epoch 79/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 0.2698 - val_loss: 0.4342\n",
      "Epoch 80/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 0.2693 - val_loss: 0.4238\n",
      "Epoch 81/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 0.2690 - val_loss: 0.5085\n",
      "Epoch 82/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 0.2683 - val_loss: 0.3387\n",
      "Epoch 83/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.2685 - val_loss: 0.5325\n",
      "Epoch 84/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.2678 - val_loss: 0.3684\n",
      "Epoch 85/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 0.2661 - val_loss: 0.4590\n",
      "Epoch 86/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.2664 - val_loss: 0.4953\n",
      "Epoch 87/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.2659 - val_loss: 0.4563\n",
      "Epoch 88/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.2653 - val_loss: 0.3408\n",
      "Epoch 89/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 0.2648 - val_loss: 0.3318\n",
      "Epoch 90/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.2649 - val_loss: 0.4683\n",
      "Epoch 91/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.2635 - val_loss: 0.3817\n",
      "Epoch 92/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.2646 - val_loss: 0.3055\n",
      "Epoch 93/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 0.2632 - val_loss: 0.4294\n",
      "Epoch 94/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.2622 - val_loss: 0.3702\n",
      "Epoch 95/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 0.2610 - val_loss: 0.3725\n",
      "Epoch 96/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.2621 - val_loss: 0.3069\n",
      "Epoch 97/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.2616 - val_loss: 0.3503\n",
      "Epoch 98/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.2607 - val_loss: 0.3170\n",
      "Epoch 99/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.2605 - val_loss: 0.3668\n",
      "Epoch 100/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.2602 - val_loss: 0.4257\n",
      "  1/121 [..............................] - ETA: 0s - loss: 0.1948WARNING:tensorflow:Callbacks method `on_test_batch_begin` is slow compared to the batch time (batch time: 0.0000s vs `on_test_batch_begin` time: 0.0040s). Check your callbacks.\n",
      "121/121 [==============================] - 0s 3ms/step - loss: 0.2980\n",
      "[CV]  learning_rate=0.003333910854886942, n_hidden=3, n_neurons=82, total= 2.6min\n",
      "[CV] learning_rate=0.003333910854886942, n_hidden=3, n_neurons=82 ....\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 2s 8ms/step - loss: 1.2944 - val_loss: 0.6645\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.6091 - val_loss: 0.5291\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.5243 - val_loss: 0.4648\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.4721 - val_loss: 0.4625\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.4377 - val_loss: 0.4260\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.4164 - val_loss: 0.4165\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 0.3981 - val_loss: 0.5004\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 0.3865 - val_loss: 0.3624\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3778 - val_loss: 0.3505\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 0.3699 - val_loss: 0.3483\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3649 - val_loss: 0.3491\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3599 - val_loss: 0.3481\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3550 - val_loss: 0.5560\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3550 - val_loss: 0.4246\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3521 - val_loss: 0.3504\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 0.3477 - val_loss: 0.3283\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 0.3438 - val_loss: 0.4174\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 0.3428 - val_loss: 0.5134\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 0.3447 - val_loss: 0.7350\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3437 - val_loss: 1.2240\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.3461 - val_loss: 0.5967\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.3396 - val_loss: 0.8070\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.3376 - val_loss: 0.6799\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3363 - val_loss: 0.4885\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3335 - val_loss: 0.3611\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 0.3287 - val_loss: 0.4233\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3274 - val_loss: 0.3453\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3259 - val_loss: 0.3444\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 0.3243 - val_loss: 0.3112\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3223 - val_loss: 0.3531\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3211 - val_loss: 0.3217\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3200 - val_loss: 0.3155\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 0.3176 - val_loss: 0.4433\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 0.3195 - val_loss: 0.3791\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 0.3164 - val_loss: 0.4920\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3160 - val_loss: 0.3098\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3149 - val_loss: 0.3961\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3126 - val_loss: 0.3245\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3117 - val_loss: 0.3455\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.3104 - val_loss: 0.3102\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 0.3087 - val_loss: 0.3878\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 0.3113 - val_loss: 0.3095\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.3076 - val_loss: 0.5573\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3088 - val_loss: 0.3767\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3066 - val_loss: 0.4576\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 0.3046 - val_loss: 0.3016\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 0.3032 - val_loss: 0.3759\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 0.3041 - val_loss: 0.3540\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3034 - val_loss: 0.5266\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3024 - val_loss: 0.3881\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 0.3017 - val_loss: 0.4815\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 0.2995 - val_loss: 0.3341\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 0.3014 - val_loss: 0.3782\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.2989 - val_loss: 0.2961\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 0.2973 - val_loss: 0.4468\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.2973 - val_loss: 0.2938\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 0.2979 - val_loss: 0.3636\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.2959 - val_loss: 0.2968\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.2941 - val_loss: 0.3221\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 0.2943 - val_loss: 0.3494\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 0.2943 - val_loss: 0.5116\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 0.2931 - val_loss: 0.3099\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.2914 - val_loss: 0.4031\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 0.2929 - val_loss: 0.2929\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.2901 - val_loss: 0.3454\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 0.2884 - val_loss: 0.2973\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 0.2893 - val_loss: 0.3133\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 0.2889 - val_loss: 0.2911\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 0.2886 - val_loss: 0.3904\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 0.2895 - val_loss: 0.5148\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 0.2917 - val_loss: 0.7447\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.2886 - val_loss: 0.5155\n",
      "Epoch 73/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.2870 - val_loss: 0.4338\n",
      "Epoch 74/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 0.2862 - val_loss: 0.3264\n",
      "Epoch 75/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.2847 - val_loss: 0.3743\n",
      "Epoch 76/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 0.2835 - val_loss: 0.3044\n",
      "Epoch 77/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 0.2826 - val_loss: 0.3703\n",
      "Epoch 78/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 0.2812 - val_loss: 0.2907\n",
      "Epoch 79/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 0.2805 - val_loss: 0.3390\n",
      "Epoch 80/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.2809 - val_loss: 0.3256\n",
      "Epoch 81/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 0.2805 - val_loss: 0.4625\n",
      "Epoch 82/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.2801 - val_loss: 0.3414\n",
      "Epoch 83/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 0.2789 - val_loss: 0.4543\n",
      "Epoch 84/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 0.2813 - val_loss: 0.3320\n",
      "Epoch 85/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.2785 - val_loss: 0.4498\n",
      "Epoch 86/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 0.2775 - val_loss: 0.2830\n",
      "Epoch 87/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.2780 - val_loss: 0.3565\n",
      "Epoch 88/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.2771 - val_loss: 0.2971\n",
      "Epoch 89/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.2736 - val_loss: 0.3058\n",
      "Epoch 90/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.2764 - val_loss: 0.3090\n",
      "Epoch 91/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.2735 - val_loss: 0.3589\n",
      "Epoch 92/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.2747 - val_loss: 0.3156\n",
      "Epoch 93/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.2750 - val_loss: 0.3776\n",
      "Epoch 94/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.2729 - val_loss: 0.2847\n",
      "Epoch 95/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.2733 - val_loss: 0.4309\n",
      "Epoch 96/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.2776 - val_loss: 0.2805\n",
      "Epoch 97/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.2705 - val_loss: 0.3661\n",
      "Epoch 98/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.2713 - val_loss: 0.2900\n",
      "Epoch 99/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.2695 - val_loss: 0.3312\n",
      "Epoch 100/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.2703 - val_loss: 0.2855\n",
      "  1/121 [..............................] - ETA: 0s - loss: 0.2431WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0000s vs `on_test_batch_end` time: 0.0040s). Check your callbacks.\n",
      "121/121 [==============================] - 0s 3ms/step - loss: 0.2930\n",
      "[CV]  learning_rate=0.003333910854886942, n_hidden=3, n_neurons=82, total= 2.5min\n",
      "[CV] learning_rate=0.024309638332517276, n_hidden=3, n_neurons=27 ....\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.6521 - val_loss: 0.5245\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.4638 - val_loss: 17.4835\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.5165 - val_loss: 35.3973\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.4809 - val_loss: 8.8997\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3807 - val_loss: 0.4227\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3626 - val_loss: 4.1616\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3977 - val_loss: 6.7020\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.4308 - val_loss: 0.4306\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3487 - val_loss: 0.3717\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3401 - val_loss: 0.3266\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3287 - val_loss: 0.3357\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3294 - val_loss: 0.3135\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3247 - val_loss: 0.3120\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3238 - val_loss: 0.3119\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3178 - val_loss: 0.3232\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3148 - val_loss: 0.3066\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3117 - val_loss: 0.3147\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3091 - val_loss: 0.3039\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3094 - val_loss: 0.3041\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3114 - val_loss: 0.3216\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3034 - val_loss: 0.2932\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3004 - val_loss: 0.3032\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.2995 - val_loss: 0.3001\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.2973 - val_loss: 0.2925\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3008 - val_loss: 0.3170\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.2936 - val_loss: 0.2984\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.2924 - val_loss: 0.2885\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.2897 - val_loss: 0.3005\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.2928 - val_loss: 0.2930\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.2934 - val_loss: 0.2845\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.2893 - val_loss: 0.2837\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.2887 - val_loss: 0.2844\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.2838 - val_loss: 0.3051\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.2845 - val_loss: 0.3766\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.2841 - val_loss: 0.2845\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.2832 - val_loss: 0.2970\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.2812 - val_loss: 0.3328\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.2785 - val_loss: 0.3839\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.2782 - val_loss: 0.3821\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.2826 - val_loss: 0.3982\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.2792 - val_loss: 0.2854\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.2730 - val_loss: 0.2950\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.2756 - val_loss: 0.2839\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.2742 - val_loss: 0.2972\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.2713 - val_loss: 0.3054\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.2707 - val_loss: 0.3189\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.2688 - val_loss: 0.2851\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.2728 - val_loss: 0.2718\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.2689 - val_loss: 0.2831\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.2698 - val_loss: 0.2886\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.2643 - val_loss: 0.2756\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.2688 - val_loss: 0.2647\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.2638 - val_loss: 0.2834\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.2634 - val_loss: 0.2745\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.2680 - val_loss: 0.2968\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.2658 - val_loss: 0.2640\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.2623 - val_loss: 0.2792\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.2616 - val_loss: 0.2815\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 0.2614 - val_loss: 0.2774\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.2617 - val_loss: 0.2628\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 2s 8ms/step - loss: 0.2605 - val_loss: 0.3150\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 0.2604 - val_loss: 0.2731\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.2587 - val_loss: 0.2815\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.2572 - val_loss: 0.2641\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 2s 8ms/step - loss: 0.2575 - val_loss: 0.2918\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 2s 9ms/step - loss: 0.2578 - val_loss: 0.3136\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.2581 - val_loss: 0.2885\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 0.2587 - val_loss: 0.2675\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 0.2575 - val_loss: 0.2690\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.2545 - val_loss: 0.2776\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.2558 - val_loss: 0.2706\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.2566 - val_loss: 0.2939\n",
      "Epoch 73/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 0.2667 - val_loss: 0.2716\n",
      "Epoch 74/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.2621 - val_loss: 0.2812\n",
      "Epoch 75/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.2587 - val_loss: 0.2896\n",
      "Epoch 76/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.2553 - val_loss: 0.2640\n",
      "Epoch 77/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.2541 - val_loss: 0.2684\n",
      "Epoch 78/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.2555 - val_loss: 0.2702\n",
      "Epoch 79/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.2535 - val_loss: 0.2687\n",
      "Epoch 80/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 0.2512 - val_loss: 0.2723\n",
      "Epoch 81/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.2524 - val_loss: 0.2798\n",
      "Epoch 82/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.2525 - val_loss: 0.2918\n",
      "Epoch 83/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.2521 - val_loss: 0.2743\n",
      "Epoch 84/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.2536 - val_loss: 0.2705\n",
      "Epoch 85/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.2501 - val_loss: 0.2659\n",
      "Epoch 86/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.2479 - val_loss: 0.2758\n",
      "Epoch 87/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.2503 - val_loss: 0.2650\n",
      "Epoch 88/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.2479 - val_loss: 0.2932\n",
      "Epoch 89/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 0.2466 - val_loss: 0.3039\n",
      "Epoch 90/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 0.2487 - val_loss: 0.2771\n",
      "Epoch 91/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.2498 - val_loss: 0.2807\n",
      "Epoch 92/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.2469 - val_loss: 0.2633\n",
      "Epoch 93/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.2464 - val_loss: 0.2820\n",
      "Epoch 94/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.2484 - val_loss: 0.2626\n",
      "Epoch 95/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.2457 - val_loss: 0.2675\n",
      "Epoch 96/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.2460 - val_loss: 0.2824\n",
      "Epoch 97/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 0.2465 - val_loss: 0.2747\n",
      "Epoch 98/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.2440 - val_loss: 0.2628\n",
      "Epoch 99/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.2432 - val_loss: 0.2666\n",
      "Epoch 100/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.2441 - val_loss: 0.2671\n",
      "121/121 [==============================] - 0s 4ms/step - loss: 0.3023\n",
      "[CV]  learning_rate=0.024309638332517276, n_hidden=3, n_neurons=27, total= 2.4min\n",
      "[CV] learning_rate=0.024309638332517276, n_hidden=3, n_neurons=27 ....\n",
      "Epoch 1/100\n",
      "239/242 [============================>.] - ETA: 0s - loss: 0.7972WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0000s vs `on_test_batch_end` time: 0.0039s). Check your callbacks.\n",
      "242/242 [==============================] - 2s 8ms/step - loss: 0.7938 - val_loss: 0.6970\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 0.4143 - val_loss: 0.3750\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3798 - val_loss: 0.5111\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3658 - val_loss: 0.5059\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3586 - val_loss: 0.7650\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3481 - val_loss: 0.6453\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3459 - val_loss: 0.9646\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3409 - val_loss: 1.7576\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3388 - val_loss: 0.7725\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3344 - val_loss: 1.4159\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3302 - val_loss: 0.4576\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3297 - val_loss: 1.1882\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3249 - val_loss: 0.8373\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3232 - val_loss: 1.2822\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3232 - val_loss: 0.3346\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3185 - val_loss: 0.8779\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3144 - val_loss: 0.6179\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3159 - val_loss: 0.4344\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3141 - val_loss: 0.5076\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3136 - val_loss: 0.8422\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3110 - val_loss: 1.6278\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3092 - val_loss: 0.3282\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3060 - val_loss: 0.2990\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3060 - val_loss: 0.3975\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3052 - val_loss: 1.3900\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3028 - val_loss: 0.4308\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3001 - val_loss: 1.6091\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.2986 - val_loss: 0.7290\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 0.3001 - val_loss: 0.4209\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 0.2980 - val_loss: 0.6467\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.2962 - val_loss: 0.9162\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.2939 - val_loss: 0.5366\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.2936 - val_loss: 0.8909\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.2903 - val_loss: 0.8978\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.2919 - val_loss: 1.2887\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 0.2908 - val_loss: 0.5592\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 0.2869 - val_loss: 1.3859\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.2883 - val_loss: 0.2915\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.2873 - val_loss: 0.4834\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.2880 - val_loss: 0.3453\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.2867 - val_loss: 1.2452\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.2837 - val_loss: 1.4689\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 0.2882 - val_loss: 0.3613\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 0.2835 - val_loss: 0.8462\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.2821 - val_loss: 2.0400\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.2831 - val_loss: 1.2621\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 0.2817 - val_loss: 0.3286\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 0.2784 - val_loss: 0.2825\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.2781 - val_loss: 1.6230\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.2799 - val_loss: 0.3338\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 0.2775 - val_loss: 0.2787\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.2748 - val_loss: 0.6786\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.2746 - val_loss: 0.9328\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.2731 - val_loss: 0.3584\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.2738 - val_loss: 0.9076\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.2735 - val_loss: 0.3099\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.2755 - val_loss: 0.8538\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.2723 - val_loss: 1.1126\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 0.2717 - val_loss: 0.5748\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.2707 - val_loss: 0.5328\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.2705 - val_loss: 0.7517\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.2695 - val_loss: 0.3528\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.2699 - val_loss: 0.4561\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.2649 - val_loss: 0.7339\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.2670 - val_loss: 0.6390\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 0.2660 - val_loss: 2.1345\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.2620 - val_loss: 0.2786\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.2628 - val_loss: 3.4644\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.2635 - val_loss: 0.2823\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.2620 - val_loss: 2.5602\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.2641 - val_loss: 0.3398\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.2641 - val_loss: 1.3284\n",
      "Epoch 73/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 0.2613 - val_loss: 1.0718\n",
      "Epoch 74/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.2588 - val_loss: 0.3986\n",
      "Epoch 75/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.2609 - val_loss: 0.2836\n",
      "Epoch 76/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.2580 - val_loss: 1.6283\n",
      "Epoch 77/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 0.2601 - val_loss: 0.3357\n",
      "Epoch 78/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.2585 - val_loss: 0.9022\n",
      "Epoch 79/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.2581 - val_loss: 0.3178\n",
      "Epoch 80/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 0.2589 - val_loss: 2.9833\n",
      "Epoch 81/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.2572 - val_loss: 0.3120\n",
      "Epoch 82/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.2584 - val_loss: 0.3344\n",
      "Epoch 83/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.2569 - val_loss: 1.3643\n",
      "Epoch 84/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.2546 - val_loss: 0.3983\n",
      "Epoch 85/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.2560 - val_loss: 1.4849\n",
      "Epoch 86/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.2551 - val_loss: 0.3014\n",
      "Epoch 87/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.2531 - val_loss: 0.8165\n",
      "Epoch 88/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.2551 - val_loss: 0.2747\n",
      "Epoch 89/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.2553 - val_loss: 0.3371\n",
      "Epoch 90/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.2540 - val_loss: 0.8014\n",
      "Epoch 91/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 0.2533 - val_loss: 0.3696\n",
      "Epoch 92/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.2537 - val_loss: 0.6563\n",
      "Epoch 93/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.2515 - val_loss: 0.6013\n",
      "Epoch 94/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.2497 - val_loss: 1.8191\n",
      "Epoch 95/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 0.2525 - val_loss: 0.3897\n",
      "Epoch 96/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.2503 - val_loss: 0.5800\n",
      "Epoch 97/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.2523 - val_loss: 0.3407\n",
      "Epoch 98/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.2494 - val_loss: 1.2237\n",
      "Epoch 99/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 0.2483 - val_loss: 1.1278\n",
      "Epoch 100/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.2478 - val_loss: 1.0829\n",
      "121/121 [==============================] - 0s 4ms/step - loss: 0.3399\n",
      "[CV]  learning_rate=0.024309638332517276, n_hidden=3, n_neurons=27, total= 2.5min\n",
      "[CV] learning_rate=0.024309638332517276, n_hidden=3, n_neurons=27 ....\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.7043 - val_loss: 14.4305\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.4766 - val_loss: 9.3004\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.5417 - val_loss: 1.5965\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.4087 - val_loss: 0.3711\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 0.3833 - val_loss: 0.4206\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.3795 - val_loss: 0.3485\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.3647 - val_loss: 0.4087\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.3596 - val_loss: 0.3417\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.3533 - val_loss: 0.3323\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.3445 - val_loss: 0.3717\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.3526 - val_loss: 0.3432\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.3450 - val_loss: 0.3183\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.3366 - val_loss: 0.3150\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.3345 - val_loss: 0.3878\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.3279 - val_loss: 0.3072\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.3254 - val_loss: 0.3166\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.3222 - val_loss: 0.3349\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.3191 - val_loss: 0.3083\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.3145 - val_loss: 0.3333\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.3118 - val_loss: 0.3449\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.3126 - val_loss: 0.3171\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.3087 - val_loss: 0.3325\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.3048 - val_loss: 0.2984\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.3047 - val_loss: 0.2791\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.3062 - val_loss: 0.3184\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.2973 - val_loss: 0.3079\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.3089 - val_loss: 0.2885\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.3011 - val_loss: 0.3205\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.2990 - val_loss: 0.3238\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.2955 - val_loss: 0.3035\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.2953 - val_loss: 0.2969\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.2917 - val_loss: 0.3337\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.2902 - val_loss: 0.2899\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.2888 - val_loss: 0.3052\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.2860 - val_loss: 0.2846\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 0.2880 - val_loss: 0.3122\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.2858 - val_loss: 0.3044\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.2865 - val_loss: 0.3470\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.2856 - val_loss: 0.2836\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 0.2856 - val_loss: 0.3141\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.2835 - val_loss: 0.2907\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.2821 - val_loss: 0.2896\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.2807 - val_loss: 0.3467\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.2827 - val_loss: 0.2965\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.2805 - val_loss: 0.2707\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.2828 - val_loss: 0.2782\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.2804 - val_loss: 0.2949\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.2787 - val_loss: 0.3532\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.2782 - val_loss: 0.2957\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.2773 - val_loss: 0.3582\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.2761 - val_loss: 0.2870\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.2777 - val_loss: 0.3424\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.2745 - val_loss: 0.2683\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 0.2776 - val_loss: 0.2987\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.2739 - val_loss: 0.2929\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.2727 - val_loss: 0.3186\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 0.2747 - val_loss: 0.2739\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.2708 - val_loss: 0.2746\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.2688 - val_loss: 0.3294\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.2711 - val_loss: 0.2895\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.2692 - val_loss: 0.3181\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.2697 - val_loss: 0.2910\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.2666 - val_loss: 0.2791\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.2659 - val_loss: 0.3555\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.2693 - val_loss: 0.2772\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.2661 - val_loss: 0.2722\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.2660 - val_loss: 0.3276\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.2639 - val_loss: 0.2788\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.2680 - val_loss: 0.3334\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.2659 - val_loss: 0.2781\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.2698 - val_loss: 0.2989\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.2633 - val_loss: 0.3220\n",
      "Epoch 73/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.2664 - val_loss: 0.2708\n",
      "Epoch 74/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.2614 - val_loss: 0.3101\n",
      "Epoch 75/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.2615 - val_loss: 0.3033\n",
      "Epoch 76/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.2615 - val_loss: 0.2718\n",
      "Epoch 77/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.2621 - val_loss: 0.3385\n",
      "Epoch 78/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.2606 - val_loss: 0.2921\n",
      "Epoch 79/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.2606 - val_loss: 0.2945\n",
      "Epoch 80/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.2604 - val_loss: 0.2662\n",
      "Epoch 81/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.2618 - val_loss: 0.3677\n",
      "Epoch 82/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.2607 - val_loss: 0.3558\n",
      "Epoch 83/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.2579 - val_loss: 0.2823\n",
      "Epoch 84/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.2570 - val_loss: 0.2811\n",
      "Epoch 85/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.2550 - val_loss: 0.4070\n",
      "Epoch 86/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.2569 - val_loss: 0.3028\n",
      "Epoch 87/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.2579 - val_loss: 0.3373\n",
      "Epoch 88/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.2566 - val_loss: 0.2694\n",
      "Epoch 89/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.2548 - val_loss: 0.2750\n",
      "Epoch 90/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.2558 - val_loss: 0.3393\n",
      "Epoch 91/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.2541 - val_loss: 0.2741\n",
      "Epoch 92/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.2563 - val_loss: 0.2857\n",
      "Epoch 93/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.2550 - val_loss: 0.2749\n",
      "Epoch 94/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.2547 - val_loss: 0.3756\n",
      "Epoch 95/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.2565 - val_loss: 0.4059\n",
      "Epoch 96/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.2545 - val_loss: 0.6970\n",
      "Epoch 97/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.2572 - val_loss: 0.3382\n",
      "Epoch 98/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.2738 - val_loss: 0.2666\n",
      "Epoch 99/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.2743 - val_loss: 0.2678\n",
      "Epoch 100/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.2542 - val_loss: 0.2879\n",
      "121/121 [==============================] - 0s 3ms/step - loss: 0.2869\n",
      "[CV]  learning_rate=0.024309638332517276, n_hidden=3, n_neurons=27, total= 2.6min\n",
      "[CV] learning_rate=0.0011275001038955842, n_hidden=2, n_neurons=56 ...\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 2.0589 - val_loss: 0.8197\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.7590 - val_loss: 0.7915\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.6767 - val_loss: 0.6322\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.6310 - val_loss: 0.5809\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.5951 - val_loss: 0.5568\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.5639 - val_loss: 0.5348\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.5372 - val_loss: 0.5405\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.5131 - val_loss: 0.5580\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.4928 - val_loss: 0.4552\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.4759 - val_loss: 0.4447\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.4613 - val_loss: 0.4404\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.4487 - val_loss: 0.4605\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.4381 - val_loss: 0.4609\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.4294 - val_loss: 0.4572\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.4219 - val_loss: 0.4032\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.4155 - val_loss: 0.4632\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.4102 - val_loss: 0.3860\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.4054 - val_loss: 0.4461\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.4011 - val_loss: 0.4432\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3978 - val_loss: 0.3914\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3942 - val_loss: 0.4620\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3918 - val_loss: 0.3689\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3889 - val_loss: 0.3812\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3861 - val_loss: 0.4560\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3843 - val_loss: 0.3642\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3816 - val_loss: 0.4840\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3803 - val_loss: 0.4026\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3778 - val_loss: 0.3636\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3760 - val_loss: 0.3893\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3741 - val_loss: 0.3584\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3725 - val_loss: 0.4505\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3717 - val_loss: 0.3624\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3693 - val_loss: 0.4210\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3680 - val_loss: 0.4287\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3671 - val_loss: 0.3514\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3657 - val_loss: 0.3746\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3639 - val_loss: 0.3974\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3634 - val_loss: 0.3498\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3616 - val_loss: 0.3939\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3603 - val_loss: 0.4464\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3602 - val_loss: 0.3495\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3583 - val_loss: 0.4433\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3582 - val_loss: 0.3463\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3569 - val_loss: 0.3641\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3559 - val_loss: 0.3445\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3544 - val_loss: 0.4760\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3550 - val_loss: 0.3473\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3532 - val_loss: 0.4477\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3530 - val_loss: 0.3422\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3515 - val_loss: 0.4110\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3513 - val_loss: 0.3413\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3500 - val_loss: 0.4265\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3495 - val_loss: 0.3688\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3483 - val_loss: 0.4062\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3477 - val_loss: 0.3723\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3470 - val_loss: 0.4266\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3464 - val_loss: 0.3473\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3461 - val_loss: 0.4559\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3458 - val_loss: 0.3501\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3450 - val_loss: 0.3924\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3440 - val_loss: 0.3742\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3436 - val_loss: 0.3364\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3432 - val_loss: 0.4240\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3427 - val_loss: 0.3426\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3422 - val_loss: 0.3473\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3415 - val_loss: 0.3349\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3408 - val_loss: 0.3874\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3410 - val_loss: 0.3394\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3398 - val_loss: 0.3998\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3400 - val_loss: 0.3433\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3394 - val_loss: 0.3976\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3391 - val_loss: 0.3368\n",
      "Epoch 73/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3384 - val_loss: 0.3591\n",
      "Epoch 74/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3378 - val_loss: 0.3316\n",
      "Epoch 75/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3372 - val_loss: 0.4166\n",
      "Epoch 76/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3374 - val_loss: 0.3303\n",
      "Epoch 77/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3364 - val_loss: 0.4219\n",
      "Epoch 78/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3368 - val_loss: 0.3379\n",
      "Epoch 79/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3357 - val_loss: 0.3567\n",
      "Epoch 80/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3355 - val_loss: 0.3312\n",
      "Epoch 81/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3348 - val_loss: 0.3474\n",
      "Epoch 82/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3341 - val_loss: 0.3294\n",
      "Epoch 83/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3336 - val_loss: 0.4217\n",
      "Epoch 84/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3336 - val_loss: 0.3452\n",
      "Epoch 85/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3335 - val_loss: 0.3579\n",
      "Epoch 86/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3330 - val_loss: 0.3769\n",
      "Epoch 87/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3326 - val_loss: 0.3465\n",
      "Epoch 88/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3320 - val_loss: 0.3874\n",
      "Epoch 89/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3320 - val_loss: 0.3387\n",
      "Epoch 90/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3314 - val_loss: 0.3271\n",
      "Epoch 91/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3310 - val_loss: 0.3947\n",
      "Epoch 92/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3314 - val_loss: 0.3374\n",
      "Epoch 93/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3306 - val_loss: 0.4270\n",
      "Epoch 94/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3307 - val_loss: 0.3319\n",
      "Epoch 95/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3295 - val_loss: 0.3413\n",
      "Epoch 96/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3290 - val_loss: 0.3565\n",
      "Epoch 97/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3287 - val_loss: 0.3285\n",
      "Epoch 98/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3285 - val_loss: 0.3667\n",
      "Epoch 99/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3280 - val_loss: 0.3529\n",
      "Epoch 100/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3274 - val_loss: 0.3252\n",
      "121/121 [==============================] - 0s 3ms/step - loss: 0.3552\n",
      "[CV]  learning_rate=0.0011275001038955842, n_hidden=2, n_neurons=56, total= 2.2min\n",
      "[CV] learning_rate=0.0011275001038955842, n_hidden=2, n_neurons=56 ...\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 1.9649 - val_loss: 11.7876\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.8713 - val_loss: 8.5813\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.7495 - val_loss: 5.9081\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.6918 - val_loss: 4.1854\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.6499 - val_loss: 2.8540\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.6135 - val_loss: 1.9502\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.5825 - val_loss: 1.3751\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.5552 - val_loss: 0.9116\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.5313 - val_loss: 0.6584\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.5105 - val_loss: 0.4941\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.4927 - val_loss: 0.4526\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.4773 - val_loss: 0.4514\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.4645 - val_loss: 0.4711\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.4536 - val_loss: 0.4829\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.4440 - val_loss: 0.4865\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.4362 - val_loss: 0.4999\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.4291 - val_loss: 0.4980\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.4226 - val_loss: 0.4710\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.4171 - val_loss: 0.4556\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.4126 - val_loss: 0.4324\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.4079 - val_loss: 0.4144\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.4039 - val_loss: 0.4021\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.4001 - val_loss: 0.3916\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3964 - val_loss: 0.3810\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3940 - val_loss: 0.3724\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3907 - val_loss: 0.3746\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3879 - val_loss: 0.3873\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3856 - val_loss: 0.4059\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3832 - val_loss: 0.4108\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3810 - val_loss: 0.4563\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3788 - val_loss: 0.4591\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3767 - val_loss: 0.5213\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3747 - val_loss: 0.5514\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3730 - val_loss: 0.5613\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3713 - val_loss: 0.6022\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3695 - val_loss: 0.6285\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3681 - val_loss: 0.7146\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3663 - val_loss: 0.7022\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3652 - val_loss: 0.7606\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3638 - val_loss: 0.8039\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3626 - val_loss: 0.8417\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3615 - val_loss: 0.9209\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3601 - val_loss: 0.9268\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3591 - val_loss: 0.9695\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3579 - val_loss: 1.0221\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3570 - val_loss: 1.1025\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3558 - val_loss: 1.1375\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3550 - val_loss: 1.1475\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3542 - val_loss: 1.1883\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3533 - val_loss: 1.2692\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3523 - val_loss: 1.2197\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3518 - val_loss: 1.3465\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3509 - val_loss: 1.4083\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3500 - val_loss: 1.3478\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3494 - val_loss: 1.4395\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3487 - val_loss: 1.4552\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.3482 - val_loss: 1.4713\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3475 - val_loss: 1.5272\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3465 - val_loss: 1.5648\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3461 - val_loss: 1.5422\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3453 - val_loss: 1.5288\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3445 - val_loss: 1.6308\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3441 - val_loss: 1.6329\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3428 - val_loss: 1.4833\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3430 - val_loss: 1.6317\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3421 - val_loss: 1.7138\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3414 - val_loss: 1.6564\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3407 - val_loss: 1.6429\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3404 - val_loss: 1.6536\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3395 - val_loss: 1.6967\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3390 - val_loss: 1.5888\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3383 - val_loss: 1.6372\n",
      "Epoch 73/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3380 - val_loss: 1.6207\n",
      "Epoch 74/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3376 - val_loss: 1.6666\n",
      "Epoch 75/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3370 - val_loss: 1.7032\n",
      "Epoch 76/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3366 - val_loss: 1.5824\n",
      "Epoch 77/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3356 - val_loss: 1.7334\n",
      "Epoch 78/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3356 - val_loss: 1.6565\n",
      "Epoch 79/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3350 - val_loss: 1.6275\n",
      "Epoch 80/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3344 - val_loss: 1.6416\n",
      "Epoch 81/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3340 - val_loss: 1.5653\n",
      "Epoch 82/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3334 - val_loss: 1.6111\n",
      "Epoch 83/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3329 - val_loss: 1.6355\n",
      "Epoch 84/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3324 - val_loss: 1.5900\n",
      "Epoch 85/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3321 - val_loss: 1.5655\n",
      "Epoch 86/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3314 - val_loss: 1.5183\n",
      "Epoch 87/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3313 - val_loss: 1.5518\n",
      "Epoch 88/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3305 - val_loss: 1.4700\n",
      "Epoch 89/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3302 - val_loss: 1.5207\n",
      "Epoch 90/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3294 - val_loss: 1.5454\n",
      "Epoch 91/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3291 - val_loss: 1.4932\n",
      "Epoch 92/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3286 - val_loss: 1.4504\n",
      "Epoch 93/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3280 - val_loss: 1.3939\n",
      "Epoch 94/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3279 - val_loss: 1.4172\n",
      "Epoch 95/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3274 - val_loss: 1.4024\n",
      "Epoch 96/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3270 - val_loss: 1.4473\n",
      "Epoch 97/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3266 - val_loss: 1.3979\n",
      "Epoch 98/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3259 - val_loss: 1.3963\n",
      "Epoch 99/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3256 - val_loss: 1.3311\n",
      "Epoch 100/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3255 - val_loss: 1.3441\n",
      "  1/121 [..............................] - ETA: 0s - loss: 0.1901WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0000s vs `on_test_batch_end` time: 0.0040s). Check your callbacks.\n",
      "121/121 [==============================] - 0s 3ms/step - loss: 0.3548\n",
      "[CV]  learning_rate=0.0011275001038955842, n_hidden=2, n_neurons=56, total= 2.2min\n",
      "[CV] learning_rate=0.0011275001038955842, n_hidden=2, n_neurons=56 ...\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 2.2098 - val_loss: 1.0343\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.9021 - val_loss: 0.7499\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.7382 - val_loss: 0.6534\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.6660 - val_loss: 0.5989\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.6186 - val_loss: 0.5633\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.5830 - val_loss: 0.5291\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.5529 - val_loss: 0.5099\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.5287 - val_loss: 0.4801\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.5065 - val_loss: 0.4621\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.4886 - val_loss: 0.4485\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.4732 - val_loss: 0.4400\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.4588 - val_loss: 0.4214\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.4475 - val_loss: 0.4254\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.4377 - val_loss: 0.4192\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.4308 - val_loss: 0.4104\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.4234 - val_loss: 0.3962\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.4175 - val_loss: 0.3871\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.4128 - val_loss: 0.3886\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.4076 - val_loss: 0.4065\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.4035 - val_loss: 0.4130\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.4003 - val_loss: 0.3742\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3967 - val_loss: 0.3894\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3939 - val_loss: 0.3701\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3910 - val_loss: 0.3914\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3888 - val_loss: 0.3607\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3862 - val_loss: 0.3632\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3838 - val_loss: 0.4180\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3823 - val_loss: 0.3700\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3800 - val_loss: 0.4057\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3787 - val_loss: 0.3854\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3770 - val_loss: 0.3868\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3749 - val_loss: 0.3778\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3738 - val_loss: 0.3872\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3723 - val_loss: 0.3638\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3707 - val_loss: 0.3537\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3692 - val_loss: 0.3681\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3676 - val_loss: 0.3745\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3672 - val_loss: 0.3776\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3654 - val_loss: 0.3973\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3646 - val_loss: 0.3938\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3632 - val_loss: 0.3484\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3623 - val_loss: 0.3821\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3615 - val_loss: 0.3882\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3608 - val_loss: 0.3487\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3592 - val_loss: 0.3771\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3590 - val_loss: 0.3434\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3575 - val_loss: 0.3940\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3571 - val_loss: 0.3706\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3563 - val_loss: 0.3502\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3556 - val_loss: 0.3613\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3546 - val_loss: 0.3455\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3534 - val_loss: 0.3600\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3534 - val_loss: 0.3769\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3527 - val_loss: 0.3341\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3518 - val_loss: 0.3459\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3508 - val_loss: 0.3729\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3507 - val_loss: 0.3442\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3496 - val_loss: 0.3522\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3491 - val_loss: 0.3409\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3485 - val_loss: 0.3315\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3476 - val_loss: 0.3966\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3478 - val_loss: 0.3325\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3468 - val_loss: 0.3378\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3460 - val_loss: 0.3509\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3452 - val_loss: 0.3382\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3447 - val_loss: 0.3736\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3444 - val_loss: 0.3544\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3438 - val_loss: 0.3588\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3433 - val_loss: 0.3289\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3427 - val_loss: 0.3315\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3414 - val_loss: 0.3604\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3417 - val_loss: 0.3453\n",
      "Epoch 73/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3411 - val_loss: 0.3580\n",
      "Epoch 74/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3406 - val_loss: 0.3593\n",
      "Epoch 75/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3402 - val_loss: 0.3255\n",
      "Epoch 76/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3400 - val_loss: 0.3320\n",
      "Epoch 77/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3388 - val_loss: 0.3274\n",
      "Epoch 78/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3388 - val_loss: 0.3292\n",
      "Epoch 79/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3383 - val_loss: 0.3282\n",
      "Epoch 80/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3378 - val_loss: 0.3355\n",
      "Epoch 81/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3376 - val_loss: 0.3259\n",
      "Epoch 82/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3369 - val_loss: 0.3482\n",
      "Epoch 83/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3369 - val_loss: 0.3273\n",
      "Epoch 84/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3362 - val_loss: 0.3342\n",
      "Epoch 85/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3361 - val_loss: 0.3254\n",
      "Epoch 86/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3353 - val_loss: 0.3272\n",
      "Epoch 87/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3351 - val_loss: 0.3217\n",
      "Epoch 88/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3348 - val_loss: 0.3757\n",
      "Epoch 89/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3348 - val_loss: 0.3488\n",
      "Epoch 90/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3340 - val_loss: 0.3282\n",
      "Epoch 91/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3335 - val_loss: 0.3199\n",
      "Epoch 92/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3331 - val_loss: 0.3741\n",
      "Epoch 93/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3334 - val_loss: 0.3362\n",
      "Epoch 94/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3326 - val_loss: 0.3205\n",
      "Epoch 95/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3320 - val_loss: 0.3898\n",
      "Epoch 96/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3324 - val_loss: 0.3199\n",
      "Epoch 97/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3314 - val_loss: 0.3238\n",
      "Epoch 98/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3310 - val_loss: 0.3647\n",
      "Epoch 99/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3306 - val_loss: 0.3375\n",
      "Epoch 100/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3308 - val_loss: 0.3192\n",
      "121/121 [==============================] - 0s 3ms/step - loss: 0.3373\n",
      "[CV]  learning_rate=0.0011275001038955842, n_hidden=2, n_neurons=56, total= 2.2min\n",
      "[CV] learning_rate=0.00802851624285897, n_hidden=3, n_neurons=23 .....\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 1.0007 - val_loss: 0.6058\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.5766 - val_loss: 0.5681\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 2s 8ms/step - loss: 0.4838 - val_loss: 0.5462\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.4330 - val_loss: 1.6158\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.4218 - val_loss: 0.6571\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 0.3965 - val_loss: 0.3699\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.3801 - val_loss: 0.3910\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 0.3723 - val_loss: 0.3883\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.3659 - val_loss: 0.3681\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.3616 - val_loss: 0.3828\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.3580 - val_loss: 0.3752\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 0.3529 - val_loss: 0.3675\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 0.3502 - val_loss: 0.3621\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.3457 - val_loss: 0.3685\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 0.3444 - val_loss: 0.3746\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.3407 - val_loss: 0.3567\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 0.3388 - val_loss: 0.3416\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.3367 - val_loss: 0.3351\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.3357 - val_loss: 0.3345\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.3331 - val_loss: 0.3749\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 0.3324 - val_loss: 0.3310\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.3298 - val_loss: 0.3417\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.3288 - val_loss: 0.3200\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.3279 - val_loss: 0.3631\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.3261 - val_loss: 0.3481\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.3245 - val_loss: 0.3624\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.3238 - val_loss: 0.3202\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.3241 - val_loss: 0.3339\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.3216 - val_loss: 0.3369\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 0.3205 - val_loss: 0.3585\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 0.3194 - val_loss: 0.3176\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 0.3175 - val_loss: 0.3265\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 0.3173 - val_loss: 0.4359\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 0.3164 - val_loss: 0.3228\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 0.3150 - val_loss: 0.3325\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 0.3132 - val_loss: 0.4576\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 0.3138 - val_loss: 0.3194\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 0.3118 - val_loss: 0.3552\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 0.3094 - val_loss: 0.3652\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3088 - val_loss: 0.5140\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3124 - val_loss: 0.3208\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3085 - val_loss: 0.3597\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3093 - val_loss: 0.3614\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3080 - val_loss: 0.3320\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 0.3054 - val_loss: 0.3052\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.3042 - val_loss: 0.3486\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 0.3044 - val_loss: 0.3219\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3042 - val_loss: 0.3022\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3014 - val_loss: 0.3138\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3007 - val_loss: 0.3291\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 0.3003 - val_loss: 0.3655\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.2999 - val_loss: 0.3308\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 0.2995 - val_loss: 0.3163\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.2980 - val_loss: 0.3019\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 0.2974 - val_loss: 0.3139\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.2963 - val_loss: 0.3498\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.2953 - val_loss: 0.3291\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.2946 - val_loss: 0.3714\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.2952 - val_loss: 0.3045\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.2923 - val_loss: 0.3547\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.2922 - val_loss: 0.3004\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.2913 - val_loss: 0.3256\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.2903 - val_loss: 0.3011\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.2891 - val_loss: 0.2979\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.2895 - val_loss: 0.3339\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.2877 - val_loss: 0.2981\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.2877 - val_loss: 0.2970\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.2857 - val_loss: 0.4393\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.2856 - val_loss: 0.5060\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.2877 - val_loss: 0.9461\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3017 - val_loss: 0.3546\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.2868 - val_loss: 0.3856\n",
      "Epoch 73/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.2866 - val_loss: 0.2947\n",
      "Epoch 74/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.2828 - val_loss: 0.4026\n",
      "Epoch 75/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.2829 - val_loss: 0.3136\n",
      "Epoch 76/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.2813 - val_loss: 0.3446\n",
      "Epoch 77/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.2824 - val_loss: 0.2957\n",
      "Epoch 78/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.2812 - val_loss: 0.3176\n",
      "Epoch 79/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 0.2803 - val_loss: 0.3407\n",
      "Epoch 80/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 0.2789 - val_loss: 0.3064\n",
      "Epoch 81/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 0.2796 - val_loss: 0.4125\n",
      "Epoch 82/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 0.2779 - val_loss: 0.3271\n",
      "Epoch 83/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.2782 - val_loss: 0.4032\n",
      "Epoch 84/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.2785 - val_loss: 0.3010\n",
      "Epoch 85/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.2748 - val_loss: 0.2886\n",
      "Epoch 86/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.2751 - val_loss: 0.3572\n",
      "Epoch 87/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 0.2745 - val_loss: 0.3090\n",
      "Epoch 88/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.2746 - val_loss: 0.3294\n",
      "Epoch 89/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 0.2735 - val_loss: 0.3567\n",
      "Epoch 90/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 0.2729 - val_loss: 0.2984\n",
      "Epoch 91/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.2731 - val_loss: 0.3151\n",
      "Epoch 92/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.2729 - val_loss: 0.2902\n",
      "Epoch 93/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 0.2720 - val_loss: 0.3754\n",
      "Epoch 94/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.2724 - val_loss: 0.2929\n",
      "Epoch 95/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.2708 - val_loss: 0.3629\n",
      "Epoch 96/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.2710 - val_loss: 0.2975\n",
      "Epoch 97/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.2705 - val_loss: 0.4067\n",
      "Epoch 98/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 0.2699 - val_loss: 0.3145\n",
      "Epoch 99/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.2700 - val_loss: 0.3162\n",
      "Epoch 100/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.2692 - val_loss: 0.2934\n",
      "121/121 [==============================] - 0s 3ms/step - loss: 0.3220\n",
      "[CV]  learning_rate=0.00802851624285897, n_hidden=3, n_neurons=23, total= 2.6min\n",
      "[CV] learning_rate=0.00802851624285897, n_hidden=3, n_neurons=23 .....\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 2s 8ms/step - loss: 0.8562 - val_loss: 1.2349\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 0.4735 - val_loss: 0.4802\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.4199 - val_loss: 0.5958\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3983 - val_loss: 0.5796\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3859 - val_loss: 0.6279\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3754 - val_loss: 0.7162\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3682 - val_loss: 0.6964\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 0.3634 - val_loss: 0.7016\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 0.3581 - val_loss: 0.7995\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3528 - val_loss: 0.7848\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3511 - val_loss: 0.7136\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3455 - val_loss: 0.6721\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3437 - val_loss: 0.5381\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 0.3394 - val_loss: 0.5347\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 2s 8ms/step - loss: 0.3373 - val_loss: 0.5512\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 2s 8ms/step - loss: 0.3363 - val_loss: 0.4974\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.3318 - val_loss: 0.5616\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 3s 10ms/step - loss: 0.3296 - val_loss: 0.5030\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 2s 8ms/step - loss: 0.3281 - val_loss: 0.4723\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 2s 8ms/step - loss: 0.3244 - val_loss: 0.4138\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 2s 8ms/step - loss: 0.3239 - val_loss: 0.4435\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.3215 - val_loss: 0.4420\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 0.3184 - val_loss: 0.5017\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 0.3190 - val_loss: 0.4781\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.3161 - val_loss: 0.4616\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.3147 - val_loss: 0.4480\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 0.3129 - val_loss: 0.4524\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 0.3111 - val_loss: 0.3985\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.3104 - val_loss: 0.3447\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.3074 - val_loss: 0.3652\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.3073 - val_loss: 0.3477\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.3061 - val_loss: 0.3704\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.3047 - val_loss: 0.3421\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.3030 - val_loss: 0.3279\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 2s 8ms/step - loss: 0.3014 - val_loss: 0.3137\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 2s 8ms/step - loss: 0.3010 - val_loss: 0.3186\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 2s 10ms/step - loss: 0.2997 - val_loss: 0.3183\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 2s 10ms/step - loss: 0.2975 - val_loss: 0.3088\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 2s 10ms/step - loss: 0.2948 - val_loss: 0.3026\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.2964 - val_loss: 0.2930\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.2951 - val_loss: 0.2945\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 2s 8ms/step - loss: 0.2936 - val_loss: 0.2948\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 4s 15ms/step - loss: 0.2924 - val_loss: 0.3149\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 2s 9ms/step - loss: 0.2921 - val_loss: 0.3044\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.2891 - val_loss: 0.2958\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.2895 - val_loss: 0.2942\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.2905 - val_loss: 0.2916\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.2891 - val_loss: 0.3008\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 0.2896 - val_loss: 0.2988\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.2870 - val_loss: 0.3300\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.2867 - val_loss: 0.2837\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.2845 - val_loss: 0.3048\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.2835 - val_loss: 0.3204\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.2822 - val_loss: 0.3125\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.2833 - val_loss: 0.3099\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.2839 - val_loss: 0.2878\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.2830 - val_loss: 0.3005\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.2821 - val_loss: 0.3027\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.2819 - val_loss: 0.3601\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.2812 - val_loss: 0.2931\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.2802 - val_loss: 0.3009\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.2783 - val_loss: 0.3419\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 0.2819 - val_loss: 0.2833\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.2777 - val_loss: 0.3195\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.2772 - val_loss: 0.4104\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.2786 - val_loss: 0.2872\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.2786 - val_loss: 0.2902\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.2761 - val_loss: 0.2966\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.2767 - val_loss: 0.3099\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.2774 - val_loss: 0.3435\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 2s 8ms/step - loss: 0.2754 - val_loss: 0.2821\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.2758 - val_loss: 0.3342\n",
      "Epoch 73/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.2755 - val_loss: 0.2877\n",
      "Epoch 74/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.2747 - val_loss: 0.3277\n",
      "Epoch 75/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.2730 - val_loss: 0.3125\n",
      "Epoch 76/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.2753 - val_loss: 0.3086\n",
      "Epoch 77/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.2720 - val_loss: 0.2876\n",
      "Epoch 78/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.2730 - val_loss: 0.3130\n",
      "Epoch 79/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.2727 - val_loss: 0.3405\n",
      "Epoch 80/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.2720 - val_loss: 0.2838\n",
      "Epoch 81/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.2725 - val_loss: 0.3118\n",
      "Epoch 82/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.2738 - val_loss: 0.2837\n",
      "Epoch 83/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.2709 - val_loss: 0.2996\n",
      "Epoch 84/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 0.2722 - val_loss: 0.2941\n",
      "Epoch 85/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 0.2703 - val_loss: 0.2820\n",
      "Epoch 86/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 0.2710 - val_loss: 0.2814\n",
      "Epoch 87/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.2704 - val_loss: 0.2795\n",
      "Epoch 88/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.2697 - val_loss: 0.3201\n",
      "Epoch 89/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.2695 - val_loss: 0.3268\n",
      "Epoch 90/100\n",
      "242/242 [==============================] - 2s 9ms/step - loss: 0.2693 - val_loss: 0.2781\n",
      "Epoch 91/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.2674 - val_loss: 0.2832\n",
      "Epoch 92/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.2692 - val_loss: 0.3250\n",
      "Epoch 93/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.2681 - val_loss: 0.3257\n",
      "Epoch 94/100\n",
      "242/242 [==============================] - 2s 8ms/step - loss: 0.2682 - val_loss: 0.2973\n",
      "Epoch 95/100\n",
      "242/242 [==============================] - 2s 9ms/step - loss: 0.2666 - val_loss: 0.2913\n",
      "Epoch 96/100\n",
      "242/242 [==============================] - 2s 10ms/step - loss: 0.2671 - val_loss: 0.2854\n",
      "Epoch 97/100\n",
      "242/242 [==============================] - 5s 20ms/step - loss: 0.2659 - val_loss: 0.2845\n",
      "Epoch 98/100\n",
      "242/242 [==============================] - 2s 10ms/step - loss: 0.2679 - val_loss: 0.3180\n",
      "Epoch 99/100\n",
      "242/242 [==============================] - 3s 11ms/step - loss: 0.2649 - val_loss: 0.2868\n",
      "Epoch 100/100\n",
      "242/242 [==============================] - 2s 10ms/step - loss: 0.2655 - val_loss: 0.2840\n",
      "121/121 [==============================] - 1s 5ms/step - loss: 0.2977\n",
      "[CV]  learning_rate=0.00802851624285897, n_hidden=3, n_neurons=23, total= 3.0min\n",
      "[CV] learning_rate=0.00802851624285897, n_hidden=3, n_neurons=23 .....\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 2s 10ms/step - loss: 0.9852 - val_loss: 11.1605\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 2s 8ms/step - loss: 0.6600 - val_loss: 2.8180\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 2s 8ms/step - loss: 0.4811 - val_loss: 0.5649\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 2s 9ms/step - loss: 0.4327 - val_loss: 0.3924\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.4101 - val_loss: 0.3963\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 2s 8ms/step - loss: 0.3976 - val_loss: 0.3840\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 3s 12ms/step - loss: 0.3908 - val_loss: 0.3742\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 2s 10ms/step - loss: 0.3874 - val_loss: 0.4057\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 2s 9ms/step - loss: 0.3791 - val_loss: 0.3586\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 2s 9ms/step - loss: 0.3746 - val_loss: 0.3993\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 2s 9ms/step - loss: 0.3707 - val_loss: 0.3574\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.3672 - val_loss: 0.3620\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 2s 8ms/step - loss: 0.3624 - val_loss: 0.4235\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.3624 - val_loss: 0.3624\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.3575 - val_loss: 0.3594\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 0.3568 - val_loss: 0.3693\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.3540 - val_loss: 0.3886\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.3520 - val_loss: 0.4027\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.3535 - val_loss: 0.3539\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 0.3474 - val_loss: 0.3477\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 0.3453 - val_loss: 0.3340\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 0.3412 - val_loss: 0.3410\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 0.3409 - val_loss: 0.4044\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 0.3394 - val_loss: 0.4024\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 0.3373 - val_loss: 0.3507\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 0.3359 - val_loss: 0.3417\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.3334 - val_loss: 0.3758\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.3342 - val_loss: 0.3794\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.3313 - val_loss: 0.3617\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 0.3306 - val_loss: 0.3254\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.3282 - val_loss: 0.3807\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.3265 - val_loss: 0.3231\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 0.3259 - val_loss: 0.3622\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.3267 - val_loss: 0.3663\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.3231 - val_loss: 0.3170\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.3206 - val_loss: 0.5095\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.3241 - val_loss: 0.3258\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.3210 - val_loss: 0.4857\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.3208 - val_loss: 0.4499\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.3191 - val_loss: 0.3589\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.3183 - val_loss: 0.3463\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.3172 - val_loss: 0.3699\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.3158 - val_loss: 0.3297\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.3129 - val_loss: 0.4006\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.3133 - val_loss: 0.3072\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.3104 - val_loss: 0.3184\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.3091 - val_loss: 0.3740\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.3159 - val_loss: 0.4064\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.3130 - val_loss: 0.4464\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.3107 - val_loss: 0.3456\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.3081 - val_loss: 0.3786\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 0.3069 - val_loss: 0.3676\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 0.3052 - val_loss: 0.3485\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 0.3046 - val_loss: 0.3487\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.3050 - val_loss: 0.5257\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.3036 - val_loss: 0.3712\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 0.3017 - val_loss: 0.3733\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.2997 - val_loss: 0.3216\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 0.2985 - val_loss: 0.4210\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.2983 - val_loss: 0.3021\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 0.2957 - val_loss: 0.3081\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 0.2956 - val_loss: 0.3204\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 0.2964 - val_loss: 0.4800\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 0.2979 - val_loss: 0.4116\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.2958 - val_loss: 0.3101\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.2916 - val_loss: 0.2986\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 0.2913 - val_loss: 0.3355\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 0.2902 - val_loss: 0.3342\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.2909 - val_loss: 0.3063\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.2899 - val_loss: 0.3409\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 0.2889 - val_loss: 0.3711\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.2880 - val_loss: 0.3054\n",
      "Epoch 73/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 0.2873 - val_loss: 0.3765\n",
      "Epoch 74/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 0.2870 - val_loss: 0.3171\n",
      "Epoch 75/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 0.2880 - val_loss: 0.3270\n",
      "Epoch 76/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 0.2880 - val_loss: 0.3823\n",
      "Epoch 77/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 0.2863 - val_loss: 0.3038\n",
      "Epoch 78/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 0.2894 - val_loss: 0.3204\n",
      "Epoch 79/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.2858 - val_loss: 0.3244\n",
      "Epoch 80/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.2858 - val_loss: 0.2981\n",
      "Epoch 81/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.2833 - val_loss: 0.3233\n",
      "Epoch 82/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.2842 - val_loss: 0.2989\n",
      "Epoch 83/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.2843 - val_loss: 0.3199\n",
      "Epoch 84/100\n",
      "242/242 [==============================] - 2s 8ms/step - loss: 0.2824 - val_loss: 0.2881\n",
      "Epoch 85/100\n",
      "242/242 [==============================] - 2s 8ms/step - loss: 0.2825 - val_loss: 0.3630\n",
      "Epoch 86/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.2809 - val_loss: 0.3257\n",
      "Epoch 87/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.2796 - val_loss: 0.3202\n",
      "Epoch 88/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.2795 - val_loss: 0.3683\n",
      "Epoch 89/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.2800 - val_loss: 0.2838\n",
      "Epoch 90/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 0.2787 - val_loss: 0.3741\n",
      "Epoch 91/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.2780 - val_loss: 0.3807\n",
      "Epoch 92/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.2768 - val_loss: 0.5081\n",
      "Epoch 93/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.2757 - val_loss: 0.2940\n",
      "Epoch 94/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.2776 - val_loss: 0.3977\n",
      "Epoch 95/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.2762 - val_loss: 0.3084\n",
      "Epoch 96/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.2755 - val_loss: 0.3313\n",
      "Epoch 97/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.2738 - val_loss: 0.3397\n",
      "Epoch 98/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 0.2752 - val_loss: 0.3657\n",
      "Epoch 99/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.2755 - val_loss: 0.2860\n",
      "Epoch 100/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.2765 - val_loss: 0.3375\n",
      "121/121 [==============================] - 0s 3ms/step - loss: 0.2973\n",
      "[CV]  learning_rate=0.00802851624285897, n_hidden=3, n_neurons=23, total= 2.8min\n",
      "[CV] learning_rate=0.0023264278584144756, n_hidden=2, n_neurons=53 ...\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 1.3898 - val_loss: 1.3497\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.6386 - val_loss: 0.6446\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 0.5625 - val_loss: 0.5070\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.5150 - val_loss: 0.4800\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.4799 - val_loss: 0.4534\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.4554 - val_loss: 0.4285\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.4373 - val_loss: 0.4627\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.4235 - val_loss: 0.4321\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.4138 - val_loss: 0.3903\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.4054 - val_loss: 0.4736\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3990 - val_loss: 0.4360\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 0.3926 - val_loss: 0.4019\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3865 - val_loss: 0.4151\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3808 - val_loss: 0.4377\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3767 - val_loss: 0.4288\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3726 - val_loss: 0.3846\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3678 - val_loss: 0.4246\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3648 - val_loss: 0.3487\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3615 - val_loss: 0.4245\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3589 - val_loss: 0.3497\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3561 - val_loss: 0.4422\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3541 - val_loss: 0.3861\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3514 - val_loss: 0.4042\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3493 - val_loss: 0.3347\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3472 - val_loss: 0.4696\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.3463 - val_loss: 0.3331\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 0.3439 - val_loss: 0.3885\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3420 - val_loss: 0.4073\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3408 - val_loss: 0.3436\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3390 - val_loss: 0.4166\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3380 - val_loss: 0.3245\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3360 - val_loss: 0.3617\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3347 - val_loss: 0.4048\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3339 - val_loss: 0.3248\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3328 - val_loss: 0.4553\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3322 - val_loss: 0.3655\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3302 - val_loss: 0.3848\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3301 - val_loss: 0.3210\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3283 - val_loss: 0.4581\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3286 - val_loss: 0.3207\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3272 - val_loss: 0.3807\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3258 - val_loss: 0.3920\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.3250 - val_loss: 0.3789\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.3241 - val_loss: 0.4022\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 2s 8ms/step - loss: 0.3236 - val_loss: 0.3147\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.3224 - val_loss: 0.3342\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 2s 10ms/step - loss: 0.3215 - val_loss: 0.4319\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 2s 8ms/step - loss: 0.3212 - val_loss: 0.3502\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 3s 11ms/step - loss: 0.3199 - val_loss: 0.3272\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 3s 12ms/step - loss: 0.3200 - val_loss: 0.3267\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 2s 8ms/step - loss: 0.3187 - val_loss: 0.3676\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 0.3184 - val_loss: 0.3702\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.3180 - val_loss: 0.3694\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3174 - val_loss: 0.3240\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3155 - val_loss: 0.3974\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3162 - val_loss: 0.3146\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3151 - val_loss: 0.4621\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3150 - val_loss: 0.3534\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.3135 - val_loss: 0.4069\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 2s 8ms/step - loss: 0.3135 - val_loss: 0.3623\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 2s 10ms/step - loss: 0.3130 - val_loss: 0.3084\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.3122 - val_loss: 0.3301\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3113 - val_loss: 0.3715\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3112 - val_loss: 0.4107\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3103 - val_loss: 0.3124\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3101 - val_loss: 0.4313\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3094 - val_loss: 0.3036\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3094 - val_loss: 0.3440\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3087 - val_loss: 0.3170\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3076 - val_loss: 0.4185\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3079 - val_loss: 0.3573\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3067 - val_loss: 0.3902\n",
      "Epoch 73/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3069 - val_loss: 0.3463\n",
      "Epoch 74/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3063 - val_loss: 0.3831\n",
      "Epoch 75/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3049 - val_loss: 0.3960\n",
      "Epoch 76/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3044 - val_loss: 0.3830\n",
      "Epoch 77/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3045 - val_loss: 0.3418\n",
      "Epoch 78/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3041 - val_loss: 0.4162\n",
      "Epoch 79/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3042 - val_loss: 0.3039\n",
      "Epoch 80/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3038 - val_loss: 0.3563\n",
      "Epoch 81/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3027 - val_loss: 0.3714\n",
      "Epoch 82/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3022 - val_loss: 0.3796\n",
      "Epoch 83/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3013 - val_loss: 0.3780\n",
      "Epoch 84/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3014 - val_loss: 0.3060\n",
      "Epoch 85/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3016 - val_loss: 0.3387\n",
      "Epoch 86/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3005 - val_loss: 0.4020\n",
      "Epoch 87/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.2998 - val_loss: 0.3450\n",
      "Epoch 88/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.2998 - val_loss: 0.3004\n",
      "Epoch 89/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.2991 - val_loss: 0.3289\n",
      "Epoch 90/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.2985 - val_loss: 0.4437\n",
      "Epoch 91/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.2987 - val_loss: 0.2959\n",
      "Epoch 92/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.2980 - val_loss: 0.4684\n",
      "Epoch 93/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.2986 - val_loss: 0.3231\n",
      "Epoch 94/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.2966 - val_loss: 0.4024\n",
      "Epoch 95/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.2966 - val_loss: 0.3443\n",
      "Epoch 96/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.2961 - val_loss: 0.3163\n",
      "Epoch 97/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.2953 - val_loss: 0.4332\n",
      "Epoch 98/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.2959 - val_loss: 0.3224\n",
      "Epoch 99/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.2944 - val_loss: 0.2959\n",
      "Epoch 100/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.2947 - val_loss: 0.5110\n",
      "121/121 [==============================] - 0s 3ms/step - loss: 0.3242\n",
      "[CV]  learning_rate=0.0023264278584144756, n_hidden=2, n_neurons=53, total= 2.5min\n",
      "[CV] learning_rate=0.0023264278584144756, n_hidden=2, n_neurons=53 ...\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 1.2430 - val_loss: 3.3885\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.6977 - val_loss: 0.8355\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.6090 - val_loss: 0.5979\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.5488 - val_loss: 0.9028\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.5054 - val_loss: 1.1119\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.4736 - val_loss: 1.1651\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.4503 - val_loss: 0.9667\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.4333 - val_loss: 0.8719\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.4202 - val_loss: 0.5901\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.4108 - val_loss: 0.6103\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.4032 - val_loss: 0.4437\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3962 - val_loss: 0.3998\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3911 - val_loss: 0.3664\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 0.3864 - val_loss: 0.3670\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 0.3835 - val_loss: 0.3939\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 0.3796 - val_loss: 0.3940\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.3759 - val_loss: 0.4977\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 0.3736 - val_loss: 0.4435\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.3711 - val_loss: 0.5055\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 0.3688 - val_loss: 0.4655\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 0.3664 - val_loss: 0.5375\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3645 - val_loss: 0.5176\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3633 - val_loss: 0.5483\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3612 - val_loss: 0.5370\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3599 - val_loss: 0.5281\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3586 - val_loss: 0.5172\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3573 - val_loss: 0.5538\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3561 - val_loss: 0.5378\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3549 - val_loss: 0.6090\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3533 - val_loss: 0.5837\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3526 - val_loss: 0.5663\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3515 - val_loss: 0.5422\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3502 - val_loss: 0.4894\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3495 - val_loss: 0.4892\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3486 - val_loss: 0.5003\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3478 - val_loss: 0.4955\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3467 - val_loss: 0.4840\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3461 - val_loss: 0.5374\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3450 - val_loss: 0.5027\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3443 - val_loss: 0.4413\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3435 - val_loss: 0.4962\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3432 - val_loss: 0.4869\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3416 - val_loss: 0.4452\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3413 - val_loss: 0.4872\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.3404 - val_loss: 0.4282\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 0.3404 - val_loss: 0.4262\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.3393 - val_loss: 0.4297\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3386 - val_loss: 0.4002\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3377 - val_loss: 0.4413\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3375 - val_loss: 0.4268\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 0.3371 - val_loss: 0.4683\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 0.3360 - val_loss: 0.4567\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3356 - val_loss: 0.4104\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3351 - val_loss: 0.4360\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 0.3347 - val_loss: 0.4399\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3339 - val_loss: 0.4251\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3336 - val_loss: 0.4078\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3328 - val_loss: 0.4212\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3321 - val_loss: 0.4045\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3320 - val_loss: 0.4177\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 0.3309 - val_loss: 0.4523\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3299 - val_loss: 0.4596\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3296 - val_loss: 0.4430\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3293 - val_loss: 0.4520\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3283 - val_loss: 0.4291\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.3287 - val_loss: 0.4701\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3278 - val_loss: 0.4770\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 0.3277 - val_loss: 0.4177\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3269 - val_loss: 0.4356\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3264 - val_loss: 0.4369\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.3259 - val_loss: 0.4051\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3256 - val_loss: 0.4445\n",
      "Epoch 73/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3249 - val_loss: 0.4384\n",
      "Epoch 74/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3241 - val_loss: 0.4687\n",
      "Epoch 75/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 0.3238 - val_loss: 0.3984\n",
      "Epoch 76/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3232 - val_loss: 0.4055\n",
      "Epoch 77/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3223 - val_loss: 0.4302\n",
      "Epoch 78/100\n",
      "242/242 [==============================] - 2s 8ms/step - loss: 0.3218 - val_loss: 0.3926\n",
      "Epoch 79/100\n",
      "242/242 [==============================] - 2s 8ms/step - loss: 0.3220 - val_loss: 0.4032\n",
      "Epoch 80/100\n",
      "242/242 [==============================] - 2s 9ms/step - loss: 0.3218 - val_loss: 0.4509\n",
      "Epoch 81/100\n",
      "242/242 [==============================] - 2s 10ms/step - loss: 0.3207 - val_loss: 0.4181\n",
      "Epoch 82/100\n",
      "242/242 [==============================] - 2s 10ms/step - loss: 0.3205 - val_loss: 0.3873\n",
      "Epoch 83/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 0.3204 - val_loss: 0.4003\n",
      "Epoch 84/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3201 - val_loss: 0.4021\n",
      "Epoch 85/100\n",
      "242/242 [==============================] - 2s 8ms/step - loss: 0.3189 - val_loss: 0.4372\n",
      "Epoch 86/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.3187 - val_loss: 0.4488\n",
      "Epoch 87/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.3187 - val_loss: 0.4674\n",
      "Epoch 88/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3181 - val_loss: 0.4615\n",
      "Epoch 89/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3173 - val_loss: 0.3802\n",
      "Epoch 90/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3171 - val_loss: 0.4288\n",
      "Epoch 91/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3169 - val_loss: 0.4370\n",
      "Epoch 92/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3171 - val_loss: 0.3988\n",
      "Epoch 93/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3158 - val_loss: 0.4620\n",
      "Epoch 94/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3155 - val_loss: 0.3948\n",
      "Epoch 95/100\n",
      "242/242 [==============================] - 2s 8ms/step - loss: 0.3148 - val_loss: 0.3768\n",
      "Epoch 96/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.3151 - val_loss: 0.3896\n",
      "Epoch 97/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 0.3144 - val_loss: 0.4082\n",
      "Epoch 98/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 0.3142 - val_loss: 0.4246\n",
      "Epoch 99/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3139 - val_loss: 0.3777\n",
      "Epoch 100/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3132 - val_loss: 0.3519\n",
      "121/121 [==============================] - 0s 4ms/step - loss: 0.3334\n",
      "[CV]  learning_rate=0.0023264278584144756, n_hidden=2, n_neurons=53, total= 2.5min\n",
      "[CV] learning_rate=0.0023264278584144756, n_hidden=2, n_neurons=53 ...\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 1.4527 - val_loss: 5.5637\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 0.6053 - val_loss: 2.8480\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.5251 - val_loss: 0.7110\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.4772 - val_loss: 0.7532\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.4512 - val_loss: 0.4282\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 2s 8ms/step - loss: 0.4336 - val_loss: 0.4104\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.4215 - val_loss: 0.4011\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.4125 - val_loss: 0.3861\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.4054 - val_loss: 0.3929\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3995 - val_loss: 0.3842\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3946 - val_loss: 0.4522\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 2s 9ms/step - loss: 0.3891 - val_loss: 0.5285\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 2s 10ms/step - loss: 0.3875 - val_loss: 0.3665\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 2s 8ms/step - loss: 0.3829 - val_loss: 0.5034\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 0.3815 - val_loss: 0.4044\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.3771 - val_loss: 0.6111\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3776 - val_loss: 0.3612\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3720 - val_loss: 0.6404\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3733 - val_loss: 0.5084\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.3701 - val_loss: 0.8770\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.3719 - val_loss: 0.3477\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.3640 - val_loss: 0.5571\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3639 - val_loss: 0.3757\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3603 - val_loss: 0.4469\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.3604 - val_loss: 0.3582\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 2s 9ms/step - loss: 0.3583 - val_loss: 0.3732\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.3571 - val_loss: 0.4560\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3562 - val_loss: 0.3601\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 0.3538 - val_loss: 0.4102\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3533 - val_loss: 0.3618\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3507 - val_loss: 0.5118\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3518 - val_loss: 0.5017\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3518 - val_loss: 1.0082\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.3572 - val_loss: 0.3716\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3485 - val_loss: 0.6317\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3499 - val_loss: 0.3344\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3457 - val_loss: 0.3301\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3447 - val_loss: 0.3308\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3440 - val_loss: 0.3467\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3431 - val_loss: 0.3333\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.3414 - val_loss: 0.4977\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3425 - val_loss: 0.3294\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.3399 - val_loss: 0.5007\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3427 - val_loss: 0.4345\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3398 - val_loss: 0.3662\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.3388 - val_loss: 0.3356\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 0.3374 - val_loss: 0.5755\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 2s 8ms/step - loss: 0.3402 - val_loss: 0.3302\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 2s 9ms/step - loss: 0.3371 - val_loss: 0.5192\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.3381 - val_loss: 0.6001\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 0.3376 - val_loss: 0.6094\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 0.3376 - val_loss: 0.8574\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3379 - val_loss: 0.9565\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 0.3413 - val_loss: 0.3815\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.3335 - val_loss: 0.5063\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3341 - val_loss: 0.3975\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3338 - val_loss: 0.9110\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.3346 - val_loss: 2.1346\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 0.3396 - val_loss: 2.2325\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3449 - val_loss: 1.1694\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 0.3381 - val_loss: 0.9488\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3378 - val_loss: 0.4074\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 2s 8ms/step - loss: 0.3299 - val_loss: 0.7311\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.3327 - val_loss: 0.3304\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3281 - val_loss: 0.7668\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3320 - val_loss: 1.1847\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3357 - val_loss: 0.9223\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3351 - val_loss: 0.3923\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3274 - val_loss: 0.5811\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3286 - val_loss: 0.8088\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3330 - val_loss: 1.5181\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3397 - val_loss: 0.6398\n",
      "Epoch 73/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3271 - val_loss: 0.4389\n",
      "Epoch 74/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3279 - val_loss: 0.6314\n",
      "Epoch 75/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3258 - val_loss: 0.7127\n",
      "Epoch 76/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3279 - val_loss: 0.4732\n",
      "Epoch 77/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3244 - val_loss: 0.7299\n",
      "Epoch 78/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3267 - val_loss: 1.1147\n",
      "Epoch 79/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3287 - val_loss: 0.8488\n",
      "Epoch 80/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3296 - val_loss: 0.7541\n",
      "Epoch 81/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3286 - val_loss: 1.0861\n",
      "Epoch 82/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3273 - val_loss: 0.9118\n",
      "Epoch 83/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3251 - val_loss: 0.5791\n",
      "Epoch 84/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3219 - val_loss: 0.6525\n",
      "Epoch 85/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3233 - val_loss: 0.6703\n",
      "Epoch 86/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3236 - val_loss: 0.3259\n",
      "Epoch 87/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3184 - val_loss: 0.3204\n",
      "Epoch 88/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3184 - val_loss: 0.3107\n",
      "Epoch 89/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.3177 - val_loss: 0.4345\n",
      "Epoch 90/100\n",
      "242/242 [==============================] - 2s 9ms/step - loss: 0.3189 - val_loss: 0.4871\n",
      "Epoch 91/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3181 - val_loss: 0.6156\n",
      "Epoch 92/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3193 - val_loss: 0.4916\n",
      "Epoch 93/100\n",
      "242/242 [==============================] - 2s 8ms/step - loss: 0.3170 - val_loss: 0.5120\n",
      "Epoch 94/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3170 - val_loss: 0.3096\n",
      "Epoch 95/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3151 - val_loss: 0.3355\n",
      "Epoch 96/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3152 - val_loss: 0.3086\n",
      "Epoch 97/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3142 - val_loss: 0.3097\n",
      "Epoch 98/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3132 - val_loss: 0.3543\n",
      "Epoch 99/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.3130 - val_loss: 0.3097\n",
      "Epoch 100/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.3128 - val_loss: 0.3082\n",
      "121/121 [==============================] - 0s 3ms/step - loss: 0.3233\n",
      "[CV]  learning_rate=0.0023264278584144756, n_hidden=2, n_neurons=53, total= 2.5min\n",
      "[CV] learning_rate=0.0007340460296244593, n_hidden=2, n_neurons=9 ....\n",
      "Epoch 1/100\n",
      "  1/242 [..............................] - ETA: 0s - loss: 10.5142WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0000s vs `on_train_batch_end` time: 0.0040s). Check your callbacks.\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 4.3857 - val_loss: 2.0491\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 1.3339 - val_loss: 1.0071\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.9298 - val_loss: 0.8027\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.8420 - val_loss: 0.7515\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.8069 - val_loss: 0.7428\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.7873 - val_loss: 0.7416\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 0.7738 - val_loss: 0.7134\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.7630 - val_loss: 0.7088\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.7535 - val_loss: 0.6945\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.7449 - val_loss: 0.6871\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.7368 - val_loss: 0.6816\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.7291 - val_loss: 0.6765\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.7219 - val_loss: 0.6661\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.7147 - val_loss: 0.6594\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.7078 - val_loss: 0.6527\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.7010 - val_loss: 0.6465\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.6946 - val_loss: 0.6407\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.6882 - val_loss: 0.6356\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.6821 - val_loss: 0.6303\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.6762 - val_loss: 0.6257\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.6703 - val_loss: 0.6201\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.6645 - val_loss: 0.6164\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.6588 - val_loss: 0.6093\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.6530 - val_loss: 0.6070\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.6475 - val_loss: 0.5996\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.6419 - val_loss: 0.5959\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.6365 - val_loss: 0.5918\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.6312 - val_loss: 0.5852\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.6258 - val_loss: 0.5802\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.6205 - val_loss: 0.5765\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.6151 - val_loss: 0.5705\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.6099 - val_loss: 0.5659\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.6045 - val_loss: 0.5622\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.5994 - val_loss: 0.5563\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.5940 - val_loss: 0.5538\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.5887 - val_loss: 0.5471\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.5832 - val_loss: 0.5422\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.5777 - val_loss: 0.5378\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.5724 - val_loss: 0.5326\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.5670 - val_loss: 0.5279\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.5614 - val_loss: 0.5230\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.5562 - val_loss: 0.5181\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.5507 - val_loss: 0.5134\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.5455 - val_loss: 0.5090\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.5404 - val_loss: 0.5044\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.5353 - val_loss: 0.5017\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.5300 - val_loss: 0.4951\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.5251 - val_loss: 0.4904\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.5200 - val_loss: 0.4857\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.5149 - val_loss: 0.4816\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.5099 - val_loss: 0.4772\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.5051 - val_loss: 0.4711\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.5001 - val_loss: 0.4671\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.4955 - val_loss: 0.4650\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.4905 - val_loss: 0.4579\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.4862 - val_loss: 0.4559\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.4816 - val_loss: 0.4534\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.4774 - val_loss: 0.4515\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.4732 - val_loss: 0.4470\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.4692 - val_loss: 0.4475\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.4655 - val_loss: 0.4435\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.4618 - val_loss: 0.4374\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.4583 - val_loss: 0.4345\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.4550 - val_loss: 0.4324\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.4519 - val_loss: 0.4328\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.4487 - val_loss: 0.4310\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.4457 - val_loss: 0.4317\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 0.4427 - val_loss: 0.4300\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.4400 - val_loss: 0.4307\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.4375 - val_loss: 0.4316\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.4351 - val_loss: 0.4238\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.4328 - val_loss: 0.4284\n",
      "Epoch 73/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.4307 - val_loss: 0.4277\n",
      "Epoch 74/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 0.4286 - val_loss: 0.4187\n",
      "Epoch 75/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.4269 - val_loss: 0.4210\n",
      "Epoch 76/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.4250 - val_loss: 0.4197\n",
      "Epoch 77/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 0.4233 - val_loss: 0.4133\n",
      "Epoch 78/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.4219 - val_loss: 0.4268\n",
      "Epoch 79/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.4204 - val_loss: 0.4200\n",
      "Epoch 80/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.4191 - val_loss: 0.4231\n",
      "Epoch 81/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 0.4179 - val_loss: 0.4207\n",
      "Epoch 82/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.4167 - val_loss: 0.4247\n",
      "Epoch 83/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 0.4154 - val_loss: 0.4252\n",
      "Epoch 84/100\n",
      "242/242 [==============================] - 2s 9ms/step - loss: 0.4144 - val_loss: 0.4148\n",
      "Epoch 85/100\n",
      "242/242 [==============================] - 3s 12ms/step - loss: 0.4134 - val_loss: 0.4180: 2s - lo\n",
      "Epoch 86/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.4124 - val_loss: 0.4259\n",
      "Epoch 87/100\n",
      "242/242 [==============================] - 2s 6ms/step - loss: 0.4115 - val_loss: 0.4383\n",
      "Epoch 88/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.4108 - val_loss: 0.4228\n",
      "Epoch 89/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.4097 - val_loss: 0.4128\n",
      "Epoch 90/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.4091 - val_loss: 0.4214\n",
      "Epoch 91/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 0.4083 - val_loss: 0.4241\n",
      "Epoch 92/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.4075 - val_loss: 0.4171\n",
      "Epoch 93/100\n",
      "242/242 [==============================] - 2s 10ms/step - loss: 0.4068 - val_loss: 0.4081\n",
      "Epoch 94/100\n",
      "242/242 [==============================] - 2s 10ms/step - loss: 0.4060 - val_loss: 0.4214\n",
      "Epoch 95/100\n",
      "242/242 [==============================] - 2s 10ms/step - loss: 0.4053 - val_loss: 0.4165\n",
      "Epoch 96/100\n",
      "242/242 [==============================] - 3s 11ms/step - loss: 0.4047 - val_loss: 0.4203\n",
      "Epoch 97/100\n",
      "242/242 [==============================] - 3s 10ms/step - loss: 0.4040 - val_loss: 0.4165\n",
      "Epoch 98/100\n",
      "242/242 [==============================] - 2s 9ms/step - loss: 0.4034 - val_loss: 0.4144\n",
      "Epoch 99/100\n",
      "242/242 [==============================] - 2s 10ms/step - loss: 0.4026 - val_loss: 0.4154\n",
      "Epoch 100/100\n",
      "242/242 [==============================] - 2s 10ms/step - loss: 0.4020 - val_loss: 0.4145\n",
      "121/121 [==============================] - 1s 5ms/step - loss: 0.4188\n",
      "[CV]  learning_rate=0.0007340460296244593, n_hidden=2, n_neurons=9, total= 2.5min\n",
      "[CV] learning_rate=0.0007340460296244593, n_hidden=2, n_neurons=9 ....\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 3s 11ms/step - loss: 3.4113 - val_loss: 6.2639\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 2s 9ms/step - loss: 1.2985 - val_loss: 4.6223\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 3s 11ms/step - loss: 0.9249 - val_loss: 5.4370\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 3s 11ms/step - loss: 0.8016 - val_loss: 6.3322\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 3s 11ms/step - loss: 0.7352 - val_loss: 7.2195\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 2s 10ms/step - loss: 0.6878 - val_loss: 7.9812\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 3s 11ms/step - loss: 0.6503 - val_loss: 8.7073\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 2s 10ms/step - loss: 0.6198 - val_loss: 9.1720\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 2s 10ms/step - loss: 0.5938 - val_loss: 9.5403\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 3s 11ms/step - loss: 0.5722 - val_loss: 10.0360\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 3s 12ms/step - loss: 0.5533 - val_loss: 10.3240\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 3s 11ms/step - loss: 0.5373 - val_loss: 10.5153\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 2s 10ms/step - loss: 0.5234 - val_loss: 10.4480\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 2s 10ms/step - loss: 0.5117 - val_loss: 10.3890\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 3s 11ms/step - loss: 0.5015 - val_loss: 10.3244\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 2s 10ms/step - loss: 0.4925 - val_loss: 10.1349\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 3s 12ms/step - loss: 0.4846 - val_loss: 9.8729\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 3s 11ms/step - loss: 0.4779 - val_loss: 9.6757\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 3s 12ms/step - loss: 0.4719 - val_loss: 9.4135\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 2s 10ms/step - loss: 0.4666 - val_loss: 9.0871\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 2s 10ms/step - loss: 0.4619 - val_loss: 8.7531\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 2s 8ms/step - loss: 0.4577 - val_loss: 8.3921\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 2s 10ms/step - loss: 0.4540 - val_loss: 8.0733\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 2s 9ms/step - loss: 0.4505 - val_loss: 7.7853\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 2s 8ms/step - loss: 0.4474 - val_loss: 7.4628\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 2s 9ms/step - loss: 0.4446 - val_loss: 7.1562\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 2s 9ms/step - loss: 0.4420 - val_loss: 6.8047\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 2s 9ms/step - loss: 0.4396 - val_loss: 6.5330\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 2s 8ms/step - loss: 0.4372 - val_loss: 6.1811\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 2s 9ms/step - loss: 0.4352 - val_loss: 5.8571\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 2s 9ms/step - loss: 0.4333 - val_loss: 5.5215\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 2s 9ms/step - loss: 0.4314 - val_loss: 5.2290\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 2s 9ms/step - loss: 0.4297 - val_loss: 4.9168\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 2s 9ms/step - loss: 0.4280 - val_loss: 4.6035\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 2s 9ms/step - loss: 0.4262 - val_loss: 4.3109\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 2s 9ms/step - loss: 0.4250 - val_loss: 4.0968\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 2s 9ms/step - loss: 0.4234 - val_loss: 3.8388\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 2s 9ms/step - loss: 0.4221 - val_loss: 3.6143\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 2s 8ms/step - loss: 0.4207 - val_loss: 3.4015\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 2s 8ms/step - loss: 0.4194 - val_loss: 3.1634\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 2s 8ms/step - loss: 0.4180 - val_loss: 2.9574\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 2s 9ms/step - loss: 0.4168 - val_loss: 2.7715\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 2s 10ms/step - loss: 0.4156 - val_loss: 2.6176\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 2s 8ms/step - loss: 0.4143 - val_loss: 2.4628\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 2s 9ms/step - loss: 0.4129 - val_loss: 2.2574\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 2s 9ms/step - loss: 0.4118 - val_loss: 2.1320\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 2s 10ms/step - loss: 0.4104 - val_loss: 1.9885\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 2s 9ms/step - loss: 0.4098 - val_loss: 1.8953\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 2s 10ms/step - loss: 0.4087 - val_loss: 1.7865\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 2s 9ms/step - loss: 0.4076 - val_loss: 1.6406\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 2s 9ms/step - loss: 0.4066 - val_loss: 1.5512\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 2s 8ms/step - loss: 0.4056 - val_loss: 1.4497\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 2s 10ms/step - loss: 0.4047 - val_loss: 1.3365\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 3s 11ms/step - loss: 0.4038 - val_loss: 1.2779\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 2s 10ms/step - loss: 0.4030 - val_loss: 1.1915\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 2s 9ms/step - loss: 0.4021 - val_loss: 1.1108\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 2s 8ms/step - loss: 0.4014 - val_loss: 1.0410\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 2s 9ms/step - loss: 0.4007 - val_loss: 0.9690\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 2s 8ms/step - loss: 0.4000 - val_loss: 0.9079\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 2s 8ms/step - loss: 0.3993 - val_loss: 0.8523\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 2s 8ms/step - loss: 0.3986 - val_loss: 0.8000\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 2s 9ms/step - loss: 0.3979 - val_loss: 0.7448\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 2s 8ms/step - loss: 0.3974 - val_loss: 0.7064\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 2s 8ms/step - loss: 0.3967 - val_loss: 0.6624\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 2s 9ms/step - loss: 0.3961 - val_loss: 0.6240\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 2s 10ms/step - loss: 0.3955 - val_loss: 0.5897\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 2s 10ms/step - loss: 0.3948 - val_loss: 0.5660\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 2s 9ms/step - loss: 0.3945 - val_loss: 0.5335\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 2s 9ms/step - loss: 0.3937 - val_loss: 0.5071\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 2s 8ms/step - loss: 0.3934 - val_loss: 0.4861\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 2s 9ms/step - loss: 0.3930 - val_loss: 0.4695\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 2s 9ms/step - loss: 0.3924 - val_loss: 0.4501\n",
      "Epoch 73/100\n",
      "242/242 [==============================] - 2s 9ms/step - loss: 0.3920 - val_loss: 0.4385\n",
      "Epoch 74/100\n",
      "242/242 [==============================] - 2s 10ms/step - loss: 0.3914 - val_loss: 0.4216\n",
      "Epoch 75/100\n",
      "242/242 [==============================] - 2s 9ms/step - loss: 0.3909 - val_loss: 0.4140\n",
      "Epoch 76/100\n",
      "242/242 [==============================] - 2s 9ms/step - loss: 0.3905 - val_loss: 0.4055\n",
      "Epoch 77/100\n",
      "242/242 [==============================] - 2s 9ms/step - loss: 0.3901 - val_loss: 0.3936\n",
      "Epoch 78/100\n",
      "242/242 [==============================] - 2s 10ms/step - loss: 0.3897 - val_loss: 0.3853\n",
      "Epoch 79/100\n",
      "242/242 [==============================] - 2s 10ms/step - loss: 0.3891 - val_loss: 0.3805\n",
      "Epoch 80/100\n",
      "242/242 [==============================] - 2s 10ms/step - loss: 0.3888 - val_loss: 0.3745\n",
      "Epoch 81/100\n",
      "242/242 [==============================] - 2s 9ms/step - loss: 0.3884 - val_loss: 0.3718\n",
      "Epoch 82/100\n",
      "242/242 [==============================] - 2s 8ms/step - loss: 0.3880 - val_loss: 0.3696\n",
      "Epoch 83/100\n",
      "242/242 [==============================] - 2s 8ms/step - loss: 0.3876 - val_loss: 0.3683\n",
      "Epoch 84/100\n",
      "242/242 [==============================] - 2s 9ms/step - loss: 0.3871 - val_loss: 0.3673\n",
      "Epoch 85/100\n",
      "242/242 [==============================] - 2s 8ms/step - loss: 0.3868 - val_loss: 0.3662\n",
      "Epoch 86/100\n",
      "242/242 [==============================] - 2s 10ms/step - loss: 0.3865 - val_loss: 0.3657\n",
      "Epoch 87/100\n",
      "242/242 [==============================] - 2s 9ms/step - loss: 0.3861 - val_loss: 0.3652\n",
      "Epoch 88/100\n",
      "242/242 [==============================] - 2s 9ms/step - loss: 0.3858 - val_loss: 0.3659\n",
      "Epoch 89/100\n",
      "242/242 [==============================] - 2s 10ms/step - loss: 0.3854 - val_loss: 0.3649\n",
      "Epoch 90/100\n",
      "242/242 [==============================] - 2s 10ms/step - loss: 0.3851 - val_loss: 0.3652\n",
      "Epoch 91/100\n",
      "242/242 [==============================] - 2s 10ms/step - loss: 0.3848 - val_loss: 0.3665\n",
      "Epoch 92/100\n",
      "242/242 [==============================] - 2s 8ms/step - loss: 0.3845 - val_loss: 0.3664\n",
      "Epoch 93/100\n",
      "242/242 [==============================] - 2s 9ms/step - loss: 0.3841 - val_loss: 0.3670\n",
      "Epoch 94/100\n",
      "242/242 [==============================] - 2s 10ms/step - loss: 0.3838 - val_loss: 0.3684\n",
      "Epoch 95/100\n",
      "242/242 [==============================] - 2s 10ms/step - loss: 0.3835 - val_loss: 0.3669\n",
      "Epoch 96/100\n",
      "242/242 [==============================] - 2s 10ms/step - loss: 0.3831 - val_loss: 0.3670\n",
      "Epoch 97/100\n",
      "242/242 [==============================] - 2s 9ms/step - loss: 0.3828 - val_loss: 0.3689\n",
      "Epoch 98/100\n",
      "242/242 [==============================] - 2s 9ms/step - loss: 0.3826 - val_loss: 0.3703\n",
      "Epoch 99/100\n",
      "242/242 [==============================] - 2s 10ms/step - loss: 0.3823 - val_loss: 0.3704\n",
      "Epoch 100/100\n",
      "242/242 [==============================] - 2s 9ms/step - loss: 0.3820 - val_loss: 0.3711\n",
      "121/121 [==============================] - 1s 4ms/step - loss: 0.3948\n",
      "[CV]  learning_rate=0.0007340460296244593, n_hidden=2, n_neurons=9, total= 3.8min\n",
      "[CV] learning_rate=0.0007340460296244593, n_hidden=2, n_neurons=9 ....\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 2s 10ms/step - loss: 3.2832 - val_loss: 13.2932\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 2s 8ms/step - loss: 1.4098 - val_loss: 1.0147\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 2s 8ms/step - loss: 0.9350 - val_loss: 0.8528\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 2s 8ms/step - loss: 0.8348 - val_loss: 0.8132\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 2s 8ms/step - loss: 0.7961 - val_loss: 0.8005\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 2s 9ms/step - loss: 0.7734 - val_loss: 0.7988\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 2s 9ms/step - loss: 0.7562 - val_loss: 0.7412\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 2s 8ms/step - loss: 0.7411 - val_loss: 0.7483\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 2s 8ms/step - loss: 0.7284 - val_loss: 0.7107\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 2s 9ms/step - loss: 0.7159 - val_loss: 0.7102\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 2s 9ms/step - loss: 0.7047 - val_loss: 0.7356\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 2s 8ms/step - loss: 0.6941 - val_loss: 0.6679\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 2s 8ms/step - loss: 0.6837 - val_loss: 0.6494\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 2s 9ms/step - loss: 0.6739 - val_loss: 0.6466\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 2s 10ms/step - loss: 0.6644 - val_loss: 0.6541\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 2s 10ms/step - loss: 0.6551 - val_loss: 0.6353\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 2s 9ms/step - loss: 0.6460 - val_loss: 0.6174\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 2s 10ms/step - loss: 0.6372 - val_loss: 0.6182\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 2s 9ms/step - loss: 0.6283 - val_loss: 0.5980\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 2s 9ms/step - loss: 0.6198 - val_loss: 0.5885\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 2s 9ms/step - loss: 0.6111 - val_loss: 0.5841\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 2s 8ms/step - loss: 0.6026 - val_loss: 0.5743\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 2s 9ms/step - loss: 0.5939 - val_loss: 0.5894\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 2s 9ms/step - loss: 0.5853 - val_loss: 0.5633\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 2s 9ms/step - loss: 0.5759 - val_loss: 0.5380\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 2s 8ms/step - loss: 0.5670 - val_loss: 0.5415\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 2s 9ms/step - loss: 0.5572 - val_loss: 0.5162\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 2s 8ms/step - loss: 0.5477 - val_loss: 0.5102\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 2s 8ms/step - loss: 0.5384 - val_loss: 0.5110\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 2s 9ms/step - loss: 0.5292 - val_loss: 0.5191\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 2s 9ms/step - loss: 0.5210 - val_loss: 0.4786\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 2s 9ms/step - loss: 0.5135 - val_loss: 0.4886\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 2s 9ms/step - loss: 0.5062 - val_loss: 0.4763\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 2s 10ms/step - loss: 0.4995 - val_loss: 0.4689\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 2s 9ms/step - loss: 0.4932 - val_loss: 0.4724\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 2s 9ms/step - loss: 0.4873 - val_loss: 0.4520\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 2s 9ms/step - loss: 0.4818 - val_loss: 0.4542\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 2s 9ms/step - loss: 0.4768 - val_loss: 0.4383\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 2s 9ms/step - loss: 0.4721 - val_loss: 0.4317\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 2s 8ms/step - loss: 0.4674 - val_loss: 0.4272\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 2s 9ms/step - loss: 0.4635 - val_loss: 0.4262\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 2s 9ms/step - loss: 0.4592 - val_loss: 0.4212\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 2s 10ms/step - loss: 0.4558 - val_loss: 0.4159\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 2s 10ms/step - loss: 0.4522 - val_loss: 0.4128\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 2s 10ms/step - loss: 0.4488 - val_loss: 0.4101\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 2s 10ms/step - loss: 0.4457 - val_loss: 0.4070\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 2s 10ms/step - loss: 0.4425 - val_loss: 0.4036\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 2s 9ms/step - loss: 0.4394 - val_loss: 0.4008\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 2s 9ms/step - loss: 0.4365 - val_loss: 0.3991\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 2s 10ms/step - loss: 0.4340 - val_loss: 0.4032\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 2s 10ms/step - loss: 0.4316 - val_loss: 0.3971\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 2s 9ms/step - loss: 0.4289 - val_loss: 0.4071\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 2s 8ms/step - loss: 0.4267 - val_loss: 0.3917\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 2s 9ms/step - loss: 0.4244 - val_loss: 0.4002\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 2s 8ms/step - loss: 0.4224 - val_loss: 0.3864\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 2s 9ms/step - loss: 0.4206 - val_loss: 0.3911\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 2s 8ms/step - loss: 0.4189 - val_loss: 0.3909\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 2s 9ms/step - loss: 0.4172 - val_loss: 0.3876\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 2s 10ms/step - loss: 0.4152 - val_loss: 0.3813\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 2s 10ms/step - loss: 0.4137 - val_loss: 0.3896\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 2s 10ms/step - loss: 0.4124 - val_loss: 0.3994\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 2s 8ms/step - loss: 0.4108 - val_loss: 0.4060\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 2s 10ms/step - loss: 0.4100 - val_loss: 0.3922\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 2s 10ms/step - loss: 0.4084 - val_loss: 0.3879\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 2s 8ms/step - loss: 0.4072 - val_loss: 0.3854\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 2s 10ms/step - loss: 0.4059 - val_loss: 0.3951\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 2s 9ms/step - loss: 0.4048 - val_loss: 0.3773\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 3s 10ms/step - loss: 0.4038 - val_loss: 0.3912\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 2s 10ms/step - loss: 0.4028 - val_loss: 0.3763\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 2s 10ms/step - loss: 0.4016 - val_loss: 0.4061\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 2s 10ms/step - loss: 0.4009 - val_loss: 0.3904\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 2s 9ms/step - loss: 0.4000 - val_loss: 0.4065\n",
      "Epoch 73/100\n",
      "242/242 [==============================] - 2s 8ms/step - loss: 0.3992 - val_loss: 0.3936\n",
      "Epoch 74/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 0.3986 - val_loss: 0.3750\n",
      "Epoch 75/100\n",
      "242/242 [==============================] - 2s 8ms/step - loss: 0.3976 - val_loss: 0.3754\n",
      "Epoch 76/100\n",
      "242/242 [==============================] - 2s 9ms/step - loss: 0.3968 - val_loss: 0.4186\n",
      "Epoch 77/100\n",
      "242/242 [==============================] - 2s 8ms/step - loss: 0.3963 - val_loss: 0.3953\n",
      "Epoch 78/100\n",
      "242/242 [==============================] - 2s 9ms/step - loss: 0.3955 - val_loss: 0.3802\n",
      "Epoch 79/100\n",
      "242/242 [==============================] - 2s 9ms/step - loss: 0.3947 - val_loss: 0.3965\n",
      "Epoch 80/100\n",
      "242/242 [==============================] - 2s 9ms/step - loss: 0.3942 - val_loss: 0.3871\n",
      "Epoch 81/100\n",
      "242/242 [==============================] - 2s 9ms/step - loss: 0.3934 - val_loss: 0.3805\n",
      "Epoch 82/100\n",
      "242/242 [==============================] - 3s 10ms/step - loss: 0.3928 - val_loss: 0.4038\n",
      "Epoch 83/100\n",
      "242/242 [==============================] - 2s 9ms/step - loss: 0.3922 - val_loss: 0.4095\n",
      "Epoch 84/100\n",
      "242/242 [==============================] - 2s 9ms/step - loss: 0.3915 - val_loss: 0.4128\n",
      "Epoch 85/100\n",
      "242/242 [==============================] - 2s 8ms/step - loss: 0.3911 - val_loss: 0.4005\n",
      "Epoch 86/100\n",
      "242/242 [==============================] - 2s 9ms/step - loss: 0.3903 - val_loss: 0.4035\n",
      "Epoch 87/100\n",
      "242/242 [==============================] - 2s 9ms/step - loss: 0.3899 - val_loss: 0.3697\n",
      "Epoch 88/100\n",
      "242/242 [==============================] - 2s 10ms/step - loss: 0.3893 - val_loss: 0.3802\n",
      "Epoch 89/100\n",
      "242/242 [==============================] - 2s 9ms/step - loss: 0.3884 - val_loss: 0.3970\n",
      "Epoch 90/100\n",
      "242/242 [==============================] - 2s 9ms/step - loss: 0.3881 - val_loss: 0.3943\n",
      "Epoch 91/100\n",
      "242/242 [==============================] - 2s 8ms/step - loss: 0.3876 - val_loss: 0.3960\n",
      "Epoch 92/100\n",
      "242/242 [==============================] - 2s 8ms/step - loss: 0.3869 - val_loss: 0.4111\n",
      "Epoch 93/100\n",
      "242/242 [==============================] - 3s 11ms/step - loss: 0.3864 - val_loss: 0.3973\n",
      "Epoch 94/100\n",
      "242/242 [==============================] - 3s 11ms/step - loss: 0.3857 - val_loss: 0.3980\n",
      "Epoch 95/100\n",
      "242/242 [==============================] - 2s 9ms/step - loss: 0.3852 - val_loss: 0.4115\n",
      "Epoch 96/100\n",
      "242/242 [==============================] - 2s 10ms/step - loss: 0.3847 - val_loss: 0.4128\n",
      "Epoch 97/100\n",
      "242/242 [==============================] - 2s 8ms/step - loss: 0.3844 - val_loss: 0.3798\n",
      "Epoch 98/100\n",
      "242/242 [==============================] - 2s 8ms/step - loss: 0.3838 - val_loss: 0.3890\n",
      "Epoch 99/100\n",
      "242/242 [==============================] - 2s 8ms/step - loss: 0.3831 - val_loss: 0.4193\n",
      "Epoch 100/100\n",
      "242/242 [==============================] - 2s 8ms/step - loss: 0.3830 - val_loss: 0.3836\n",
      "121/121 [==============================] - 0s 4ms/step - loss: 0.3782\n",
      "[CV]  learning_rate=0.0007340460296244593, n_hidden=2, n_neurons=9, total= 3.7min\n",
      "[CV] learning_rate=0.005311235568439109, n_hidden=0, n_neurons=77 ....\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 2s 8ms/step - loss: 2.1520 - val_loss: 56.3698\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 1.6628 - val_loss: 85.9292\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 1.3985 - val_loss: 141.6084\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 2.3368 - val_loss: 251.2227\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 2s 7ms/step - loss: 2.8561 - val_loss: 459.6369\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 2s 8ms/step - loss: 8.6736 - val_loss: 742.5228\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 1s 6ms/step - loss: 5.1126 - val_loss: 1142.2052\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 20.2924 - val_loss: 1972.8693\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 22.2115 - val_loss: 3435.5386\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 23.0397 - val_loss: 6729.5757\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 42.9534 - val_loss: 11393.3525\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 185.3896 - val_loss: 20372.3809\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 307.0254 - val_loss: 36896.7383\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 525.5137 - val_loss: 65859.4609\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 1068.6039 - val_loss: 119457.8984\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 1948.9791 - val_loss: 213006.6875\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 1556.5233 - val_loss: 385445.6250\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 5127.3149 - val_loss: 692198.8125\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 6940.1538 - val_loss: 1283964.5000\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 13619.9395 - val_loss: 2303799.0000\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 17530.9590 - val_loss: 4161687.0000\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 40537.3242 - val_loss: 7462929.0000\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 118187.8594 - val_loss: 13495954.0000\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 93967.1250 - val_loss: 24566624.0000\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 174161.2031 - val_loss: 43957580.0000\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 623153.7500 - val_loss: 79166664.0000\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 591145.9375 - val_loss: 142886544.0000\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 1712405.3750 - val_loss: 256282144.0000\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 3423389.7500 - val_loss: 460185728.0000\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 5474757.0000 - val_loss: 861291392.0000\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 8472196.0000 - val_loss: 1543421184.0000\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 14597396.0000 - val_loss: 2790663424.0000\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 36318424.0000 - val_loss: 4995271680.0000\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 81427800.0000 - val_loss: 8980523008.0000\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 92668104.0000 - val_loss: 21114021888.0000\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 202016480.0000 - val_loss: 37984493568.0000\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 277287712.0000 - val_loss: 68816371712.0000\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 499378432.0000 - val_loss: 123322425344.0000\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 1480669568.0000 - val_loss: 220884107264.0000\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 1424833408.0000 - val_loss: 402834358272.0000\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 5216116224.0000 - val_loss: 725869461504.0000\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 8958778368.0000 - val_loss: 1300607533056.0000\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 10048156672.0000 - val_loss: 2338659762176.0000\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 38484889600.0000 - val_loss: 4249694765056.0000\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 44929667072.0000 - val_loss: 7655343521792.0000\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 55433719808.0000 - val_loss: 13776400154624.0000\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 160847446016.0000 - val_loss: 24678095650816.0000\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 256659374080.0000 - val_loss: 44262150373376.0000\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 507189723136.0000 - val_loss: 79493888737280.0000\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 736610222080.0000 - val_loss: 142437724979200.0000\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 1963609686016.0000 - val_loss: 255728593928192.0000\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 1671643004928.0000 - val_loss: 466004253605888.0000\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 7873176272896.0000 - val_loss: 854977731887104.0000\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 7073235468288.0000 - val_loss: 1542614008463360.0000\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 17197104627712.0000 - val_loss: 2769673548464128.0000\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 27662642839552.0000 - val_loss: 4976905560260608.0000\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 58096474914816.0000 - val_loss: 8936702735286272.0000\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 133829570330624.0000 - val_loss: 16103327041323008.0000\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 126285888094208.0000 - val_loss: 29280950277898240.0000\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 212824420777984.0000 - val_loss: 52400572401188864.0000\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 870513568120832.0000 - val_loss: 95299234034614272.0000\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 885599036768256.0000 - val_loss: 173225995371806720.0000\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 1077629910253568.0000 - val_loss: 312517935174254592.0000\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 1949593969360896.0000 - val_loss: 561807148523192320.0000\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 5119192458067968.0000 - val_loss: 999738919014629376.0000\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 11783088157753344.0000 - val_loss: 1804290609721114624.0000\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 28209602898165760.0000 - val_loss: 3231222781475553280.0000\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 24271566711816192.0000 - val_loss: 5833607375235317760.0000\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 68333238917005312.0000 - val_loss: 10480419491635265536.0000\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 143748835955441664.0000 - val_loss: 18786315045808635904.0000\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 250692671222317056.0000 - val_loss: 33702604248543395840.0000\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 487801116801630208.0000 - val_loss: 60681316661236596736.0000\n",
      "Epoch 73/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 781460640853131264.0000 - val_loss: 108920339840234422272.0000\n",
      "Epoch 74/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 1665599587382984704.0000 - val_loss: 195458774694855966720.0000\n",
      "Epoch 75/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 1846583599361425408.0000 - val_loss: 352775895642441515008.0000\n",
      "Epoch 76/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 3139497398317875200.0000 - val_loss: 614740997292351815680.0000\n",
      "Epoch 77/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 9246960959317082112.0000 - val_loss: 1112552715290725580800.0000\n",
      "Epoch 78/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 18916092602258292736.0000 - val_loss: 1994635408500626292736.0000\n",
      "Epoch 79/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 20599053478243860480.0000 - val_loss: 3575583384554904223744.0000\n",
      "Epoch 80/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 45761102201990676480.0000 - val_loss: 6406056343860521467904.0000\n",
      "Epoch 81/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 77230919391916326912.0000 - val_loss: 11515071491438712717312.0000\n",
      "Epoch 82/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 100301391335400669184.0000 - val_loss: 20664055321448396357632.0000\n",
      "Epoch 83/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 242829992928468795392.0000 - val_loss: 37134676173663116460032.0000\n",
      "Epoch 84/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 257295924367489761280.0000 - val_loss: 67067794801985775992832.0000\n",
      "Epoch 85/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 571891111609642254336.0000 - val_loss: 120108786290954462035968.0000\n",
      "Epoch 86/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 1438118424934547980288.0000 - val_loss: 216528134138781849616384.0000\n",
      "Epoch 87/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 1706846948062350278656.0000 - val_loss: 389535679235273382690816.0000\n",
      "Epoch 88/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 6540503429436319727616.0000 - val_loss: 706184237410054202982400.0000\n",
      "Epoch 89/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 5344101359277070876672.0000 - val_loss: 1279480868701678237384704.0000\n",
      "Epoch 90/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 13759837808405914845184.0000 - val_loss: 2292344748352945063460864.0000\n",
      "Epoch 91/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 17582657553504390873088.0000 - val_loss: 4121339855606811333754880.0000\n",
      "Epoch 92/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 34053997855759583412224.0000 - val_loss: 7439669883254953748725760.0000\n",
      "Epoch 93/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 64979327035986373771264.0000 - val_loss: 13253877242338879792480256.0000\n",
      "Epoch 94/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 85032860881149543579648.0000 - val_loss: 25180370592150795310858240.0000\n",
      "Epoch 95/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 367866879844157883416576.0000 - val_loss: 46103573916854789735448576.0000\n",
      "Epoch 96/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 337418871425837396131840.0000 - val_loss: 83630426410358691994796032.0000\n",
      "Epoch 97/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 899674369784608865648640.0000 - val_loss: 150166052173425931701977088.0000\n",
      "Epoch 98/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 1580619786364532467695616.0000 - val_loss: 269050115746655205773541376.0000\n",
      "Epoch 99/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 2108655961977023396577280.0000 - val_loss: 484282851782442775023190016.0000\n",
      "Epoch 100/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 6205983344946635624939520.0000 - val_loss: 879403070936705252957618176.0000\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 2297949676247591250034688.0000\n",
      "[CV]  learning_rate=0.005311235568439109, n_hidden=0, n_neurons=77, total= 1.2min\n",
      "[CV] learning_rate=0.005311235568439109, n_hidden=0, n_neurons=77 ....\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 1.7789 - val_loss: 3.3608\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.6249 - val_loss: 1.0405\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5639 - val_loss: 4.8387\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5402 - val_loss: 8.4263\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5265 - val_loss: 12.9742\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5177 - val_loss: 16.2687\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5130 - val_loss: 17.9466\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5105 - val_loss: 18.4649\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5082 - val_loss: 18.3178\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5051 - val_loss: 19.6041\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5058 - val_loss: 18.8827\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5045 - val_loss: 18.5753\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5026 - val_loss: 19.4997\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5029 - val_loss: 19.6359\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5023 - val_loss: 18.7877\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5021 - val_loss: 18.4859\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5004 - val_loss: 19.1952\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5018 - val_loss: 19.8575\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5009 - val_loss: 19.8875\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4996 - val_loss: 20.2500\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5015 - val_loss: 20.2623\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5011 - val_loss: 19.9846\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5014 - val_loss: 18.6744\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5000 - val_loss: 19.8615\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5009 - val_loss: 19.7086\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5006 - val_loss: 19.0333\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5003 - val_loss: 18.4601\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5010 - val_loss: 19.3394\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4996 - val_loss: 18.7069\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5011 - val_loss: 18.5107\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5005 - val_loss: 18.1359\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5007 - val_loss: 18.1951\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5005 - val_loss: 18.6293\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5002 - val_loss: 19.3696\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5012 - val_loss: 18.9478\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5007 - val_loss: 19.2249\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5007 - val_loss: 19.6865\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5007 - val_loss: 20.2399\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5006 - val_loss: 20.0458\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4999 - val_loss: 20.7579\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5005 - val_loss: 19.8273\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4999 - val_loss: 19.7383\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4997 - val_loss: 19.9995\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5008 - val_loss: 19.7386\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5003 - val_loss: 20.6592\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5000 - val_loss: 19.5099\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5006 - val_loss: 19.0742\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5005 - val_loss: 20.3971\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4997 - val_loss: 20.2818\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4998 - val_loss: 19.7625\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5005 - val_loss: 20.5194\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5007 - val_loss: 20.4475\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5011 - val_loss: 19.6148\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5007 - val_loss: 19.3385\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5008 - val_loss: 19.6657\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4995 - val_loss: 19.2239\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5007 - val_loss: 20.2640\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5007 - val_loss: 20.4313\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5011 - val_loss: 19.2846\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5009 - val_loss: 19.2983\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5007 - val_loss: 20.3508\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5003 - val_loss: 19.5878\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4998 - val_loss: 19.0819\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5012 - val_loss: 18.7666\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5005 - val_loss: 18.9238\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4995 - val_loss: 18.1233\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5008 - val_loss: 18.4600\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5009 - val_loss: 18.2847\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5008 - val_loss: 18.0342\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5007 - val_loss: 19.2641\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5003 - val_loss: 19.9427\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5007 - val_loss: 20.5128\n",
      "Epoch 73/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5007 - val_loss: 20.7178\n",
      "Epoch 74/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5009 - val_loss: 20.2354\n",
      "Epoch 75/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4994 - val_loss: 20.3669\n",
      "Epoch 76/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5013 - val_loss: 20.6692\n",
      "Epoch 77/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5012 - val_loss: 19.3709\n",
      "Epoch 78/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5006 - val_loss: 20.6932\n",
      "Epoch 79/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5004 - val_loss: 20.5999\n",
      "Epoch 80/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5007 - val_loss: 20.8139\n",
      "Epoch 81/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5005 - val_loss: 21.1544\n",
      "Epoch 82/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5012 - val_loss: 19.4935\n",
      "Epoch 83/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4991 - val_loss: 20.6786\n",
      "Epoch 84/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4991 - val_loss: 19.8081\n",
      "Epoch 85/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5007 - val_loss: 20.2448\n",
      "Epoch 86/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5005 - val_loss: 21.0392\n",
      "Epoch 87/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5003 - val_loss: 19.7554\n",
      "Epoch 88/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5002 - val_loss: 20.7926\n",
      "Epoch 89/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5005 - val_loss: 21.3266\n",
      "Epoch 90/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5003 - val_loss: 21.2780\n",
      "Epoch 91/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5009 - val_loss: 20.2825\n",
      "Epoch 92/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5005 - val_loss: 19.3782\n",
      "Epoch 93/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5006 - val_loss: 20.0363\n",
      "Epoch 94/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5005 - val_loss: 20.6516\n",
      "Epoch 95/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5009 - val_loss: 20.4431\n",
      "Epoch 96/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5009 - val_loss: 20.4267\n",
      "Epoch 97/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5012 - val_loss: 20.2032\n",
      "Epoch 98/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5007 - val_loss: 21.0226\n",
      "Epoch 99/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5005 - val_loss: 20.3148\n",
      "Epoch 100/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5008 - val_loss: 19.5200\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.9670\n",
      "[CV]  learning_rate=0.005311235568439109, n_hidden=0, n_neurons=77, total= 1.1min\n",
      "[CV] learning_rate=0.005311235568439109, n_hidden=0, n_neurons=77 ....\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 1.8469 - val_loss: 28.3004\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.9447 - val_loss: 40.2533\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 1.0481 - val_loss: 56.5639\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 1.2545 - val_loss: 83.3410\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.8866 - val_loss: 50.1584\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.9353 - val_loss: 104.1128\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 1.7660 - val_loss: 128.6831\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 2.7217 - val_loss: 136.7430\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 1.3127 - val_loss: 153.2015\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 1.7243 - val_loss: 216.8745\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 2.6401 - val_loss: 284.5380\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 5.0437 - val_loss: 336.1388\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 2.3273 - val_loss: 350.5396\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 3.1265 - val_loss: 478.3180\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 5.0786 - val_loss: 573.3203\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 5.9951 - val_loss: 700.2657\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 7.8681 - val_loss: 866.4489\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 16.4151 - val_loss: 935.3167\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 14.7586 - val_loss: 1185.2651\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 7.4806 - val_loss: 1585.6218\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 16.4537 - val_loss: 1895.3141\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 11.6428 - val_loss: 2461.1902\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 14.2139 - val_loss: 2686.2612\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 15.1847 - val_loss: 3424.9233\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 51.6032 - val_loss: 4162.2656\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 77.0461 - val_loss: 4739.8765\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 61.1581 - val_loss: 5601.0952\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 90.1815 - val_loss: 6520.6460\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 32.9083 - val_loss: 7352.7437\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 37.4234 - val_loss: 9230.1182\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 56.6345 - val_loss: 10599.5791\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 121.4638 - val_loss: 12467.4023\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 78.3223 - val_loss: 14451.4180\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 93.2331 - val_loss: 17668.3047\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 128.4771 - val_loss: 20923.3789\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 102.9627 - val_loss: 25989.3438\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 159.6783 - val_loss: 29886.5020\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 349.0797 - val_loss: 35323.5391\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 260.3909 - val_loss: 41511.6328\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 641.9871 - val_loss: 49295.1328\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 529.9877 - val_loss: 58058.7422\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 727.8304 - val_loss: 68870.4766\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 834.4756 - val_loss: 81789.1641\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 1219.3704 - val_loss: 96854.8438\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 574.5696 - val_loss: 114582.6250\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 1607.8445 - val_loss: 135574.4219\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 2463.7307 - val_loss: 162332.6562\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 860.1958 - val_loss: 197295.0625\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 1901.5085 - val_loss: 223561.4062\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 2604.8096 - val_loss: 264608.8750\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 1536.1315 - val_loss: 312545.1875\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 5334.5854 - val_loss: 373145.2812\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 4552.6738 - val_loss: 442030.4062\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 7303.5234 - val_loss: 522292.3125\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 2895.5417 - val_loss: 620247.9375\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 5375.5347 - val_loss: 736339.5625\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 7238.6543 - val_loss: 877483.4375\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 11323.6514 - val_loss: 1043803.8750\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 15705.6377 - val_loss: 1238484.2500\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 18570.8359 - val_loss: 1453070.6250\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 12090.4570 - val_loss: 1724604.7500\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 9233.4805 - val_loss: 2056842.8750\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 11271.7939 - val_loss: 2529346.7500\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 18105.1016 - val_loss: 3009176.5000\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 28972.0938 - val_loss: 3540282.5000\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 65120.5273 - val_loss: 4242203.0000\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 64046.5820 - val_loss: 5000442.0000\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 83068.1719 - val_loss: 5923657.5000\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 67912.4688 - val_loss: 7026826.0000\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 59566.6250 - val_loss: 8333174.5000\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 150520.3906 - val_loss: 9958772.0000\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 58358.2617 - val_loss: 11915657.0000\n",
      "Epoch 73/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 63337.8867 - val_loss: 14335448.0000\n",
      "Epoch 74/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 78975.9531 - val_loss: 16946008.0000\n",
      "Epoch 75/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 101381.5234 - val_loss: 20921354.0000\n",
      "Epoch 76/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 103219.2188 - val_loss: 25082760.0000\n",
      "Epoch 77/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 277119.2812 - val_loss: 29819564.0000\n",
      "Epoch 78/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 211699.8750 - val_loss: 35333376.0000\n",
      "Epoch 79/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 560626.1875 - val_loss: 42183376.0000\n",
      "Epoch 80/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 359127.8125 - val_loss: 49962012.0000\n",
      "Epoch 81/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 270559.3750 - val_loss: 59521284.0000\n",
      "Epoch 82/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 888759.8125 - val_loss: 70889448.0000\n",
      "Epoch 83/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 1210529.1250 - val_loss: 84249728.0000\n",
      "Epoch 84/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 498831.3438 - val_loss: 100661576.0000\n",
      "Epoch 85/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 894009.8125 - val_loss: 119445032.0000\n",
      "Epoch 86/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 685153.1875 - val_loss: 142633584.0000\n",
      "Epoch 87/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 1385272.6250 - val_loss: 167689408.0000\n",
      "Epoch 88/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 2143773.5000 - val_loss: 199282320.0000\n",
      "Epoch 89/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 1474733.1250 - val_loss: 236061744.0000\n",
      "Epoch 90/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 2099988.0000 - val_loss: 281620768.0000\n",
      "Epoch 91/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 2387684.2500 - val_loss: 331345888.0000\n",
      "Epoch 92/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 6073632.5000 - val_loss: 394041824.0000\n",
      "Epoch 93/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 2548613.7500 - val_loss: 468745824.0000\n",
      "Epoch 94/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 6581948.5000 - val_loss: 555598208.0000\n",
      "Epoch 95/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 4484856.5000 - val_loss: 658550528.0000\n",
      "Epoch 96/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 11134799.0000 - val_loss: 1020660672.0000\n",
      "Epoch 97/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 5051555.0000 - val_loss: 1231174784.0000\n",
      "Epoch 98/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 6368889.0000 - val_loss: 1449931520.0000\n",
      "Epoch 99/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 23948442.0000 - val_loss: 1723889792.0000\n",
      "Epoch 100/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 15300596.0000 - val_loss: 2046878464.0000\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 2363154.7500\n",
      "[CV]  learning_rate=0.005311235568439109, n_hidden=0, n_neurons=77, total= 1.0min\n",
      "[CV] learning_rate=0.0004208026572921413, n_hidden=2, n_neurons=78 ...\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 3.3838 - val_loss: 6.4390\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 1.6510 - val_loss: 3.8271\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 1.0555 - val_loss: 2.0925\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.8302 - val_loss: 1.2722\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.7312 - val_loss: 0.8547\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.6799 - val_loss: 0.6964\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.6478 - val_loss: 0.6278\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.6237 - val_loss: 0.5915\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.6036 - val_loss: 0.5722\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5859 - val_loss: 0.5528\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5699 - val_loss: 0.5401\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5555 - val_loss: 0.5249\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5422 - val_loss: 0.5145\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5300 - val_loss: 0.5051\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5189 - val_loss: 0.4979\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5088 - val_loss: 0.4917\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4994 - val_loss: 0.4845\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4908 - val_loss: 0.4797\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4828 - val_loss: 0.4696\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4754 - val_loss: 0.4645\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4687 - val_loss: 0.4600\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4625 - val_loss: 0.4590\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4567 - val_loss: 0.4567\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4514 - val_loss: 0.4585\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4464 - val_loss: 0.4571\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4418 - val_loss: 0.4528\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4377 - val_loss: 0.4537\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4338 - val_loss: 0.4547\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4302 - val_loss: 0.4558\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4268 - val_loss: 0.4549\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4235 - val_loss: 0.4621\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4205 - val_loss: 0.4587\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4177 - val_loss: 0.4565\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4151 - val_loss: 0.4540\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4126 - val_loss: 0.4642\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4103 - val_loss: 0.4606\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4081 - val_loss: 0.4577\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4060 - val_loss: 0.4616\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4040 - val_loss: 0.4682\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4022 - val_loss: 0.4639\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4003 - val_loss: 0.4658\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3985 - val_loss: 0.4654\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - ETA: 0s - loss: 0.397 - 1s 3ms/step - loss: 0.3969 - val_loss: 0.4735\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3953 - val_loss: 0.4598\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3939 - val_loss: 0.4651\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3923 - val_loss: 0.4571\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3910 - val_loss: 0.4584\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3897 - val_loss: 0.4583\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3884 - val_loss: 0.4654\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3871 - val_loss: 0.4581\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3859 - val_loss: 0.4550\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3847 - val_loss: 0.4507\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3836 - val_loss: 0.4531\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3825 - val_loss: 0.4606\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3815 - val_loss: 0.4597\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3805 - val_loss: 0.4667\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3795 - val_loss: 0.4566\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3786 - val_loss: 0.4523\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3776 - val_loss: 0.4582\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3767 - val_loss: 0.4636\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3759 - val_loss: 0.4710\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3750 - val_loss: 0.4516\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3743 - val_loss: 0.4513\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3735 - val_loss: 0.4508\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3726 - val_loss: 0.4600\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3719 - val_loss: 0.4576\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3713 - val_loss: 0.4466\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3706 - val_loss: 0.4449\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3699 - val_loss: 0.4552\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3691 - val_loss: 0.4425\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3686 - val_loss: 0.4469\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3679 - val_loss: 0.4457\n",
      "Epoch 73/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3672 - val_loss: 0.4470\n",
      "Epoch 74/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3667 - val_loss: 0.4516\n",
      "Epoch 75/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3661 - val_loss: 0.4422\n",
      "Epoch 76/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3654 - val_loss: 0.4543\n",
      "Epoch 77/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3650 - val_loss: 0.4354\n",
      "Epoch 78/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3644 - val_loss: 0.4436\n",
      "Epoch 79/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3638 - val_loss: 0.4425\n",
      "Epoch 80/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3632 - val_loss: 0.4343\n",
      "Epoch 81/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3627 - val_loss: 0.4501\n",
      "Epoch 82/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3622 - val_loss: 0.4429\n",
      "Epoch 83/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3618 - val_loss: 0.4402\n",
      "Epoch 84/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3613 - val_loss: 0.4422\n",
      "Epoch 85/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3608 - val_loss: 0.4391\n",
      "Epoch 86/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3603 - val_loss: 0.4440\n",
      "Epoch 87/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3599 - val_loss: 0.4344\n",
      "Epoch 88/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3594 - val_loss: 0.4415\n",
      "Epoch 89/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3590 - val_loss: 0.4421\n",
      "Epoch 90/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3586 - val_loss: 0.4456\n",
      "Epoch 91/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3580 - val_loss: 0.4404\n",
      "Epoch 92/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3577 - val_loss: 0.4284\n",
      "Epoch 93/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3573 - val_loss: 0.4406\n",
      "Epoch 94/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3570 - val_loss: 0.4310\n",
      "Epoch 95/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3565 - val_loss: 0.4244\n",
      "Epoch 96/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3561 - val_loss: 0.4486\n",
      "Epoch 97/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3558 - val_loss: 0.4429\n",
      "Epoch 98/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3554 - val_loss: 0.4378\n",
      "Epoch 99/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3550 - val_loss: 0.4436\n",
      "Epoch 100/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3546 - val_loss: 0.4392\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.3775\n",
      "[CV]  learning_rate=0.0004208026572921413, n_hidden=2, n_neurons=78, total= 1.2min\n",
      "[CV] learning_rate=0.0004208026572921413, n_hidden=2, n_neurons=78 ...\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 3.9457 - val_loss: 13.3852\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 1.4805 - val_loss: 25.5759\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.9852 - val_loss: 24.6669\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.8280 - val_loss: 20.8998\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.7448 - val_loss: 16.2327\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.6933 - val_loss: 12.9010\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.6579 - val_loss: 10.0609\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.6318 - val_loss: 8.1309\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.6108 - val_loss: 6.4798\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5930 - val_loss: 5.1202\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5772 - val_loss: 4.1757\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5633 - val_loss: 3.2741\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5507 - val_loss: 2.6531\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5393 - val_loss: 2.0504\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5289 - val_loss: 1.6656\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5194 - val_loss: 1.3823\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5107 - val_loss: 1.0892\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5030 - val_loss: 0.9143\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4958 - val_loss: 0.7759\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4892 - val_loss: 0.6731\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4832 - val_loss: 0.5951\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4777 - val_loss: 0.5479\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4725 - val_loss: 0.5208\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4678 - val_loss: 0.4884\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4635 - val_loss: 0.4563\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4594 - val_loss: 0.4486\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4557 - val_loss: 0.4381\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4522 - val_loss: 0.4297\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4488 - val_loss: 0.4226\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4457 - val_loss: 0.4220\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4428 - val_loss: 0.4165\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4400 - val_loss: 0.4153\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4374 - val_loss: 0.4127\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4349 - val_loss: 0.4092\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4326 - val_loss: 0.4063\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4302 - val_loss: 0.4046\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4280 - val_loss: 0.4030\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4259 - val_loss: 0.4038\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4238 - val_loss: 0.4034\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4219 - val_loss: 0.4034\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4201 - val_loss: 0.4033\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4182 - val_loss: 0.4073\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4165 - val_loss: 0.4057\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4148 - val_loss: 0.4094\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4130 - val_loss: 0.4088\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4115 - val_loss: 0.4135\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4100 - val_loss: 0.4250\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4086 - val_loss: 0.4283\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4071 - val_loss: 0.4357\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4057 - val_loss: 0.4459\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4043 - val_loss: 0.4477\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4030 - val_loss: 0.4572\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4018 - val_loss: 0.4727\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4005 - val_loss: 0.4778\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3994 - val_loss: 0.4986\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3982 - val_loss: 0.5125\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3971 - val_loss: 0.5085\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3960 - val_loss: 0.5388\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3950 - val_loss: 0.5538\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3939 - val_loss: 0.5716\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3929 - val_loss: 0.5643\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3920 - val_loss: 0.5851\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3910 - val_loss: 0.6040\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3900 - val_loss: 0.6173\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3892 - val_loss: 0.6444\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3883 - val_loss: 0.6515\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3874 - val_loss: 0.6818\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3865 - val_loss: 0.6919\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3857 - val_loss: 0.7209\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3849 - val_loss: 0.7318\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3841 - val_loss: 0.7284\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3833 - val_loss: 0.7628\n",
      "Epoch 73/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3824 - val_loss: 0.7819\n",
      "Epoch 74/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3817 - val_loss: 0.7824\n",
      "Epoch 75/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3808 - val_loss: 0.7600\n",
      "Epoch 76/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3803 - val_loss: 0.8307\n",
      "Epoch 77/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3795 - val_loss: 0.8219\n",
      "Epoch 78/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3788 - val_loss: 0.8424\n",
      "Epoch 79/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3781 - val_loss: 0.8782\n",
      "Epoch 80/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3774 - val_loss: 0.8657\n",
      "Epoch 81/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3767 - val_loss: 0.8903\n",
      "Epoch 82/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3760 - val_loss: 0.8997\n",
      "Epoch 83/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3753 - val_loss: 0.9205\n",
      "Epoch 84/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3745 - val_loss: 0.9857\n",
      "Epoch 85/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3740 - val_loss: 0.9331\n",
      "Epoch 86/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3735 - val_loss: 0.9538\n",
      "Epoch 87/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3728 - val_loss: 0.9815\n",
      "Epoch 88/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3722 - val_loss: 0.9924\n",
      "Epoch 89/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3716 - val_loss: 0.9955\n",
      "Epoch 90/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3711 - val_loss: 1.0142\n",
      "Epoch 91/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3705 - val_loss: 1.0396\n",
      "Epoch 92/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3699 - val_loss: 1.0568\n",
      "Epoch 93/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3694 - val_loss: 1.0390\n",
      "Epoch 94/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3688 - val_loss: 1.0718\n",
      "Epoch 95/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3682 - val_loss: 1.0400\n",
      "Epoch 96/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3677 - val_loss: 1.0804\n",
      "Epoch 97/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3671 - val_loss: 1.0566\n",
      "Epoch 98/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3667 - val_loss: 1.0978\n",
      "Epoch 99/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3662 - val_loss: 1.0897\n",
      "Epoch 100/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3656 - val_loss: 1.1171\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.3852\n",
      "[CV]  learning_rate=0.0004208026572921413, n_hidden=2, n_neurons=78, total= 1.2min\n",
      "[CV] learning_rate=0.0004208026572921413, n_hidden=2, n_neurons=78 ...\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 3.2958 - val_loss: 4.3415\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 1.4040 - val_loss: 2.4101\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.9555 - val_loss: 1.6064\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.8185 - val_loss: 1.0032\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.7556 - val_loss: 0.8144\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.7186 - val_loss: 0.7218\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.6916 - val_loss: 0.6771\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.6695 - val_loss: 0.6538\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.6503 - val_loss: 0.6298\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.6332 - val_loss: 0.6108\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.6173 - val_loss: 0.5979\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.6028 - val_loss: 0.5785\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5896 - val_loss: 0.5676\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5771 - val_loss: 0.5536\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5656 - val_loss: 0.5425\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5546 - val_loss: 0.5308\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5446 - val_loss: 0.5202\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5355 - val_loss: 0.5130\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5265 - val_loss: 0.5073\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5185 - val_loss: 0.4952\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5110 - val_loss: 0.4921\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5037 - val_loss: 0.4861\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4969 - val_loss: 0.4839\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4905 - val_loss: 0.4709\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4846 - val_loss: 0.4658\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4789 - val_loss: 0.4621\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4736 - val_loss: 0.4580\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4685 - val_loss: 0.4547\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4637 - val_loss: 0.4488\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4594 - val_loss: 0.4471\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4551 - val_loss: 0.4436\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4510 - val_loss: 0.4464\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4474 - val_loss: 0.4417\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4438 - val_loss: 0.4323\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4405 - val_loss: 0.4347\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4373 - val_loss: 0.4268\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4343 - val_loss: 0.4250\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4315 - val_loss: 0.4259\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4287 - val_loss: 0.4224\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4262 - val_loss: 0.4202\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4237 - val_loss: 0.4176\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4214 - val_loss: 0.4180\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4193 - val_loss: 0.4184\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4172 - val_loss: 0.4163\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4151 - val_loss: 0.4212\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4131 - val_loss: 0.4060\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4115 - val_loss: 0.4140\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4096 - val_loss: 0.4152\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4080 - val_loss: 0.4186\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4063 - val_loss: 0.4160\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4048 - val_loss: 0.4122\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4033 - val_loss: 0.4072\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4017 - val_loss: 0.4177\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4005 - val_loss: 0.4057\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3992 - val_loss: 0.4105\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3979 - val_loss: 0.4098\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3966 - val_loss: 0.4032\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3955 - val_loss: 0.4000\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3943 - val_loss: 0.4046\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3932 - val_loss: 0.4106\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3920 - val_loss: 0.4142\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3910 - val_loss: 0.4005\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3899 - val_loss: 0.4138\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3890 - val_loss: 0.4099\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3880 - val_loss: 0.4143\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3870 - val_loss: 0.4204\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3861 - val_loss: 0.4224\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3853 - val_loss: 0.4039\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3843 - val_loss: 0.4143\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3834 - val_loss: 0.4122\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3826 - val_loss: 0.4141\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3818 - val_loss: 0.4076\n",
      "Epoch 73/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3810 - val_loss: 0.4063\n",
      "Epoch 74/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3802 - val_loss: 0.4039\n",
      "Epoch 75/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3795 - val_loss: 0.3980\n",
      "Epoch 76/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3787 - val_loss: 0.4110\n",
      "Epoch 77/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3779 - val_loss: 0.4034\n",
      "Epoch 78/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3772 - val_loss: 0.3913\n",
      "Epoch 79/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3765 - val_loss: 0.3903\n",
      "Epoch 80/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3756 - val_loss: 0.3946\n",
      "Epoch 81/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3753 - val_loss: 0.3928\n",
      "Epoch 82/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3743 - val_loss: 0.4123\n",
      "Epoch 83/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3738 - val_loss: 0.4078\n",
      "Epoch 84/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3732 - val_loss: 0.4141\n",
      "Epoch 85/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3725 - val_loss: 0.3962\n",
      "Epoch 86/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3719 - val_loss: 0.4072\n",
      "Epoch 87/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3714 - val_loss: 0.3941\n",
      "Epoch 88/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3708 - val_loss: 0.3971\n",
      "Epoch 89/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3702 - val_loss: 0.3999\n",
      "Epoch 90/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3696 - val_loss: 0.3994\n",
      "Epoch 91/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3691 - val_loss: 0.4067\n",
      "Epoch 92/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3685 - val_loss: 0.3963\n",
      "Epoch 93/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3681 - val_loss: 0.3981\n",
      "Epoch 94/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3675 - val_loss: 0.3917\n",
      "Epoch 95/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3670 - val_loss: 0.3940\n",
      "Epoch 96/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3665 - val_loss: 0.4048\n",
      "Epoch 97/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3659 - val_loss: 0.4067\n",
      "Epoch 98/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3655 - val_loss: 0.3920\n",
      "Epoch 99/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3650 - val_loss: 0.3899\n",
      "Epoch 100/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3646 - val_loss: 0.3904\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.3668\n",
      "[CV]  learning_rate=0.0004208026572921413, n_hidden=2, n_neurons=78, total= 1.2min\n",
      "[CV] learning_rate=0.0025187334662874973, n_hidden=1, n_neurons=62 ...\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 1.6093 - val_loss: 22.8658\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.9757 - val_loss: 42.6571\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 1.0120 - val_loss: 9.0766\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.6722 - val_loss: 0.5655\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5530 - val_loss: 0.5345\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5210 - val_loss: 0.5231\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4994 - val_loss: 0.4943\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4823 - val_loss: 0.4456\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4674 - val_loss: 0.4345\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4555 - val_loss: 0.4225\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4458 - val_loss: 0.4109\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4366 - val_loss: 0.4027\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4294 - val_loss: 0.3935\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4232 - val_loss: 0.3888\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4179 - val_loss: 0.3841\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4129 - val_loss: 0.3865\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4091 - val_loss: 0.3772\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4050 - val_loss: 0.3820\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4015 - val_loss: 0.3816\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3982 - val_loss: 0.3739\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3955 - val_loss: 0.3681\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3927 - val_loss: 0.3641\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3902 - val_loss: 0.3632\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3871 - val_loss: 0.3662\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3851 - val_loss: 0.3835\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3837 - val_loss: 0.3584\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3814 - val_loss: 0.3574\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3791 - val_loss: 0.3565\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3776 - val_loss: 0.3675\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3760 - val_loss: 0.3534\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3744 - val_loss: 0.3606\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3730 - val_loss: 0.3549\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3715 - val_loss: 0.3516\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3699 - val_loss: 0.3586\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3687 - val_loss: 0.3511\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3671 - val_loss: 0.3527\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3661 - val_loss: 0.3617\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3652 - val_loss: 0.3451\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3640 - val_loss: 0.3576\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3628 - val_loss: 0.3462\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3614 - val_loss: 0.3773\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3608 - val_loss: 0.3478\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3602 - val_loss: 0.3580\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3592 - val_loss: 0.3403\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3578 - val_loss: 0.3565\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3570 - val_loss: 0.3426\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3571 - val_loss: 0.3380\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3557 - val_loss: 0.3427\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3548 - val_loss: 0.3382\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3542 - val_loss: 0.3371\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3529 - val_loss: 0.3505\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3529 - val_loss: 0.3482\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3525 - val_loss: 0.3365\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3513 - val_loss: 0.3485\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3509 - val_loss: 0.3355\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3501 - val_loss: 0.3544\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3497 - val_loss: 0.3395\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3494 - val_loss: 0.3342\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3486 - val_loss: 0.3618\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3480 - val_loss: 0.3329\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3473 - val_loss: 0.3324\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3472 - val_loss: 0.3309\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3462 - val_loss: 0.3310\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3455 - val_loss: 0.3365\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3455 - val_loss: 0.3387\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3448 - val_loss: 0.3612\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3452 - val_loss: 0.3325\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3439 - val_loss: 0.3380\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3436 - val_loss: 0.3295\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3433 - val_loss: 0.3301\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3426 - val_loss: 0.3294\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3421 - val_loss: 0.3276\n",
      "Epoch 73/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3417 - val_loss: 0.3285\n",
      "Epoch 74/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3412 - val_loss: 0.3568\n",
      "Epoch 75/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3409 - val_loss: 0.3315\n",
      "Epoch 76/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3405 - val_loss: 0.3764\n",
      "Epoch 77/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3411 - val_loss: 0.3282\n",
      "Epoch 78/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3399 - val_loss: 0.3267\n",
      "Epoch 79/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3395 - val_loss: 0.3497\n",
      "Epoch 80/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3387 - val_loss: 0.3268\n",
      "Epoch 81/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3383 - val_loss: 0.3256\n",
      "Epoch 82/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3384 - val_loss: 0.3353\n",
      "Epoch 83/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3376 - val_loss: 0.3910\n",
      "Epoch 84/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3380 - val_loss: 0.3326\n",
      "Epoch 85/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3373 - val_loss: 0.3754\n",
      "Epoch 86/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3371 - val_loss: 0.3230\n",
      "Epoch 87/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3359 - val_loss: 0.3603\n",
      "Epoch 88/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3362 - val_loss: 0.3226\n",
      "Epoch 89/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3352 - val_loss: 0.3410\n",
      "Epoch 90/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3353 - val_loss: 0.3275\n",
      "Epoch 91/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3347 - val_loss: 0.3690\n",
      "Epoch 92/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3354 - val_loss: 0.3301\n",
      "Epoch 93/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3340 - val_loss: 0.3235\n",
      "Epoch 94/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3340 - val_loss: 0.3276\n",
      "Epoch 95/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3333 - val_loss: 0.3595\n",
      "Epoch 96/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3331 - val_loss: 0.3377\n",
      "Epoch 97/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3328 - val_loss: 0.4436\n",
      "Epoch 98/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3334 - val_loss: 0.4809\n",
      "Epoch 99/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3331 - val_loss: 0.3835\n",
      "Epoch 100/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3322 - val_loss: 0.4097\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.3592\n",
      "[CV]  learning_rate=0.0025187334662874973, n_hidden=1, n_neurons=62, total= 1.1min\n",
      "[CV] learning_rate=0.0025187334662874973, n_hidden=1, n_neurons=62 ...\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 1.5733 - val_loss: 2.3921\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.6848 - val_loss: 0.7589\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.6075 - val_loss: 0.6815\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5560 - val_loss: 1.2371\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5201 - val_loss: 1.7185\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4939 - val_loss: 2.2018\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4740 - val_loss: 2.2293\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4599 - val_loss: 2.3547\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4490 - val_loss: 2.1218\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4411 - val_loss: 1.9011\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4333 - val_loss: 1.6778\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4276 - val_loss: 1.4823\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4219 - val_loss: 1.3258\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4165 - val_loss: 1.0805\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4126 - val_loss: 0.9832\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4090 - val_loss: 0.8437\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4056 - val_loss: 0.7393\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4022 - val_loss: 0.6409\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3997 - val_loss: 0.5694\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3965 - val_loss: 0.5271\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3942 - val_loss: 0.4798\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3914 - val_loss: 0.4305\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3897 - val_loss: 0.4264\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3876 - val_loss: 0.3933\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3858 - val_loss: 0.3870\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3838 - val_loss: 0.3705\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3823 - val_loss: 0.3620\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3808 - val_loss: 0.3595\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3789 - val_loss: 0.3583\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3776 - val_loss: 0.3565\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3762 - val_loss: 0.3569\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3748 - val_loss: 0.3608\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3740 - val_loss: 0.3624\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3721 - val_loss: 0.3640\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3712 - val_loss: 0.3614\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3698 - val_loss: 0.3636\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3690 - val_loss: 0.3710\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3681 - val_loss: 0.3755\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3672 - val_loss: 0.3794\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3659 - val_loss: 0.3805\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3655 - val_loss: 0.4008\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3645 - val_loss: 0.4302\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3643 - val_loss: 0.4237\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3633 - val_loss: 0.4223\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3624 - val_loss: 0.4385\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3611 - val_loss: 0.4411\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3612 - val_loss: 0.4569\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3607 - val_loss: 0.4522\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3598 - val_loss: 0.4681\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3594 - val_loss: 0.4612\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3589 - val_loss: 0.4701\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3579 - val_loss: 0.4718\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3576 - val_loss: 0.4941\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3567 - val_loss: 0.4659\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3563 - val_loss: 0.4611\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3562 - val_loss: 0.4613\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3555 - val_loss: 0.4914\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3550 - val_loss: 0.4860\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3542 - val_loss: 0.4809\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3539 - val_loss: 0.4605\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3538 - val_loss: 0.4626\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3529 - val_loss: 0.4785\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3531 - val_loss: 0.4947\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3521 - val_loss: 0.4765\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3518 - val_loss: 0.4801\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3512 - val_loss: 0.4597\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3503 - val_loss: 0.4391\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3496 - val_loss: 0.4414\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3497 - val_loss: 0.4808\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3493 - val_loss: 0.4805\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3492 - val_loss: 0.4964\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3485 - val_loss: 0.4775\n",
      "Epoch 73/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3477 - val_loss: 0.4728\n",
      "Epoch 74/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3479 - val_loss: 0.4657\n",
      "Epoch 75/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3475 - val_loss: 0.4560\n",
      "Epoch 76/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3467 - val_loss: 0.4343\n",
      "Epoch 77/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3468 - val_loss: 0.4150\n",
      "Epoch 78/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3461 - val_loss: 0.4040\n",
      "Epoch 79/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3454 - val_loss: 0.4198\n",
      "Epoch 80/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3457 - val_loss: 0.4280\n",
      "Epoch 81/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3449 - val_loss: 0.4265\n",
      "Epoch 82/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3449 - val_loss: 0.4140\n",
      "Epoch 83/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3445 - val_loss: 0.4345\n",
      "Epoch 84/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3433 - val_loss: 0.4364\n",
      "Epoch 85/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3438 - val_loss: 0.4222\n",
      "Epoch 86/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3433 - val_loss: 0.4245\n",
      "Epoch 87/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3429 - val_loss: 0.4293\n",
      "Epoch 88/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3422 - val_loss: 0.4331\n",
      "Epoch 89/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3424 - val_loss: 0.4461\n",
      "Epoch 90/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3413 - val_loss: 0.4720\n",
      "Epoch 91/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3412 - val_loss: 0.5070\n",
      "Epoch 92/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3409 - val_loss: 0.5035\n",
      "Epoch 93/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3407 - val_loss: 0.4576\n",
      "Epoch 94/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3407 - val_loss: 0.4529\n",
      "Epoch 95/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3401 - val_loss: 0.4770\n",
      "Epoch 96/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3398 - val_loss: 0.4715\n",
      "Epoch 97/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3400 - val_loss: 0.4632\n",
      "Epoch 98/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3394 - val_loss: 0.4806\n",
      "Epoch 99/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3388 - val_loss: 0.4444\n",
      "Epoch 100/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3385 - val_loss: 0.4533\n",
      "121/121 [==============================] - 0s 2ms/step - loss: 0.3547\n",
      "[CV]  learning_rate=0.0025187334662874973, n_hidden=1, n_neurons=62, total= 1.1min\n",
      "[CV] learning_rate=0.0025187334662874973, n_hidden=1, n_neurons=62 ...\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 1.3816 - val_loss: 1.6253\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.6866 - val_loss: 0.9429\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.6213 - val_loss: 1.0298\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5735 - val_loss: 0.7282\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5339 - val_loss: 0.5825\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5109 - val_loss: 2.3175\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4908 - val_loss: 1.8611\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5020 - val_loss: 4.6321\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4936 - val_loss: 4.2987\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5084 - val_loss: 6.1303\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4967 - val_loss: 3.5294\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4714 - val_loss: 3.5352\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4693 - val_loss: 1.6651\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4454 - val_loss: 1.8023\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4302 - val_loss: 1.2632\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4249 - val_loss: 0.9523\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4206 - val_loss: 0.6033\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4138 - val_loss: 1.0231\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4154 - val_loss: 0.5027\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4073 - val_loss: 0.7480\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4064 - val_loss: 0.3754\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4014 - val_loss: 0.3745\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3990 - val_loss: 0.3879\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3978 - val_loss: 0.3967\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3948 - val_loss: 0.5031\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3951 - val_loss: 0.4015\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3919 - val_loss: 0.6647\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3934 - val_loss: 0.3668\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3881 - val_loss: 0.4954\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3886 - val_loss: 0.4148\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3867 - val_loss: 0.7244\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3892 - val_loss: 0.4821\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3851 - val_loss: 0.8168\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3881 - val_loss: 0.5591\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3838 - val_loss: 0.7303\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3825 - val_loss: 0.3919\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3803 - val_loss: 0.4227\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3788 - val_loss: 0.4586\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3784 - val_loss: 0.5855\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3774 - val_loss: 0.3556\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3751 - val_loss: 0.7193\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3772 - val_loss: 0.3560\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3725 - val_loss: 0.3688\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3721 - val_loss: 0.3559\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3715 - val_loss: 0.3613\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3699 - val_loss: 0.3615\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3702 - val_loss: 0.4000\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3689 - val_loss: 0.3892\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3684 - val_loss: 0.4404\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3686 - val_loss: 0.9864\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3716 - val_loss: 0.8698\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3727 - val_loss: 1.5442\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3759 - val_loss: 1.9457\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3758 - val_loss: 3.1954\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4045 - val_loss: 3.7158\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3930 - val_loss: 4.3588\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3978 - val_loss: 4.3708\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3994 - val_loss: 3.6462\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3902 - val_loss: 2.6500\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3862 - val_loss: 2.3755\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3858 - val_loss: 1.2302\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3689 - val_loss: 3.1294\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3891 - val_loss: 2.0295\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4013 - val_loss: 1.2985\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3686 - val_loss: 0.5601\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3626 - val_loss: 0.4312\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3615 - val_loss: 0.3395\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3596 - val_loss: 0.4221\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3578 - val_loss: 0.3373\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3567 - val_loss: 0.3541\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3558 - val_loss: 0.3829\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3555 - val_loss: 0.3323\n",
      "Epoch 73/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3551 - val_loss: 0.3952\n",
      "Epoch 74/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3552 - val_loss: 0.3385\n",
      "Epoch 75/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3543 - val_loss: 0.3760\n",
      "Epoch 76/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3539 - val_loss: 0.3679\n",
      "Epoch 77/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3540 - val_loss: 0.3387\n",
      "Epoch 78/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3524 - val_loss: 0.3481\n",
      "Epoch 79/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3530 - val_loss: 0.3485\n",
      "Epoch 80/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3514 - val_loss: 0.3316\n",
      "Epoch 81/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3512 - val_loss: 0.3662\n",
      "Epoch 82/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3508 - val_loss: 0.5108\n",
      "Epoch 83/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3515 - val_loss: 0.3317\n",
      "Epoch 84/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3496 - val_loss: 0.3978\n",
      "Epoch 85/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3497 - val_loss: 0.3347\n",
      "Epoch 86/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3491 - val_loss: 0.3405\n",
      "Epoch 87/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3483 - val_loss: 0.4944\n",
      "Epoch 88/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3487 - val_loss: 0.3268\n",
      "Epoch 89/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3466 - val_loss: 0.3317\n",
      "Epoch 90/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3469 - val_loss: 0.3452\n",
      "Epoch 91/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3463 - val_loss: 0.3280\n",
      "Epoch 92/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3473 - val_loss: 0.3792\n",
      "Epoch 93/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3461 - val_loss: 0.3319\n",
      "Epoch 94/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3451 - val_loss: 0.5343\n",
      "Epoch 95/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3476 - val_loss: 0.4935\n",
      "Epoch 96/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3470 - val_loss: 0.6194\n",
      "Epoch 97/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3481 - val_loss: 0.4329\n",
      "Epoch 98/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3453 - val_loss: 0.8526\n",
      "Epoch 99/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3479 - val_loss: 1.2230\n",
      "Epoch 100/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3531 - val_loss: 1.9297\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.3422\n",
      "[CV]  learning_rate=0.0025187334662874973, n_hidden=1, n_neurons=62, total= 1.1min\n",
      "[CV] learning_rate=0.000623897084264486, n_hidden=0, n_neurons=89 ....\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 6.9108 - val_loss: 11.9459\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 3.8576 - val_loss: 6.9540\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 2.3910 - val_loss: 4.1050\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 1.6415 - val_loss: 2.6975\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 1.2453 - val_loss: 2.1466\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 1.0315 - val_loss: 1.7702\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.9110 - val_loss: 1.4203\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.8392 - val_loss: 1.3622\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.7968 - val_loss: 1.2471\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.7683 - val_loss: 1.2160\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.7492 - val_loss: 1.1499\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.7341 - val_loss: 1.1499\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.7226 - val_loss: 1.1029\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.7121 - val_loss: 1.1040\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.7032 - val_loss: 1.1053\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.6950 - val_loss: 1.0916\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.6873 - val_loss: 1.0787\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.6802 - val_loss: 1.0173\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.6728 - val_loss: 1.0453\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.6666 - val_loss: 1.0265\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.6605 - val_loss: 0.9573\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.6545 - val_loss: 0.9253\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.6485 - val_loss: 0.9403\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.6433 - val_loss: 0.9012\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.6379 - val_loss: 0.9115\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.6330 - val_loss: 0.8982\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.6283 - val_loss: 0.8873\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.6238 - val_loss: 0.8571\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.6188 - val_loss: 0.9233\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.6154 - val_loss: 0.8914\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.6108 - val_loss: 0.9359\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.6075 - val_loss: 0.9327\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.6039 - val_loss: 0.9206\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.6006 - val_loss: 0.8683\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5972 - val_loss: 0.8335\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5939 - val_loss: 0.8428\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5909 - val_loss: 0.8532\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5877 - val_loss: 0.8850\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5849 - val_loss: 0.9171\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5829 - val_loss: 0.8586\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5802 - val_loss: 0.8348\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5774 - val_loss: 0.8606\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5755 - val_loss: 0.8180\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5729 - val_loss: 0.8510\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5711 - val_loss: 0.8375\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5690 - val_loss: 0.8324\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5671 - val_loss: 0.8333\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5653 - val_loss: 0.8098\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5632 - val_loss: 0.8343\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5619 - val_loss: 0.7869\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5602 - val_loss: 0.7773\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5587 - val_loss: 0.7713\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5571 - val_loss: 0.7723\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5557 - val_loss: 0.7692\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5543 - val_loss: 0.7750\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5529 - val_loss: 0.7989\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5517 - val_loss: 0.8165\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5506 - val_loss: 0.8248\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5497 - val_loss: 0.7829\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5486 - val_loss: 0.7561\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5472 - val_loss: 0.7829\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5464 - val_loss: 0.7930\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5455 - val_loss: 0.7877\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5448 - val_loss: 0.7426\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5437 - val_loss: 0.7482\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5427 - val_loss: 0.7771\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5423 - val_loss: 0.7420\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5413 - val_loss: 0.7508\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5405 - val_loss: 0.7786\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5400 - val_loss: 0.7769\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5395 - val_loss: 0.7290\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5383 - val_loss: 0.7711\n",
      "Epoch 73/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5379 - val_loss: 0.7936\n",
      "Epoch 74/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5375 - val_loss: 0.7918\n",
      "Epoch 75/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5369 - val_loss: 0.8021\n",
      "Epoch 76/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5366 - val_loss: 0.7779\n",
      "Epoch 77/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5356 - val_loss: 0.8078\n",
      "Epoch 78/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5355 - val_loss: 0.8024\n",
      "Epoch 79/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5350 - val_loss: 0.7975\n",
      "Epoch 80/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5348 - val_loss: 0.7492\n",
      "Epoch 81/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5341 - val_loss: 0.7508\n",
      "Epoch 82/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5338 - val_loss: 0.7401\n",
      "Epoch 83/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5330 - val_loss: 0.7748\n",
      "Epoch 84/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5327 - val_loss: 0.8017\n",
      "Epoch 85/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5328 - val_loss: 0.7479\n",
      "Epoch 86/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5323 - val_loss: 0.7496\n",
      "Epoch 87/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5320 - val_loss: 0.7382\n",
      "Epoch 88/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5316 - val_loss: 0.7354\n",
      "Epoch 89/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5314 - val_loss: 0.7111\n",
      "Epoch 90/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5309 - val_loss: 0.7226\n",
      "Epoch 91/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5305 - val_loss: 0.7595\n",
      "Epoch 92/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5307 - val_loss: 0.6771\n",
      "Epoch 93/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5300 - val_loss: 0.7133\n",
      "Epoch 94/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5300 - val_loss: 0.7189\n",
      "Epoch 95/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5294 - val_loss: 0.7653\n",
      "Epoch 96/100\n",
      "242/242 [==============================] - ETA: 0s - loss: 0.530 - 1s 3ms/step - loss: 0.5298 - val_loss: 0.7183\n",
      "Epoch 97/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5294 - val_loss: 0.7039\n",
      "Epoch 98/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5292 - val_loss: 0.6949\n",
      "Epoch 99/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5288 - val_loss: 0.7204\n",
      "Epoch 100/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5285 - val_loss: 0.7572\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.5358\n",
      "[CV]  learning_rate=0.000623897084264486, n_hidden=0, n_neurons=89, total= 1.1min\n",
      "[CV] learning_rate=0.000623897084264486, n_hidden=0, n_neurons=89 ....\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 4.7311 - val_loss: 33.6114\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 2.8824 - val_loss: 26.1328\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 1.8805 - val_loss: 20.3597\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 1.3307 - val_loss: 15.8022\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 1.0244 - val_loss: 12.1622\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.8502 - val_loss: 9.2490\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.7488 - val_loss: 6.9098\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.6874 - val_loss: 5.0481\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.6485 - val_loss: 3.5987\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.6227 - val_loss: 2.4853\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.6044 - val_loss: 1.6607\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5907 - val_loss: 1.0904\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5800 - val_loss: 0.7303\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5713 - val_loss: 0.5504\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5639 - val_loss: 0.5249\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5575 - val_loss: 0.6288\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5519 - val_loss: 0.8427\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5469 - val_loss: 1.1510\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5425 - val_loss: 1.5384\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5385 - val_loss: 1.9861\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5350 - val_loss: 2.4837\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5318 - val_loss: 3.0230\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5289 - val_loss: 3.5820\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5263 - val_loss: 4.1607\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5240 - val_loss: 4.7581\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5218 - val_loss: 5.3727\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5199 - val_loss: 5.9909\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5181 - val_loss: 6.6000\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5165 - val_loss: 7.2014\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5151 - val_loss: 7.7985\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5137 - val_loss: 8.3904\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5125 - val_loss: 8.9860\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5114 - val_loss: 9.5526\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5104 - val_loss: 10.0976\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5095 - val_loss: 10.6256\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5086 - val_loss: 11.1538\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5078 - val_loss: 11.6438\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5071 - val_loss: 12.1294\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5065 - val_loss: 12.5866\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5059 - val_loss: 13.0321\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5053 - val_loss: 13.4642\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5048 - val_loss: 13.8659\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5044 - val_loss: 14.2506\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5039 - val_loss: 14.6380\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5035 - val_loss: 14.9951\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5032 - val_loss: 15.3424\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5028 - val_loss: 15.6810\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5025 - val_loss: 16.0106\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5022 - val_loss: 16.3130\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5019 - val_loss: 16.6006\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5017 - val_loss: 16.8604\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5014 - val_loss: 17.1214\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5012 - val_loss: 17.3660\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5010 - val_loss: 17.6041\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5008 - val_loss: 17.8100\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5006 - val_loss: 18.0112\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5005 - val_loss: 18.1962\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5003 - val_loss: 18.3666\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5001 - val_loss: 18.5354\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5000 - val_loss: 18.7065\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4999 - val_loss: 18.8724\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4998 - val_loss: 19.0091\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4996 - val_loss: 19.1462\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4995 - val_loss: 19.2868\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4994 - val_loss: 19.4262\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4994 - val_loss: 19.5352\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4992 - val_loss: 19.6358\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4991 - val_loss: 19.7460\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4991 - val_loss: 19.8289\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4990 - val_loss: 19.9148\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4989 - val_loss: 19.9909\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4988 - val_loss: 20.0788\n",
      "Epoch 73/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4988 - val_loss: 20.1350\n",
      "Epoch 74/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4987 - val_loss: 20.1944\n",
      "Epoch 75/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4987 - val_loss: 20.2721\n",
      "Epoch 76/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4986 - val_loss: 20.3226\n",
      "Epoch 77/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4986 - val_loss: 20.3792\n",
      "Epoch 78/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4985 - val_loss: 20.4256\n",
      "Epoch 79/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4984 - val_loss: 20.4541\n",
      "Epoch 80/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4984 - val_loss: 20.4905\n",
      "Epoch 81/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4984 - val_loss: 20.5425\n",
      "Epoch 82/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4983 - val_loss: 20.5738\n",
      "Epoch 83/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4983 - val_loss: 20.6023\n",
      "Epoch 84/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4983 - val_loss: 20.6417\n",
      "Epoch 85/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4982 - val_loss: 20.6729\n",
      "Epoch 86/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4982 - val_loss: 20.7055\n",
      "Epoch 87/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4981 - val_loss: 20.7513\n",
      "Epoch 88/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4982 - val_loss: 20.7747\n",
      "Epoch 89/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4981 - val_loss: 20.7904\n",
      "Epoch 90/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4981 - val_loss: 20.8134\n",
      "Epoch 91/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4980 - val_loss: 20.8459\n",
      "Epoch 92/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4980 - val_loss: 20.8722\n",
      "Epoch 93/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4980 - val_loss: 20.8806\n",
      "Epoch 94/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4980 - val_loss: 20.8925\n",
      "Epoch 95/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4980 - val_loss: 20.9109\n",
      "Epoch 96/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4979 - val_loss: 20.9424\n",
      "Epoch 97/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4979 - val_loss: 20.9586\n",
      "Epoch 98/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4979 - val_loss: 20.9702\n",
      "Epoch 99/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4979 - val_loss: 20.9819\n",
      "Epoch 100/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4979 - val_loss: 20.9769\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 1.0024\n",
      "[CV]  learning_rate=0.000623897084264486, n_hidden=0, n_neurons=89, total= 1.1min\n",
      "[CV] learning_rate=0.000623897084264486, n_hidden=0, n_neurons=89 ....\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 4.8408 - val_loss: 10.7742\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 2.7517 - val_loss: 4.9818\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 1.7047 - val_loss: 2.7366\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 1.1663 - val_loss: 1.7714\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.8833 - val_loss: 1.2966\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.7328 - val_loss: 1.0090\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.6515 - val_loss: 0.8848\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.6072 - val_loss: 0.8607\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5833 - val_loss: 0.8107\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5696 - val_loss: 0.7656\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5613 - val_loss: 0.7775\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5563 - val_loss: 0.8063\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5536 - val_loss: 0.7813\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5514 - val_loss: 0.7518\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5497 - val_loss: 0.7241\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5483 - val_loss: 0.7093\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5470 - val_loss: 0.7316\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5462 - val_loss: 0.7195\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5451 - val_loss: 0.7332\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5442 - val_loss: 0.7422\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5434 - val_loss: 0.7368\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5426 - val_loss: 0.7433\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5418 - val_loss: 0.7530\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5413 - val_loss: 0.7396\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5406 - val_loss: 0.7051\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5400 - val_loss: 0.6935\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5390 - val_loss: 0.7257\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5383 - val_loss: 0.7700\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5380 - val_loss: 0.7830\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5376 - val_loss: 0.7822\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5373 - val_loss: 0.7545\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5367 - val_loss: 0.7413\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5363 - val_loss: 0.7136\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5357 - val_loss: 0.7244\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5354 - val_loss: 0.7069\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5349 - val_loss: 0.7096\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5346 - val_loss: 0.6778\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5336 - val_loss: 0.7322\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5339 - val_loss: 0.7147\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5335 - val_loss: 0.7163\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5332 - val_loss: 0.7192\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5330 - val_loss: 0.6959\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5327 - val_loss: 0.6789\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5322 - val_loss: 0.7042\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5316 - val_loss: 0.7456\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5318 - val_loss: 0.7508\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5317 - val_loss: 0.7136\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5314 - val_loss: 0.7030\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5312 - val_loss: 0.6763\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5309 - val_loss: 0.6833\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5308 - val_loss: 0.6826\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5306 - val_loss: 0.6814\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5302 - val_loss: 0.6982\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5302 - val_loss: 0.6854\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5298 - val_loss: 0.7217\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5300 - val_loss: 0.6991\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5296 - val_loss: 0.7163\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5297 - val_loss: 0.6899\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5295 - val_loss: 0.6640\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5290 - val_loss: 0.7003\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5289 - val_loss: 0.7318\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5291 - val_loss: 0.7200\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5286 - val_loss: 0.7534\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5291 - val_loss: 0.7296\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5286 - val_loss: 0.7396\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5287 - val_loss: 0.7347\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5288 - val_loss: 0.6846\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5281 - val_loss: 0.7254\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5282 - val_loss: 0.7438\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5282 - val_loss: 0.7522\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5283 - val_loss: 0.7419\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5282 - val_loss: 0.7310\n",
      "Epoch 73/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5283 - val_loss: 0.6837\n",
      "Epoch 74/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5278 - val_loss: 0.7116\n",
      "Epoch 75/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5278 - val_loss: 0.7277\n",
      "Epoch 76/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5277 - val_loss: 0.7496\n",
      "Epoch 77/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5281 - val_loss: 0.7027\n",
      "Epoch 78/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5279 - val_loss: 0.6764\n",
      "Epoch 79/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5277 - val_loss: 0.6819\n",
      "Epoch 80/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5277 - val_loss: 0.6665\n",
      "Epoch 81/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5277 - val_loss: 0.6464\n",
      "Epoch 82/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5276 - val_loss: 0.6529\n",
      "Epoch 83/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5275 - val_loss: 0.6393\n",
      "Epoch 84/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5274 - val_loss: 0.6628\n",
      "Epoch 85/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5271 - val_loss: 0.7052\n",
      "Epoch 86/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5275 - val_loss: 0.6661\n",
      "Epoch 87/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5273 - val_loss: 0.6763\n",
      "Epoch 88/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5272 - val_loss: 0.7013\n",
      "Epoch 89/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5273 - val_loss: 0.7002\n",
      "Epoch 90/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5272 - val_loss: 0.7143\n",
      "Epoch 91/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5272 - val_loss: 0.7266\n",
      "Epoch 92/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5270 - val_loss: 0.7486\n",
      "Epoch 93/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5274 - val_loss: 0.7016\n",
      "Epoch 94/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5269 - val_loss: 0.7344\n",
      "Epoch 95/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5273 - val_loss: 0.7137\n",
      "Epoch 96/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5272 - val_loss: 0.6789\n",
      "Epoch 97/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5268 - val_loss: 0.7195\n",
      "Epoch 98/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5272 - val_loss: 0.7086\n",
      "Epoch 99/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5271 - val_loss: 0.7149\n",
      "Epoch 100/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5272 - val_loss: 0.6944\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.5309\n",
      "[CV]  learning_rate=0.000623897084264486, n_hidden=0, n_neurons=89, total= 1.0min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  30 out of  30 | elapsed: 60.9min finished\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Cannot clone object <tensorflow.python.keras.wrappers.scikit_learn.KerasRegressor object at 0x000001AAC1ECBE88>, as the constructor either does not set or modifies parameter learning_rate",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-66-7a5b3986f830>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[0mrnd_search_cv\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mRandomizedSearchCV\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkeras_reg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparam_distribs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_iter\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m rnd_search_cv.fit(X_train, y_train, epochs=100,\n\u001b[1;32m---> 12\u001b[1;33m                   validation_data=(X_valid, y_valid))\n\u001b[0m",
      "\u001b[1;32mc:\\users\\artur\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     70\u001b[0m                           FutureWarning)\n\u001b[0;32m     71\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 72\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     73\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     74\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\artur\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    760\u001b[0m             \u001b[1;31m# of the params are estimators as well.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    761\u001b[0m             self.best_estimator_ = clone(clone(base_estimator).set_params(\n\u001b[1;32m--> 762\u001b[1;33m                 **self.best_params_))\n\u001b[0m\u001b[0;32m    763\u001b[0m             \u001b[0mrefit_start_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    764\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\artur\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     70\u001b[0m                           FutureWarning)\n\u001b[0;32m     71\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 72\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     73\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     74\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\artur\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\base.py\u001b[0m in \u001b[0;36mclone\u001b[1;34m(estimator, safe)\u001b[0m\n\u001b[0;32m     96\u001b[0m             raise RuntimeError('Cannot clone object %s, as the constructor '\n\u001b[0;32m     97\u001b[0m                                \u001b[1;34m'either does not set or modifies parameter %s'\u001b[0m \u001b[1;33m%\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 98\u001b[1;33m                                (estimator, name))\n\u001b[0m\u001b[0;32m     99\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mnew_object\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    100\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Cannot clone object <tensorflow.python.keras.wrappers.scikit_learn.KerasRegressor object at 0x000001AAC1ECBE88>, as the constructor either does not set or modifies parameter learning_rate"
     ]
    }
   ],
   "source": [
    "from scipy.stats import reciprocal\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "param_distribs = {\n",
    "    \"n_hidden\": [0, 1, 2, 3],\n",
    "    \"n_neurons\": np.arange(1, 100),\n",
    "    \"learning_rate\": reciprocal(3e-4, 3e-2),\n",
    "}\n",
    "\n",
    "rnd_search_cv = RandomizedSearchCV(keras_reg, param_distribs, n_iter=10, cv=3, verbose=2)\n",
    "rnd_search_cv.fit(X_train, y_train, epochs=100,\n",
    "                  validation_data=(X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exponential learning rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train_full, y_train_full), (X_test, y_test) = keras.datasets.mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_valid, X_train = X_train_full[:5000] / 255., X_train_full[5000:] / 255.\n",
    "y_valid, y_train = y_train_full[:5000], y_train_full[5000:]\n",
    "X_test = X_test / 255."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "K = keras.backend\n",
    "\n",
    "class ExponentialLearningRate(keras.callbacks.Callback):\n",
    "    def __init__(self, factor):\n",
    "        self.factor = factor\n",
    "        self.rates = []\n",
    "        self.losses = []\n",
    "    def on_batch_end(self, batch, logs):\n",
    "        self.rates.append(K.get_value(self.model.optimizer.lr))\n",
    "        self.losses.append(logs[\"loss\"])\n",
    "        K.set_value(self.model.optimizer.lr, self.model.optimizer.lr * self.factor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape=[28, 28]),\n",
    "    keras.layers.Dense(300, activation=\"relu\"),\n",
    "    keras.layers.Dense(100, activation=\"relu\"),\n",
    "    keras.layers.Dense(10, activation=\"softmax\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "              optimizer=keras.optimizers.SGD(lr=1e-3),\n",
    "              metrics=[\"accuracy\"])\n",
    "\n",
    "expon_lr = ExponentialLearningRate(factor=1.005)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1719/1719 [==============================] - 4s 2ms/step - loss: nan - accuracy: 0.5780 - val_loss: nan - val_accuracy: 0.0958\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, epochs=1,\n",
    "                    validation_data=(X_valid, y_valid),\n",
    "                    callbacks=[expon_lr])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Loss')"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(expon_lr.rates, expon_lr.losses)\n",
    "plt.gca().set_xscale('log')\n",
    "plt.hlines(min(expon_lr.losses), min(expon_lr.rates), max(expon_lr.rates))\n",
    "plt.axis([min(expon_lr.rates), max(expon_lr.rates), 0, expon_lr.losses[0]])\n",
    "plt.xlabel(\"Learning rate\")\n",
    "plt.ylabel(\"Loss\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now we get a sense about what learning rate is acceptable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape=[28, 28]),\n",
    "    keras.layers.Dense(300, activation=\"relu\"),\n",
    "    keras.layers.Dense(100, activation=\"relu\"),\n",
    "    keras.layers.Dense(10, activation=\"softmax\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "              optimizer=keras.optimizers.SGD(lr=2e-1),\n",
    "              metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.2326 - accuracy: 0.9287 - val_loss: 0.1004 - val_accuracy: 0.9704\n",
      "Epoch 2/100\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.0942 - accuracy: 0.9705 - val_loss: 0.0921 - val_accuracy: 0.9726\n",
      "Epoch 3/100\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.0615 - accuracy: 0.9806 - val_loss: 0.0746 - val_accuracy: 0.9806\n",
      "Epoch 4/100\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.0446 - accuracy: 0.9850 - val_loss: 0.0773 - val_accuracy: 0.9770\n",
      "Epoch 5/100\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.0362 - accuracy: 0.9884 - val_loss: 0.0681 - val_accuracy: 0.9798\n",
      "Epoch 6/100\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.0242 - accuracy: 0.9920 - val_loss: 0.0753 - val_accuracy: 0.9806\n",
      "Epoch 7/100\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.0189 - accuracy: 0.9938 - val_loss: 0.0735 - val_accuracy: 0.9806\n",
      "Epoch 8/100\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.0128 - accuracy: 0.9959 - val_loss: 0.1158 - val_accuracy: 0.9718\n",
      "Epoch 9/100\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.0106 - accuracy: 0.9966 - val_loss: 0.0747 - val_accuracy: 0.9822\n",
      "Epoch 10/100\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.0075 - accuracy: 0.9977 - val_loss: 0.0666 - val_accuracy: 0.9854\n",
      "Epoch 11/100\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.0038 - accuracy: 0.9988 - val_loss: 0.0950 - val_accuracy: 0.9796\n",
      "Epoch 12/100\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.0021 - accuracy: 0.9996 - val_loss: 0.0711 - val_accuracy: 0.9846\n",
      "Epoch 13/100\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 8.5159e-04 - accuracy: 0.9999 - val_loss: 0.0748 - val_accuracy: 0.9840\n",
      "Epoch 14/100\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 6.6167e-04 - accuracy: 0.9999 - val_loss: 0.0719 - val_accuracy: 0.9852\n",
      "Epoch 15/100\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 2.9587e-04 - accuracy: 1.0000 - val_loss: 0.0730 - val_accuracy: 0.9842\n",
      "Epoch 16/100\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 2.1147e-04 - accuracy: 1.0000 - val_loss: 0.0739 - val_accuracy: 0.9844\n",
      "Epoch 17/100\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 1.8241e-04 - accuracy: 1.0000 - val_loss: 0.0752 - val_accuracy: 0.9838\n",
      "Epoch 18/100\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 1.6283e-04 - accuracy: 1.0000 - val_loss: 0.0758 - val_accuracy: 0.9840\n",
      "Epoch 19/100\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 1.4719e-04 - accuracy: 1.0000 - val_loss: 0.0763 - val_accuracy: 0.9840\n",
      "Epoch 20/100\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 1.3637e-04 - accuracy: 1.0000 - val_loss: 0.0773 - val_accuracy: 0.9838\n",
      "Epoch 21/100\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 1.2630e-04 - accuracy: 1.0000 - val_loss: 0.0777 - val_accuracy: 0.9838\n",
      "Epoch 22/100\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 1.1817e-04 - accuracy: 1.0000 - val_loss: 0.0780 - val_accuracy: 0.9838\n",
      "Epoch 23/100\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 1.1082e-04 - accuracy: 1.0000 - val_loss: 0.0782 - val_accuracy: 0.9844\n",
      "Epoch 24/100\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 1.0461e-04 - accuracy: 1.0000 - val_loss: 0.0788 - val_accuracy: 0.9840\n",
      "Epoch 25/100\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 9.9458e-05 - accuracy: 1.0000 - val_loss: 0.0793 - val_accuracy: 0.9842\n",
      "Epoch 26/100\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 9.4005e-05 - accuracy: 1.0000 - val_loss: 0.0795 - val_accuracy: 0.9840\n",
      "Epoch 27/100\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 8.9580e-05 - accuracy: 1.0000 - val_loss: 0.0803 - val_accuracy: 0.9840\n",
      "Epoch 28/100\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 8.5697e-05 - accuracy: 1.0000 - val_loss: 0.0804 - val_accuracy: 0.9838\n",
      "Epoch 29/100\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 8.1869e-05 - accuracy: 1.0000 - val_loss: 0.0810 - val_accuracy: 0.9840\n",
      "Epoch 30/100\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 7.8484e-05 - accuracy: 1.0000 - val_loss: 0.0809 - val_accuracy: 0.9842\n"
     ]
    }
   ],
   "source": [
    "early_stopping_cb = keras.callbacks.EarlyStopping(patience=20)\n",
    "checkpoint_cb = keras.callbacks.ModelCheckpoint(\"my_mnist_model.h5\", save_best_only=True)\n",
    "\n",
    "history = model.fit(X_train, y_train, epochs=100,\n",
    "                    validation_data=(X_valid, y_valid),\n",
    "                    callbacks=[early_stopping_cb, checkpoint_cb])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
